2023-07-15 21:13:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-15 21:13:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-15 21:13:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume spk model from checkpoint /home/work_nfs4_ssd/hzhao/aslp-spknet-fork/exp/ecapa_augment_vox2/results/ecapa_augments_vox2/final.pth.tar
2023-07-15 21:18:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-15 21:18:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-15 21:18:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume spk model from checkpoint /home/work_nfs4_ssd/hzhao/aslp-spknet-fork/exp/ecapa_augment_vox2/results/ecapa_augments_vox2/final.pth.tar
2023-07-15 21:23:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-15 21:23:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-15 21:23:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume spk model from checkpoint /home/work_nfs4_ssd/hzhao/aslp-spknet-fork/exp/ecapa_augment_vox2/results/ecapa_augments_vox2/final.pth.tar
2023-07-15 21:40:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-15 21:40:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-15 21:40:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume spk model from checkpoint /home/work_nfs4_ssd/hzhao/aslp-spknet-fork/exp/ecapa_augment_vox2/results/ecapa_augments_vox2/final.pth.tar
2023-07-16 19:58:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-16 19:58:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-16 19:58:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume spk model from checkpoint /home/work_nfs4_ssd/hzhao/aslp-spknet-fork/exp/ecapa_augment_vox2/results/ecapa_augments_vox2/final.pth.tar
2023-07-16 19:58:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: gradient clipping by 5.0, default L2
2023-07-16 19:58:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-16 19:59:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.00e+02 / 2.29e+03 batches (snr_loss = +43.82)...
2023-07-16 19:59:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.00e+02 / 2.29e+03 batches (ce_loss = +7.58)...
2023-07-16 19:59:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.00e+02 / 2.29e+03 batches (mae_loss = +0.07)...
2023-07-16 19:59:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.00e+02 / 2.29e+03 batches (loss = +47.68)...
2023-07-16 19:59:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.00e+02 / 2.29e+03 batches (snr_loss = +42.82)...
2023-07-16 19:59:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.00e+02 / 2.29e+03 batches (ce_loss = +7.58)...
2023-07-16 19:59:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.00e+02 / 2.29e+03 batches (mae_loss = +0.07)...
2023-07-16 19:59:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.00e+02 / 2.29e+03 batches (loss = +46.67)...
2023-07-16 20:00:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 3.00e+02 / 2.29e+03 batches (snr_loss = +43.55)...
2023-07-16 20:00:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 3.00e+02 / 2.29e+03 batches (ce_loss = +7.58)...
2023-07-16 20:00:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 3.00e+02 / 2.29e+03 batches (mae_loss = +0.07)...
2023-07-16 20:00:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 3.00e+02 / 2.29e+03 batches (loss = +47.40)...
2023-07-16 20:00:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 4.00e+02 / 2.29e+03 batches (snr_loss = +43.10)...
2023-07-16 20:00:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 4.00e+02 / 2.29e+03 batches (ce_loss = +7.58)...
2023-07-16 20:00:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 4.00e+02 / 2.29e+03 batches (mae_loss = +0.07)...
2023-07-16 20:00:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 4.00e+02 / 2.29e+03 batches (loss = +46.95)...
2023-07-16 20:00:55 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 5.00e+02 / 2.29e+03 batches (snr_loss = +42.85)...
2023-07-16 20:00:55 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 5.00e+02 / 2.29e+03 batches (ce_loss = +7.58)...
2023-07-16 20:00:55 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 5.00e+02 / 2.29e+03 batches (mae_loss = +0.07)...
2023-07-16 20:00:55 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 5.00e+02 / 2.29e+03 batches (loss = +46.71)...
2023-07-16 20:01:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 6.00e+02 / 2.29e+03 batches (snr_loss = +43.08)...
2023-07-16 20:01:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 6.00e+02 / 2.29e+03 batches (ce_loss = +7.58)...
2023-07-16 20:01:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 6.00e+02 / 2.29e+03 batches (mae_loss = +0.07)...
2023-07-16 20:01:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 6.00e+02 / 2.29e+03 batches (loss = +46.94)...
2023-07-16 20:01:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 7.00e+02 / 2.29e+03 batches (snr_loss = +42.26)...
2023-07-16 20:01:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 7.00e+02 / 2.29e+03 batches (ce_loss = +7.58)...
2023-07-16 20:01:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 7.00e+02 / 2.29e+03 batches (mae_loss = +0.07)...
2023-07-16 20:01:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 7.00e+02 / 2.29e+03 batches (loss = +46.12)...
2023-07-16 20:01:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 8.00e+02 / 2.29e+03 batches (snr_loss = +42.94)...
2023-07-16 20:01:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 8.00e+02 / 2.29e+03 batches (ce_loss = +7.58)...
2023-07-16 20:01:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 8.00e+02 / 2.29e+03 batches (mae_loss = +0.07)...
2023-07-16 20:01:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 8.00e+02 / 2.29e+03 batches (loss = +46.80)...
2023-07-16 20:01:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 9.00e+02 / 2.29e+03 batches (snr_loss = +43.00)...
2023-07-16 20:01:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 9.00e+02 / 2.29e+03 batches (ce_loss = +7.58)...
2023-07-16 20:01:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 9.00e+02 / 2.29e+03 batches (mae_loss = +0.07)...
2023-07-16 20:01:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 9.00e+02 / 2.29e+03 batches (loss = +46.86)...
2023-07-16 20:02:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.00e+03 / 2.29e+03 batches (snr_loss = +42.69)...
2023-07-16 20:02:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.00e+03 / 2.29e+03 batches (ce_loss = +7.58)...
2023-07-16 20:02:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.00e+03 / 2.29e+03 batches (mae_loss = +0.07)...
2023-07-16 20:02:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.00e+03 / 2.29e+03 batches (loss = +46.55)...
2023-07-16 20:02:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.10e+03 / 2.29e+03 batches (snr_loss = +43.11)...
2023-07-16 20:02:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.10e+03 / 2.29e+03 batches (ce_loss = +7.58)...
2023-07-16 20:02:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.10e+03 / 2.29e+03 batches (mae_loss = +0.07)...
2023-07-16 20:02:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.10e+03 / 2.29e+03 batches (loss = +46.97)...
2023-07-16 20:03:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.20e+03 / 2.29e+03 batches (snr_loss = +43.09)...
2023-07-16 20:03:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.20e+03 / 2.29e+03 batches (ce_loss = +7.58)...
2023-07-16 20:03:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.20e+03 / 2.29e+03 batches (mae_loss = +0.07)...
2023-07-16 20:03:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.20e+03 / 2.29e+03 batches (loss = +46.95)...
2023-07-16 20:03:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.30e+03 / 2.29e+03 batches (snr_loss = +43.35)...
2023-07-16 20:03:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.30e+03 / 2.29e+03 batches (ce_loss = +7.58)...
2023-07-16 20:03:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.30e+03 / 2.29e+03 batches (mae_loss = +0.07)...
2023-07-16 20:03:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.30e+03 / 2.29e+03 batches (loss = +47.21)...
2023-07-16 20:04:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.40e+03 / 2.29e+03 batches (snr_loss = +43.05)...
2023-07-16 20:04:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.40e+03 / 2.29e+03 batches (ce_loss = +7.58)...
2023-07-16 20:04:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.40e+03 / 2.29e+03 batches (mae_loss = +0.07)...
2023-07-16 20:04:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.40e+03 / 2.29e+03 batches (loss = +46.91)...
2023-07-16 20:04:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.50e+03 / 2.29e+03 batches (snr_loss = +43.73)...
2023-07-16 20:04:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.50e+03 / 2.29e+03 batches (ce_loss = +7.58)...
2023-07-16 20:04:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.50e+03 / 2.29e+03 batches (mae_loss = +0.07)...
2023-07-16 20:04:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.50e+03 / 2.29e+03 batches (loss = +47.59)...
2023-07-16 20:05:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.60e+03 / 2.29e+03 batches (snr_loss = +43.24)...
2023-07-16 20:05:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.60e+03 / 2.29e+03 batches (ce_loss = +7.58)...
2023-07-16 20:05:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.60e+03 / 2.29e+03 batches (mae_loss = +0.07)...
2023-07-16 20:05:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.60e+03 / 2.29e+03 batches (loss = +47.10)...
2023-07-16 20:05:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.70e+03 / 2.29e+03 batches (snr_loss = +43.34)...
2023-07-16 20:05:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.70e+03 / 2.29e+03 batches (ce_loss = +7.58)...
2023-07-16 20:05:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.70e+03 / 2.29e+03 batches (mae_loss = +0.07)...
2023-07-16 20:05:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.70e+03 / 2.29e+03 batches (loss = +47.20)...
2023-07-16 20:05:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.80e+03 / 2.29e+03 batches (snr_loss = +43.47)...
2023-07-16 20:05:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.80e+03 / 2.29e+03 batches (ce_loss = +7.58)...
2023-07-16 20:05:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.80e+03 / 2.29e+03 batches (mae_loss = +0.07)...
2023-07-16 20:05:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.80e+03 / 2.29e+03 batches (loss = +47.33)...
2023-07-16 20:06:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.90e+03 / 2.29e+03 batches (snr_loss = +43.14)...
2023-07-16 20:06:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.90e+03 / 2.29e+03 batches (ce_loss = +7.58)...
2023-07-16 20:06:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.90e+03 / 2.29e+03 batches (mae_loss = +0.07)...
2023-07-16 20:06:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.90e+03 / 2.29e+03 batches (loss = +47.00)...
2023-07-16 20:06:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.00e+03 / 2.29e+03 batches (snr_loss = +42.84)...
2023-07-16 20:06:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.00e+03 / 2.29e+03 batches (ce_loss = +7.58)...
2023-07-16 20:06:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.00e+03 / 2.29e+03 batches (mae_loss = +0.07)...
2023-07-16 20:06:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.00e+03 / 2.29e+03 batches (loss = +46.70)...
2023-07-16 20:07:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.10e+03 / 2.29e+03 batches (snr_loss = +43.82)...
2023-07-16 20:07:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.10e+03 / 2.29e+03 batches (ce_loss = +7.58)...
2023-07-16 20:07:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.10e+03 / 2.29e+03 batches (mae_loss = +0.07)...
2023-07-16 20:07:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.10e+03 / 2.29e+03 batches (loss = +47.68)...
2023-07-16 20:07:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.20e+03 / 2.29e+03 batches (snr_loss = +43.00)...
2023-07-16 20:07:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.20e+03 / 2.29e+03 batches (ce_loss = +7.58)...
2023-07-16 20:07:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.20e+03 / 2.29e+03 batches (mae_loss = +0.07)...
2023-07-16 20:07:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.20e+03 / 2.29e+03 batches (loss = +46.86)...
2023-07-16 20:07:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 2290 batches: 45.84,47.75,42.75,46.03,47.18,52.46,49.04,50.89,46.78,41.74,46.32,48.03,48.62,42.80,49.31,43.46,44.35,44.79,43.20,48.42,48.20,46.80,49.27,44.33,47.61,46.99,49.69,48.05,53.03,48.98,44.06,42.82,50.30,51.53,47.78,47.68,48.12,47.78,48.98,49.45,48.24,48.17,43.49,48.68,52.67,50.16,42.90,50.74,48.50,47.72,46.41,47.62,43.28,50.60,45.42,50.65,53.48,43.63,46.54,53.13,41.53,45.82,42.13,48.04,43.18,48.96,47.51,50.60,50.75,45.30,50.21,46.28,46.56,47.52,48.33,48.88,53.92,43.26,49.16,42.30,51.47,50.92,44.99,45.35,44.96,43.83,52.99,51.35,52.81,44.98,47.63,50.71,49.40,49.26,48.81,43.34,49.06,51.94,54.93,45.53,44.25,44.14,45.83,46.34,41.66,47.42,49.35,43.78,48.30,47.98,49.09,51.23,40.65,38.81,47.75,41.72,46.81,47.07,46.43,44.14,46.14,49.11,48.93,42.58,44.52,50.89,44.01,43.38,48.53,45.97,43.98,51.16,46.33,48.74,43.27,46.15,59.53,44.97,44.75,47.14,45.86,48.51,44.87,48.71,47.47,44.77,52.21,41.85,45.49,45.89,44.13,49.10,45.81,46.05,44.30,46.48,50.10,48.85,44.59,47.69,42.48,46.62,51.39,42.59,48.43,42.61,45.23,41.64,47.69,52.93,49.82,42.72,55.14,46.91,49.30,43.91,50.27,50.59,46.09,56.14,44.54,47.62,47.08,45.28,47.48,43.40,43.31,42.30,42.07,47.99,48.81,47.88,46.32,44.25,47.63,51.73,50.63,46.55,45.03,49.56,48.09,49.70,45.18,52.13,55.13,43.45,43.99,40.08,46.40,51.44,43.54,49.36,55.85,46.21,51.66,48.83,53.48,50.48,46.95,51.68,50.40,44.63,42.62,47.87,41.06,42.85,45.58,44.02,46.86,47.13,48.42,49.43,45.63,51.37,42.87,42.96,47.01,55.76,40.67,45.74,45.15,43.58,46.11,43.71,41.97,41.06,51.19,47.14,45.57,46.81,43.93,52.07,45.29,46.64,43.59,45.72,49.11,46.68,44.77,52.16,48.91,51.58,53.46,46.82,47.65,47.74,44.23,44.28,47.50,47.32,51.90,46.57,44.84,46.07,43.51,51.34,52.63,49.14,45.21,47.95,43.47,50.89,44.06,49.11,42.70,49.28,45.89,51.66,48.43,44.06,49.66,50.86,43.98,46.71,54.28,51.45,47.39,49.78,52.48,46.81,45.36,49.70,53.48,46.31,47.64,44.91,50.37,48.63,49.01,51.15,42.47,48.88,48.47,40.82,49.63,59.40,45.81,50.53,45.78,44.46,47.10,44.33,46.26,42.98,46.78,46.33,45.54,48.49,44.27,42.10,45.29,49.18,51.87,51.73,49.15,48.02,48.16,45.54,51.37,47.94,42.39,50.00,52.02,47.33,48.12,47.86,49.98,44.68,41.12,51.76,46.13,44.07,44.26,52.20,43.41,47.13,47.52,42.71,48.79,42.74,49.72,53.59,45.57,44.13,42.70,46.65,44.60,50.29,45.10,48.84,45.92,49.10,47.05,44.86,43.62,40.91,47.87,45.38,47.79,46.50,47.35,41.05,45.60,42.59,44.76,48.29,54.01,46.70,46.81,46.41,45.26,47.66,47.63,44.37,55.91,42.94,44.67,46.88,43.78,43.19,48.96,51.73,46.60,49.00,47.08,47.38,43.48,48.53,49.38,44.59,44.34,41.41,49.59,48.75,42.75,42.66,50.96,48.39,55.73,44.12,42.51,42.16,45.52,47.16,43.91,44.86,43.57,44.50,41.05,43.24,45.57,44.59,47.62,45.72,47.11,43.43,46.57,44.29,47.49,48.12,44.54,46.12,44.41,50.49,42.49,42.41,44.35,46.01,43.74,47.39,47.11,47.70,52.43,46.11,46.15,45.52,52.50,49.04,42.35,45.96,41.77,45.34,44.01,53.42,58.23,45.35,44.47,48.13,46.78,47.87,46.79,45.20,46.70,49.61,50.71,46.94,49.46,48.74,44.41,43.05,43.49,42.15,51.42,48.73,44.33,51.83,43.44,48.77,47.31,44.13,40.74,44.53,45.67,56.07,44.68,51.66,51.04,47.39,49.51,56.07,44.12,51.75,47.85,43.68,48.43,43.65,50.07,47.82,52.07,52.47,48.71,49.99,47.65,43.69,44.48,48.81,47.71,49.13,50.17,46.90,49.70,42.40,47.56,44.43,53.60,43.58,48.57,41.53,42.75,50.83,57.25,46.13,48.04,51.71,50.58,49.90,44.46,45.04,43.39,43.19,44.59,42.76,45.70,49.77,45.64,45.86,44.37,46.03,49.77,47.68,45.86,44.77,46.03,50.79,46.38,40.90,45.99,53.38,49.28,47.01,49.19,47.54,49.84,41.66,50.05,50.02,41.78,52.94,44.56,49.00,44.67,53.55,47.47,46.91,43.11,46.29,40.59,49.29,44.32,51.14,44.75,42.38,44.18,46.29,45.46,46.48,49.37,45.79,46.67,44.64,45.50,48.56,43.57,40.14,45.64,44.06,43.24,51.36,44.74,51.03,48.69,42.83,45.62,42.90,50.24,46.95,43.65,45.90,49.85,49.47,49.39,46.88,48.58,49.15,42.70,41.44,42.37,46.39,45.16,40.48,44.78,49.49,47.44,45.96,46.27,50.21,45.72,51.54,43.50,40.21,44.52,45.34,47.50,48.46,46.87,43.30,45.84,46.61,42.79,45.33,42.10,45.98,47.69,43.83,44.93,49.48,45.15,45.32,47.51,45.50,45.73,46.86,45.49,45.23,49.09,47.52,48.02,46.33,45.27,47.72,40.92,47.46,50.96,45.18,46.33,46.40,51.68,48.72,48.39,52.72,54.74,44.46,50.81,48.44,42.66,46.62,48.05,47.82,41.78,47.36,48.80,45.36,46.71,50.55,42.91,40.27,47.90,47.43,46.58,42.52,41.55,42.53,45.71,46.24,48.44,41.98,42.38,46.27,37.44,43.81,42.12,44.26,55.37,46.83,47.91,46.81,44.76,45.60,54.33,54.33,43.03,49.53,45.58,50.33,47.97,47.34,47.13,47.97,42.56,44.07,46.95,42.43,44.89,46.32,40.01,41.32,45.43,48.69,47.56,45.67,49.68,39.24,50.43,47.29,48.90,46.61,43.25,49.10,51.88,46.69,39.51,44.64,43.98,49.75,46.88,45.46,48.26,46.56,47.88,46.86,45.51,46.47,51.31,41.28,42.86,51.58,49.18,54.94,46.06,42.30,49.47,49.41,48.60,41.12,46.81,43.39,46.97,48.28,45.20,48.23,44.47,45.49,49.37,47.51,53.43,53.02,44.28,44.62,47.33,49.37,47.89,52.97,51.52,43.88,45.92,48.11,43.55,46.07,38.65,44.65,52.15,50.96,42.19,46.58,43.32,52.96,48.82,46.40,42.45,43.33,49.32,44.77,53.00,51.94,43.33,48.86,46.22,50.42,48.23,46.92,46.03,51.01,42.84,43.17,55.10,47.95,43.55,47.63,44.42,44.15,47.56,48.67,44.71,46.88,47.20,53.91,41.23,54.88,46.72,47.56,49.03,43.18,41.75,43.58,47.15,50.87,42.18,43.43,44.08,48.70,42.77,47.78,47.16,50.97,46.14,51.75,47.97,44.06,43.94,47.75,48.43,52.52,51.48,45.74,43.85,44.02,48.47,44.89,44.84,42.29,46.42,47.47,54.56,45.83,44.68,48.97,41.97,44.48,45.10,44.91,40.81,45.01,42.86,53.81,46.89,47.70,47.68,56.12,50.44,42.51,45.47,50.70,51.36,44.07,46.06,44.03,45.10,47.36,47.64,49.23,39.00,50.88,44.32,48.77,51.84,40.82,42.94,44.35,45.74,49.22,50.11,47.48,46.09,43.79,47.97,50.25,45.93,51.84,45.27,50.83,46.19,43.22,46.00,45.21,49.31,40.76,48.54,44.11,44.26,47.90,52.39,43.91,43.63,54.67,45.54,42.25,44.61,46.30,45.34,41.62,46.54,43.14,46.30,46.79,51.32,45.50,43.56,42.99,49.79,52.70,46.49,48.76,42.74,56.27,53.28,45.24,45.09,41.53,49.58,51.45,44.75,42.40,49.23,48.68,48.30,43.41,46.08,43.18,43.89,46.12,44.38,42.81,50.24,45.67,45.07,47.46,44.37,48.85,48.50,51.16,45.89,46.97,48.44,46.10,41.98,48.07,38.64,44.60,51.68,52.28,43.68,51.38,50.35,45.39,42.31,42.54,47.73,45.78,41.61,46.05,54.01,47.15,48.43,42.66,48.05,40.87,42.88,46.45,49.83,43.91,47.74,42.91,47.17,49.37,45.71,46.63,45.31,54.36,46.38,48.00,42.60,49.18,43.70,50.68,44.33,44.43,46.33,46.03,38.85,44.13,48.87,49.27,50.84,53.39,45.90,46.24,44.09,53.86,42.45,45.23,48.20,49.47,51.42,43.73,45.21,45.44,43.80,42.17,42.71,51.91,42.27,48.99,49.53,39.31,44.07,50.07,51.12,48.76,42.69,44.94,47.56,45.37,47.59,42.42,44.36,44.19,49.52,44.80,49.12,42.34,53.25,48.05,47.85,52.79,48.47,42.35,45.40,49.35,41.46,47.93,44.76,54.97,49.44,43.12,47.61,53.02,46.98,45.64,51.97,48.02,43.45,44.37,44.58,47.63,47.09,49.28,49.54,48.59,50.14,47.67,48.77,41.96,46.96,43.40,40.03,49.33,45.20,55.28,55.96,48.18,51.28,52.74,49.80,48.51,50.49,48.52,45.88,50.08,53.51,42.11,55.06,44.40,46.85,47.41,51.84,47.76,53.87,50.63,41.71,43.38,44.69,46.47,47.28,48.27,43.44,48.16,51.27,48.71,44.74,44.33,44.34,42.80,49.07,46.81,45.90,48.62,50.12,48.82,44.17,46.12,49.22,50.37,48.14,47.03,45.59,47.20,45.51,53.38,49.56,52.93,43.67,46.40,50.21,42.36,40.97,44.76,44.82,42.97,45.54,43.55,46.02,48.93,39.87,48.56,45.08,44.55,59.82,38.07,47.70,44.80,49.88,42.14,46.09,46.84,48.32,44.63,49.94,46.55,47.70,46.97,40.41,44.90,39.61,49.62,46.42,48.63,46.06,49.74,50.46,43.62,48.80,42.84,51.09,46.82,49.74,46.18,47.23,43.92,42.32,39.62,49.07,50.08,46.23,52.54,45.36,49.58,51.91,51.79,44.11,52.46,44.59,47.69,48.15,49.90,46.79,41.11,44.36,48.50,47.38,53.16,51.41,53.24,50.11,49.18,48.60,50.13,46.96,45.24,53.68,46.94,48.47,48.07,47.77,42.58,43.32,40.77,43.57,44.02,44.17,45.24,44.17,44.16,49.91,47.01,49.20,42.79,51.74,44.79,49.09,44.70,50.89,45.74,42.48,46.26,49.17,46.77,49.16,42.26,43.87,44.30,45.06,47.87,49.38,47.96,51.04,44.30,47.22,47.86,50.02,46.44,44.69,41.94,48.05,48.25,48.53,56.71,43.78,42.11,46.66,48.10,43.28,45.23,44.95,48.71,51.65,49.27,44.34,47.82,43.27,46.07,47.00,43.51,46.82,45.09,51.16,47.78,44.55,47.64,46.70,53.78,44.51,46.09,45.68,39.82,49.15,49.32,45.61,53.64,53.06,48.63,41.36,42.46,49.03,52.76,44.80,53.21,47.79,50.25,45.85,47.21,43.09,50.19,45.47,46.48,40.79,46.59,48.73,49.73,40.96,48.80,42.14,47.49,42.71,43.86,50.81,46.78,46.30,48.47,50.38,54.83,41.77,46.93,44.29,45.89,43.11,49.03,48.48,47.90,49.14,45.11,44.02,44.61,44.26,44.79,48.30,43.92,55.63,42.81,52.40,52.10,46.11,48.69,46.03,47.66,50.88,42.60,49.94,44.72,42.89,50.99,42.35,47.10,41.96,49.26,51.00,44.12,43.89,51.78,48.52,44.07,51.08,47.06,47.04,44.79,48.69,48.47,49.14,51.40,41.80,48.63,43.05,42.45,51.18,40.55,44.74,47.57,48.25,52.11,45.13,43.93,49.19,50.07,47.36,49.10,47.98,50.16,44.50,41.47,42.62,47.62,49.80,47.58,53.42,48.04,44.20,46.65,55.22,46.16,46.43,45.86,48.66,47.38,42.76,47.73,46.22,47.36,44.05,55.21,49.34,42.35,50.27,47.16,39.31,45.43,44.25,40.66,45.56,46.49,44.64,40.57,49.84,47.03,50.87,48.01,55.96,43.37,47.14,43.94,46.76,48.94,50.71,48.81,50.87,50.95,42.81,59.63,43.41,43.31,42.24,42.86,43.37,45.65,53.29,54.23,49.35,50.93,48.51,46.55,52.51,50.55,46.29,53.36,47.39,57.79,45.39,45.96,42.37,43.38,45.58,45.92,42.93,44.21,47.04,52.87,43.61,48.78,45.40,47.69,48.88,43.73,57.38,52.19,48.61,50.26,49.08,47.32,52.22,50.09,49.84,42.05,48.49,51.24,41.83,48.24,49.55,55.71,55.58,47.85,42.57,55.66,45.18,43.65,42.75,49.97,50.98,52.11,51.08,48.09,41.19,45.47,42.90,49.71,50.76,48.98,45.08,51.79,47.56,45.81,48.06,45.65,49.08,49.58,40.65,45.19,47.70,40.02,47.98,46.21,43.90,40.06,45.41,48.26,54.24,50.09,45.39,52.57,40.32,43.96,48.39,48.44,47.78,47.41,46.94,47.19,43.43,48.80,49.12,47.26,43.09,42.66,42.51,46.76,49.75,46.32,50.84,46.55,45.63,43.44,50.95,40.74,51.79,45.14,44.74,42.51,49.92,53.01,52.69,48.04,48.95,45.36,52.13,46.86,45.28,47.01,44.09,45.50,44.66,44.10,45.87,43.20,47.18,47.81,46.38,44.04,52.16,46.49,49.34,44.19,46.38,46.66,55.72,45.68,48.51,45.17,55.50,49.75,47.70,44.71,47.33,44.03,46.87,48.23,46.73,46.67,46.15,41.88,49.51,51.08,52.92,50.57,44.29,48.20,44.81,49.53,46.56,42.92,43.95,46.83,47.70,46.21,48.94,53.46,53.19,44.59,44.14,45.40,55.27,50.58,51.30,49.73,47.52,45.86,47.38,53.08,40.60,40.86,42.92,46.29,42.78,40.56,44.47,51.68,40.85,43.80,47.46,50.65,56.62,45.66,48.58,48.18,47.27,54.90,49.09,46.68,47.67,46.89,42.79,52.43,42.92,49.87,48.56,45.98,42.43,48.53,45.01,50.42,47.14,46.82,49.51,44.00,46.71,52.74,45.38,46.07,50.95,40.83,45.08,49.28,43.91,44.51,43.77,49.60,45.73,54.53,42.78,45.10,44.73,44.67,43.98,42.27,46.33,43.50,46.11,44.25,46.04,48.06,48.54,45.84,44.27,50.25,45.15,46.03,47.27,47.38,45.36,41.57,44.37,50.17,43.54,51.27,40.64,42.07,43.01,46.71,46.33,45.20,42.99,43.42,51.55,45.20,49.31,46.31,43.03,47.95,44.97,48.78,52.54,47.17,50.73,49.28,50.07,48.31,48.78,44.40,47.33,48.43,42.20,52.69,44.56,47.04,47.60,47.90,49.03,51.23,47.95,46.25,48.32,58.12,42.63,54.46,53.45,46.81,41.54,47.22,47.58,47.63,49.11,46.83,48.29,46.86,48.13,54.07,51.84,45.74,48.26,49.91,47.95,55.39,49.47,46.87,41.45,41.91,47.46,49.90,43.61,46.04,41.67,46.09,48.53,50.78,44.89,51.66,52.16,52.79,42.98,43.59,50.48,48.02,48.01,47.90,47.37,46.59,48.95,43.68,48.28,41.90,51.15,44.39,46.51,46.04,48.83,44.77,45.59,50.67,45.90,42.82,44.25,45.87,46.86,44.64,44.62,46.96,48.41,48.02,43.67,47.90,47.08,41.03,48.90,47.32,45.68,45.98,47.08,42.41,47.39,42.28,43.64,52.67,52.07,45.24,45.20,46.44,48.53,45.46,44.54,45.36,44.92,57.06,45.28,49.05,48.06,46.65,49.18,47.19,44.58,57.28,42.56,50.57,44.20,45.70,43.85,50.10,45.06,45.92,46.41,46.85,49.27,53.31,49.15,46.95,46.88,45.16,48.72,43.68,46.48,48.78,46.99,49.45,43.64,54.08,45.67,51.13,46.17,51.41,48.56,47.75,40.68,49.44,53.18,45.95,43.06,44.73,40.78,48.13,46.85,50.87,43.68,49.06,52.22,48.72,44.32,41.74,47.25,50.96,42.78,45.59,47.51,51.77,44.64,47.01,47.17,43.66,45.84,47.91,49.41,47.35,39.77,46.96,45.55,44.77,45.04,55.05,46.10,48.29,48.74,47.15,44.51,45.76,48.48,45.70,52.32,47.28,39.73,45.94,47.06,42.44,51.15,43.67,48.81,53.20,46.44,44.56,51.23,43.11,42.42,43.52,49.20,45.81,48.34,47.88,43.50,46.41,47.73,49.35,41.55,43.13,56.30,43.28,42.62,45.46,42.78,48.99,50.26,47.45,49.24,44.91,42.33,42.29,47.68,54.45,42.16,46.11,41.71,44.97,41.66,50.33,51.02,48.47,45.76,50.78,43.93,45.72,46.13,44.38,43.94,45.17,52.88,50.82,44.87,47.70,46.58,49.77,45.90,48.15,51.15,44.84,48.00,47.95,55.86,42.80,46.88,48.92,50.82,48.90,46.29,43.91,51.13,50.11,45.34,40.73,39.56,54.39,49.10,50.70,53.99,47.01,53.07,50.85,50.07,51.06,50.34,52.76,55.15,54.12,46.40,45.99,43.87,45.12,48.04,45.14,48.21,48.04,44.18,48.25,45.94,44.89,48.73,43.18,45.16,43.10,50.39,45.63,46.05,44.29,53.72,47.52,42.68,51.51,48.06,52.15,52.34,47.70,43.98,43.43,50.33,44.23,45.13,41.50,48.97,55.62,40.86,40.12,50.09,46.60,44.39,52.28,51.18,44.18,48.49,51.05,43.13,45.06,46.50,46.68,47.84,43.96,50.14,42.66,47.05,49.22,46.19,48.90,53.55,49.44,50.32,44.92,49.78,50.77,42.98,48.21,44.81,43.61,44.71,50.43,61.30,44.38,44.45,45.93,45.01,52.03,43.10,41.93,44.99,41.78,44.52,48.26,45.42,40.70,43.38,47.14,46.00,45.04,43.41,45.46,42.70,48.68,47.71,55.66,51.10,40.49,52.36,47.78,48.31,49.94,45.27,53.37,49.11,54.07,44.59,45.31,47.19,44.99,47.15,49.16,47.26,42.72,49.54,45.72,44.20,48.49,43.59,43.57,48.17,46.08,45.18,48.68,45.99,55.14,49.66,45.00,45.27,52.23,49.81,47.54,51.82,44.52,42.99,50.65,50.53,45.14,45.45,47.53,48.40,47.48,47.82,47.13,43.98,42.01,51.36,43.57,51.80,45.66,46.33,46.68,43.18,45.11,48.49,47.96,46.95,46.33,45.14,54.21,44.18,51.51,46.47,42.40,44.27,49.55,48.08,46.99,46.09,41.13,53.57,45.42,51.57,46.44,47.18,46.71,43.83,42.59,46.30,40.96,47.71,42.64,40.44,47.52,42.91,42.45,45.58,47.91,42.51,43.41,47.29,41.94,47.02,43.70,47.20,47.77,44.85,44.89,49.63,43.02,40.91,42.45,47.18,47.63,47.81,46.73,44.42,46.33,49.11,47.18,45.17,42.90,47.34,46.66,50.45,48.33,45.37,43.71,41.06,49.32,48.09,42.72,50.26,45.50,43.59,40.57,45.62,45.24,49.52,46.01,42.88,47.20,43.03,44.88,45.94,55.76,41.03,44.72,50.40,46.19,54.52,44.38,45.33,44.69,51.22,49.64,51.79,44.32,44.16,48.37,52.38,49.02,46.65,55.93,47.11,48.14,47.39,51.67,47.32,47.73,49.52,54.02,45.20,43.69,48.68,47.81,48.66,50.10
2023-07-16 20:07:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: start from epoch 0, loss = 46.9887
2023-07-16 20:07:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-16 20:08:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 9.43e+03 batches (snr_loss = -1.46)...
2023-07-16 20:08:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 9.43e+03 batches (ce_loss = +6.99)...
2023-07-16 20:08:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 9.43e+03 batches (mae_loss = +0.11)...
2023-07-16 20:08:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 9.43e+03 batches (loss = +2.15)...
2023-07-16 20:08:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 9.43e+03 batches (norm = +8.08)...
2023-07-16 20:08:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 9.43e+03 batches (snr_loss = -3.02)...
2023-07-16 20:08:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 9.43e+03 batches (ce_loss = +5.90)...
2023-07-16 20:08:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 9.43e+03 batches (mae_loss = +0.08)...
2023-07-16 20:08:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 9.43e+03 batches (loss = +0.01)...
2023-07-16 20:08:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 9.43e+03 batches (norm = +5.55)...
2023-07-16 20:09:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 9.43e+03 batches (snr_loss = -3.18)...
2023-07-16 20:09:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 9.43e+03 batches (ce_loss = +5.25)...
2023-07-16 20:09:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 9.43e+03 batches (mae_loss = +0.07)...
2023-07-16 20:09:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 9.43e+03 batches (loss = -0.49)...
2023-07-16 20:09:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 9.43e+03 batches (norm = +3.23)...
2023-07-16 20:09:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 9.43e+03 batches (snr_loss = -3.08)...
2023-07-16 20:09:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 9.43e+03 batches (ce_loss = +4.97)...
2023-07-16 20:09:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 9.43e+03 batches (mae_loss = +0.05)...
2023-07-16 20:09:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 9.43e+03 batches (loss = -0.54)...
2023-07-16 20:09:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 9.43e+03 batches (norm = +5.72)...
2023-07-16 20:10:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 9.43e+03 batches (snr_loss = -3.32)...
2023-07-16 20:10:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 9.43e+03 batches (ce_loss = +4.87)...
2023-07-16 20:10:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 9.43e+03 batches (mae_loss = +0.05)...
2023-07-16 20:10:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 9.43e+03 batches (loss = -0.84)...
2023-07-16 20:10:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 9.43e+03 batches (norm = +8.90)...
2023-07-16 20:10:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 9.43e+03 batches (snr_loss = -3.13)...
2023-07-16 20:10:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 9.43e+03 batches (ce_loss = +4.81)...
2023-07-16 20:10:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 9.43e+03 batches (mae_loss = +0.05)...
2023-07-16 20:10:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 9.43e+03 batches (loss = -0.68)...
2023-07-16 20:10:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 9.43e+03 batches (norm = +26.62)...
2023-07-16 20:10:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 9.43e+03 batches (snr_loss = -3.43)...
2023-07-16 20:10:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 9.43e+03 batches (ce_loss = +4.76)...
2023-07-16 20:10:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 9.43e+03 batches (mae_loss = +0.04)...
2023-07-16 20:10:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 9.43e+03 batches (loss = -1.01)...
2023-07-16 20:10:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 9.43e+03 batches (norm = +8.89)...
2023-07-16 20:11:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 9.43e+03 batches (snr_loss = -3.68)...
2023-07-16 20:11:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 9.43e+03 batches (ce_loss = +4.74)...
2023-07-16 20:11:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 9.43e+03 batches (mae_loss = +0.04)...
2023-07-16 20:11:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 9.43e+03 batches (loss = -1.27)...
2023-07-16 20:11:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 9.43e+03 batches (norm = +6.26)...
2023-07-16 20:11:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 9.43e+03 batches (snr_loss = -3.61)...
2023-07-16 20:11:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 9.43e+03 batches (ce_loss = +4.70)...
2023-07-16 20:11:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 9.43e+03 batches (mae_loss = +0.04)...
2023-07-16 20:11:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 9.43e+03 batches (loss = -1.23)...
2023-07-16 20:11:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 9.43e+03 batches (norm = +5.87)...
2023-07-16 20:12:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 9.43e+03 batches (snr_loss = -3.47)...
2023-07-16 20:12:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 9.43e+03 batches (ce_loss = +4.68)...
2023-07-16 20:12:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 9.43e+03 batches (mae_loss = +0.04)...
2023-07-16 20:12:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 9.43e+03 batches (loss = -1.10)...
2023-07-16 20:12:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 9.43e+03 batches (norm = +9.02)...
2023-07-16 20:12:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 9.43e+03 batches (snr_loss = -3.38)...
2023-07-16 20:12:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 9.43e+03 batches (ce_loss = +4.68)...
2023-07-16 20:12:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:12:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 9.43e+03 batches (loss = -1.01)...
2023-07-16 20:12:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 9.43e+03 batches (norm = +9.03)...
2023-07-16 20:13:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.20e+03 / 9.43e+03 batches (snr_loss = -3.67)...
2023-07-16 20:13:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.20e+03 / 9.43e+03 batches (ce_loss = +4.65)...
2023-07-16 20:13:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.20e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:13:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.20e+03 / 9.43e+03 batches (loss = -1.31)...
2023-07-16 20:13:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.20e+03 / 9.43e+03 batches (norm = +7.04)...
2023-07-16 20:13:53 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.30e+03 / 9.43e+03 batches (snr_loss = -3.70)...
2023-07-16 20:13:53 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.30e+03 / 9.43e+03 batches (ce_loss = +4.63)...
2023-07-16 20:13:53 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.30e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:13:53 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.30e+03 / 9.43e+03 batches (loss = -1.35)...
2023-07-16 20:13:53 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.30e+03 / 9.43e+03 batches (norm = +7.83)...
2023-07-16 20:14:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.40e+03 / 9.43e+03 batches (snr_loss = -3.19)...
2023-07-16 20:14:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.40e+03 / 9.43e+03 batches (ce_loss = +4.63)...
2023-07-16 20:14:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.40e+03 / 9.43e+03 batches (mae_loss = +0.04)...
2023-07-16 20:14:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.40e+03 / 9.43e+03 batches (loss = -0.84)...
2023-07-16 20:14:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.40e+03 / 9.43e+03 batches (norm = +11.00)...
2023-07-16 20:14:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.50e+03 / 9.43e+03 batches (snr_loss = -3.21)...
2023-07-16 20:14:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.50e+03 / 9.43e+03 batches (ce_loss = +4.62)...
2023-07-16 20:14:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.50e+03 / 9.43e+03 batches (mae_loss = +0.04)...
2023-07-16 20:14:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.50e+03 / 9.43e+03 batches (loss = -0.87)...
2023-07-16 20:14:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.50e+03 / 9.43e+03 batches (norm = +9.22)...
2023-07-16 20:15:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.60e+03 / 9.43e+03 batches (snr_loss = -3.55)...
2023-07-16 20:15:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.60e+03 / 9.43e+03 batches (ce_loss = +4.62)...
2023-07-16 20:15:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.60e+03 / 9.43e+03 batches (mae_loss = +0.04)...
2023-07-16 20:15:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.60e+03 / 9.43e+03 batches (loss = -1.20)...
2023-07-16 20:15:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.60e+03 / 9.43e+03 batches (norm = +16.90)...
2023-07-16 20:15:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.70e+03 / 9.43e+03 batches (snr_loss = -3.84)...
2023-07-16 20:15:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.70e+03 / 9.43e+03 batches (ce_loss = +4.59)...
2023-07-16 20:15:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.70e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:15:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.70e+03 / 9.43e+03 batches (loss = -1.51)...
2023-07-16 20:15:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.70e+03 / 9.43e+03 batches (norm = +9.02)...
2023-07-16 20:16:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.80e+03 / 9.43e+03 batches (snr_loss = -3.63)...
2023-07-16 20:16:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.80e+03 / 9.43e+03 batches (ce_loss = +4.59)...
2023-07-16 20:16:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.80e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:16:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.80e+03 / 9.43e+03 batches (loss = -1.31)...
2023-07-16 20:16:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.80e+03 / 9.43e+03 batches (norm = +14.92)...
2023-07-16 20:16:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.90e+03 / 9.43e+03 batches (snr_loss = -3.27)...
2023-07-16 20:16:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.90e+03 / 9.43e+03 batches (ce_loss = +4.58)...
2023-07-16 20:16:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.90e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:16:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.90e+03 / 9.43e+03 batches (loss = -0.95)...
2023-07-16 20:16:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.90e+03 / 9.43e+03 batches (norm = +7.22)...
2023-07-16 20:17:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+03 / 9.43e+03 batches (snr_loss = -3.48)...
2023-07-16 20:17:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+03 / 9.43e+03 batches (ce_loss = +4.54)...
2023-07-16 20:17:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:17:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+03 / 9.43e+03 batches (loss = -1.18)...
2023-07-16 20:17:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+03 / 9.43e+03 batches (norm = +7.87)...
2023-07-16 20:17:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.10e+03 / 9.43e+03 batches (snr_loss = -3.48)...
2023-07-16 20:17:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.10e+03 / 9.43e+03 batches (ce_loss = +4.53)...
2023-07-16 20:17:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.10e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:17:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.10e+03 / 9.43e+03 batches (loss = -1.18)...
2023-07-16 20:17:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.10e+03 / 9.43e+03 batches (norm = +12.41)...
2023-07-16 20:18:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.20e+03 / 9.43e+03 batches (snr_loss = -3.68)...
2023-07-16 20:18:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.20e+03 / 9.43e+03 batches (ce_loss = +4.51)...
2023-07-16 20:18:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.20e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:18:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.20e+03 / 9.43e+03 batches (loss = -1.39)...
2023-07-16 20:18:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.20e+03 / 9.43e+03 batches (norm = +10.95)...
2023-07-16 20:19:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.30e+03 / 9.43e+03 batches (snr_loss = -4.03)...
2023-07-16 20:19:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.30e+03 / 9.43e+03 batches (ce_loss = +4.49)...
2023-07-16 20:19:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.30e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:19:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.30e+03 / 9.43e+03 batches (loss = -1.75)...
2023-07-16 20:19:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.30e+03 / 9.43e+03 batches (norm = +8.72)...
2023-07-16 20:19:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.40e+03 / 9.43e+03 batches (snr_loss = -3.33)...
2023-07-16 20:19:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.40e+03 / 9.43e+03 batches (ce_loss = +4.48)...
2023-07-16 20:19:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.40e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:19:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.40e+03 / 9.43e+03 batches (loss = -1.06)...
2023-07-16 20:19:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.40e+03 / 9.43e+03 batches (norm = +10.26)...
2023-07-16 20:20:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.50e+03 / 9.43e+03 batches (snr_loss = -4.33)...
2023-07-16 20:20:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.50e+03 / 9.43e+03 batches (ce_loss = +4.46)...
2023-07-16 20:20:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.50e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:20:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.50e+03 / 9.43e+03 batches (loss = -2.07)...
2023-07-16 20:20:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.50e+03 / 9.43e+03 batches (norm = +10.79)...
2023-07-16 20:20:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.60e+03 / 9.43e+03 batches (snr_loss = -3.73)...
2023-07-16 20:20:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.60e+03 / 9.43e+03 batches (ce_loss = +4.49)...
2023-07-16 20:20:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.60e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:20:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.60e+03 / 9.43e+03 batches (loss = -1.45)...
2023-07-16 20:20:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.60e+03 / 9.43e+03 batches (norm = +25.43)...
2023-07-16 20:21:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.70e+03 / 9.43e+03 batches (snr_loss = -3.98)...
2023-07-16 20:21:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.70e+03 / 9.43e+03 batches (ce_loss = +4.46)...
2023-07-16 20:21:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.70e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:21:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.70e+03 / 9.43e+03 batches (loss = -1.72)...
2023-07-16 20:21:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.70e+03 / 9.43e+03 batches (norm = +11.11)...
2023-07-16 20:21:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.80e+03 / 9.43e+03 batches (snr_loss = -3.66)...
2023-07-16 20:21:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.80e+03 / 9.43e+03 batches (ce_loss = +4.45)...
2023-07-16 20:21:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.80e+03 / 9.43e+03 batches (mae_loss = +0.04)...
2023-07-16 20:21:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.80e+03 / 9.43e+03 batches (loss = -1.40)...
2023-07-16 20:21:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.80e+03 / 9.43e+03 batches (norm = +10.66)...
2023-07-16 20:22:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.90e+03 / 9.43e+03 batches (snr_loss = -3.38)...
2023-07-16 20:22:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.90e+03 / 9.43e+03 batches (ce_loss = +4.43)...
2023-07-16 20:22:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.90e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:22:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.90e+03 / 9.43e+03 batches (loss = -1.13)...
2023-07-16 20:22:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.90e+03 / 9.43e+03 batches (norm = +8.77)...
2023-07-16 20:22:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+03 / 9.43e+03 batches (snr_loss = -3.84)...
2023-07-16 20:22:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+03 / 9.43e+03 batches (ce_loss = +4.42)...
2023-07-16 20:22:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:22:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+03 / 9.43e+03 batches (loss = -1.60)...
2023-07-16 20:22:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+03 / 9.43e+03 batches (norm = +13.50)...
2023-07-16 20:23:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.10e+03 / 9.43e+03 batches (snr_loss = -3.63)...
2023-07-16 20:23:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.10e+03 / 9.43e+03 batches (ce_loss = +4.41)...
2023-07-16 20:23:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.10e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:23:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.10e+03 / 9.43e+03 batches (loss = -1.39)...
2023-07-16 20:23:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.10e+03 / 9.43e+03 batches (norm = +10.24)...
2023-07-16 20:23:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.20e+03 / 9.43e+03 batches (snr_loss = -3.89)...
2023-07-16 20:23:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.20e+03 / 9.43e+03 batches (ce_loss = +4.41)...
2023-07-16 20:23:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.20e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:23:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.20e+03 / 9.43e+03 batches (loss = -1.65)...
2023-07-16 20:23:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.20e+03 / 9.43e+03 batches (norm = +13.88)...
2023-07-16 20:24:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.30e+03 / 9.43e+03 batches (snr_loss = -3.59)...
2023-07-16 20:24:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.30e+03 / 9.43e+03 batches (ce_loss = +4.41)...
2023-07-16 20:24:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.30e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:24:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.30e+03 / 9.43e+03 batches (loss = -1.35)...
2023-07-16 20:24:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.30e+03 / 9.43e+03 batches (norm = +10.38)...
2023-07-16 20:24:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.40e+03 / 9.43e+03 batches (snr_loss = -4.07)...
2023-07-16 20:24:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.40e+03 / 9.43e+03 batches (ce_loss = +4.36)...
2023-07-16 20:24:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.40e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:24:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.40e+03 / 9.43e+03 batches (loss = -1.86)...
2023-07-16 20:24:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.40e+03 / 9.43e+03 batches (norm = +9.83)...
2023-07-16 20:24:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.50e+03 / 9.43e+03 batches (snr_loss = -3.69)...
2023-07-16 20:24:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.50e+03 / 9.43e+03 batches (ce_loss = +4.36)...
2023-07-16 20:24:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.50e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:24:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.50e+03 / 9.43e+03 batches (loss = -1.48)...
2023-07-16 20:24:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.50e+03 / 9.43e+03 batches (norm = +16.12)...
2023-07-16 20:25:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.60e+03 / 9.43e+03 batches (snr_loss = -4.10)...
2023-07-16 20:25:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.60e+03 / 9.43e+03 batches (ce_loss = +4.34)...
2023-07-16 20:25:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.60e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:25:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.60e+03 / 9.43e+03 batches (loss = -1.90)...
2023-07-16 20:25:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.60e+03 / 9.43e+03 batches (norm = +11.07)...
2023-07-16 20:25:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.70e+03 / 9.43e+03 batches (snr_loss = -3.83)...
2023-07-16 20:25:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.70e+03 / 9.43e+03 batches (ce_loss = +4.33)...
2023-07-16 20:25:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.70e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:25:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.70e+03 / 9.43e+03 batches (loss = -1.64)...
2023-07-16 20:25:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.70e+03 / 9.43e+03 batches (norm = +7.96)...
2023-07-16 20:26:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.80e+03 / 9.43e+03 batches (snr_loss = -3.92)...
2023-07-16 20:26:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.80e+03 / 9.43e+03 batches (ce_loss = +4.33)...
2023-07-16 20:26:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.80e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:26:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.80e+03 / 9.43e+03 batches (loss = -1.73)...
2023-07-16 20:26:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.80e+03 / 9.43e+03 batches (norm = +10.02)...
2023-07-16 20:26:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.90e+03 / 9.43e+03 batches (snr_loss = -3.83)...
2023-07-16 20:26:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.90e+03 / 9.43e+03 batches (ce_loss = +4.30)...
2023-07-16 20:26:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.90e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:26:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.90e+03 / 9.43e+03 batches (loss = -1.64)...
2023-07-16 20:26:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.90e+03 / 9.43e+03 batches (norm = +8.32)...
2023-07-16 20:27:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+03 / 9.43e+03 batches (snr_loss = -3.32)...
2023-07-16 20:27:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+03 / 9.43e+03 batches (ce_loss = +4.31)...
2023-07-16 20:27:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:27:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+03 / 9.43e+03 batches (loss = -1.13)...
2023-07-16 20:27:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+03 / 9.43e+03 batches (norm = +9.41)...
2023-07-16 20:27:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.10e+03 / 9.43e+03 batches (snr_loss = -3.87)...
2023-07-16 20:27:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.10e+03 / 9.43e+03 batches (ce_loss = +4.29)...
2023-07-16 20:27:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.10e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:27:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.10e+03 / 9.43e+03 batches (loss = -1.70)...
2023-07-16 20:27:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.10e+03 / 9.43e+03 batches (norm = +10.81)...
2023-07-16 20:28:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.20e+03 / 9.43e+03 batches (snr_loss = -3.52)...
2023-07-16 20:28:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.20e+03 / 9.43e+03 batches (ce_loss = +4.28)...
2023-07-16 20:28:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.20e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:28:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.20e+03 / 9.43e+03 batches (loss = -1.35)...
2023-07-16 20:28:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.20e+03 / 9.43e+03 batches (norm = +6.52)...
2023-07-16 20:28:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.30e+03 / 9.43e+03 batches (snr_loss = -3.90)...
2023-07-16 20:28:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.30e+03 / 9.43e+03 batches (ce_loss = +4.29)...
2023-07-16 20:28:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.30e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:28:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.30e+03 / 9.43e+03 batches (loss = -1.73)...
2023-07-16 20:28:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.30e+03 / 9.43e+03 batches (norm = +13.36)...
2023-07-16 20:28:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.40e+03 / 9.43e+03 batches (snr_loss = -3.87)...
2023-07-16 20:28:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.40e+03 / 9.43e+03 batches (ce_loss = +4.26)...
2023-07-16 20:28:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.40e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:28:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.40e+03 / 9.43e+03 batches (loss = -1.71)...
2023-07-16 20:28:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.40e+03 / 9.43e+03 batches (norm = +11.04)...
2023-07-16 20:29:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.50e+03 / 9.43e+03 batches (snr_loss = -3.66)...
2023-07-16 20:29:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.50e+03 / 9.43e+03 batches (ce_loss = +4.24)...
2023-07-16 20:29:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.50e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:29:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.50e+03 / 9.43e+03 batches (loss = -1.51)...
2023-07-16 20:29:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.50e+03 / 9.43e+03 batches (norm = +9.14)...
2023-07-16 20:29:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.60e+03 / 9.43e+03 batches (snr_loss = -3.88)...
2023-07-16 20:29:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.60e+03 / 9.43e+03 batches (ce_loss = +4.25)...
2023-07-16 20:29:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.60e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:29:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.60e+03 / 9.43e+03 batches (loss = -1.73)...
2023-07-16 20:29:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.60e+03 / 9.43e+03 batches (norm = +239.84)...
2023-07-16 20:30:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.70e+03 / 9.43e+03 batches (snr_loss = -3.52)...
2023-07-16 20:30:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.70e+03 / 9.43e+03 batches (ce_loss = +4.21)...
2023-07-16 20:30:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.70e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:30:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.70e+03 / 9.43e+03 batches (loss = -1.39)...
2023-07-16 20:30:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.70e+03 / 9.43e+03 batches (norm = +9.36)...
2023-07-16 20:30:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.80e+03 / 9.43e+03 batches (snr_loss = -3.93)...
2023-07-16 20:30:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.80e+03 / 9.43e+03 batches (ce_loss = +4.24)...
2023-07-16 20:30:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.80e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:30:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.80e+03 / 9.43e+03 batches (loss = -1.77)...
2023-07-16 20:30:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.80e+03 / 9.43e+03 batches (norm = +8.82)...
2023-07-16 20:31:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.90e+03 / 9.43e+03 batches (snr_loss = -4.03)...
2023-07-16 20:31:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.90e+03 / 9.43e+03 batches (ce_loss = +4.20)...
2023-07-16 20:31:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.90e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:31:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.90e+03 / 9.43e+03 batches (loss = -1.90)...
2023-07-16 20:31:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.90e+03 / 9.43e+03 batches (norm = +7.91)...
2023-07-16 20:31:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+03 / 9.43e+03 batches (snr_loss = -3.86)...
2023-07-16 20:31:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+03 / 9.43e+03 batches (ce_loss = +4.21)...
2023-07-16 20:31:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:31:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+03 / 9.43e+03 batches (loss = -1.72)...
2023-07-16 20:31:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+03 / 9.43e+03 batches (norm = +8.25)...
2023-07-16 20:32:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.10e+03 / 9.43e+03 batches (snr_loss = -3.95)...
2023-07-16 20:32:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.10e+03 / 9.43e+03 batches (ce_loss = +4.21)...
2023-07-16 20:32:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.10e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:32:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.10e+03 / 9.43e+03 batches (loss = -1.81)...
2023-07-16 20:32:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.10e+03 / 9.43e+03 batches (norm = +12.61)...
2023-07-16 20:32:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.20e+03 / 9.43e+03 batches (snr_loss = -3.90)...
2023-07-16 20:32:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.20e+03 / 9.43e+03 batches (ce_loss = +4.24)...
2023-07-16 20:32:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.20e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:32:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.20e+03 / 9.43e+03 batches (loss = -1.75)...
2023-07-16 20:32:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.20e+03 / 9.43e+03 batches (norm = +12.66)...
2023-07-16 20:33:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.30e+03 / 9.43e+03 batches (snr_loss = -4.37)...
2023-07-16 20:33:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.30e+03 / 9.43e+03 batches (ce_loss = +4.16)...
2023-07-16 20:33:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.30e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:33:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.30e+03 / 9.43e+03 batches (loss = -2.26)...
2023-07-16 20:33:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.30e+03 / 9.43e+03 batches (norm = +15.08)...
2023-07-16 20:33:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.40e+03 / 9.43e+03 batches (snr_loss = -4.12)...
2023-07-16 20:33:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.40e+03 / 9.43e+03 batches (ce_loss = +4.22)...
2023-07-16 20:33:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.40e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:33:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.40e+03 / 9.43e+03 batches (loss = -1.98)...
2023-07-16 20:33:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.40e+03 / 9.43e+03 batches (norm = +12.45)...
2023-07-16 20:34:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.50e+03 / 9.43e+03 batches (snr_loss = -3.60)...
2023-07-16 20:34:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.50e+03 / 9.43e+03 batches (ce_loss = +4.16)...
2023-07-16 20:34:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.50e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:34:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.50e+03 / 9.43e+03 batches (loss = -1.49)...
2023-07-16 20:34:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.50e+03 / 9.43e+03 batches (norm = +9.48)...
2023-07-16 20:34:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.60e+03 / 9.43e+03 batches (snr_loss = -4.27)...
2023-07-16 20:34:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.60e+03 / 9.43e+03 batches (ce_loss = +4.17)...
2023-07-16 20:34:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.60e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:34:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.60e+03 / 9.43e+03 batches (loss = -2.16)...
2023-07-16 20:34:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.60e+03 / 9.43e+03 batches (norm = +12.32)...
2023-07-16 20:35:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.70e+03 / 9.43e+03 batches (snr_loss = -3.83)...
2023-07-16 20:35:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.70e+03 / 9.43e+03 batches (ce_loss = +4.15)...
2023-07-16 20:35:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.70e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:35:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.70e+03 / 9.43e+03 batches (loss = -1.72)...
2023-07-16 20:35:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.70e+03 / 9.43e+03 batches (norm = +11.63)...
2023-07-16 20:35:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.80e+03 / 9.43e+03 batches (snr_loss = -4.24)...
2023-07-16 20:35:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.80e+03 / 9.43e+03 batches (ce_loss = +4.17)...
2023-07-16 20:35:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.80e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:35:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.80e+03 / 9.43e+03 batches (loss = -2.13)...
2023-07-16 20:35:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.80e+03 / 9.43e+03 batches (norm = +10.98)...
2023-07-16 20:35:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.90e+03 / 9.43e+03 batches (snr_loss = -4.14)...
2023-07-16 20:35:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.90e+03 / 9.43e+03 batches (ce_loss = +4.13)...
2023-07-16 20:36:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.90e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:36:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.90e+03 / 9.43e+03 batches (loss = -2.04)...
2023-07-16 20:36:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.90e+03 / 9.43e+03 batches (norm = +8.80)...
2023-07-16 20:36:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+03 / 9.43e+03 batches (snr_loss = -3.78)...
2023-07-16 20:36:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+03 / 9.43e+03 batches (ce_loss = +4.12)...
2023-07-16 20:36:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:36:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+03 / 9.43e+03 batches (loss = -1.69)...
2023-07-16 20:36:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+03 / 9.43e+03 batches (norm = +9.41)...
2023-07-16 20:36:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.10e+03 / 9.43e+03 batches (snr_loss = -4.68)...
2023-07-16 20:36:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.10e+03 / 9.43e+03 batches (ce_loss = +4.10)...
2023-07-16 20:36:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.10e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:36:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.10e+03 / 9.43e+03 batches (loss = -2.60)...
2023-07-16 20:36:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.10e+03 / 9.43e+03 batches (norm = +10.94)...
2023-07-16 20:37:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.20e+03 / 9.43e+03 batches (snr_loss = -3.53)...
2023-07-16 20:37:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.20e+03 / 9.43e+03 batches (ce_loss = +4.12)...
2023-07-16 20:37:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.20e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:37:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.20e+03 / 9.43e+03 batches (loss = -1.44)...
2023-07-16 20:37:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.20e+03 / 9.43e+03 batches (norm = +9.55)...
2023-07-16 20:37:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.30e+03 / 9.43e+03 batches (snr_loss = -3.95)...
2023-07-16 20:37:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.30e+03 / 9.43e+03 batches (ce_loss = +4.11)...
2023-07-16 20:37:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.30e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:37:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.30e+03 / 9.43e+03 batches (loss = -1.86)...
2023-07-16 20:37:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.30e+03 / 9.43e+03 batches (norm = +12.39)...
2023-07-16 20:38:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.40e+03 / 9.43e+03 batches (snr_loss = -4.19)...
2023-07-16 20:38:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.40e+03 / 9.43e+03 batches (ce_loss = +4.10)...
2023-07-16 20:38:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.40e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:38:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.40e+03 / 9.43e+03 batches (loss = -2.12)...
2023-07-16 20:38:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.40e+03 / 9.43e+03 batches (norm = +19.31)...
2023-07-16 20:38:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.50e+03 / 9.43e+03 batches (snr_loss = -4.55)...
2023-07-16 20:38:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.50e+03 / 9.43e+03 batches (ce_loss = +4.08)...
2023-07-16 20:38:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.50e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:38:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.50e+03 / 9.43e+03 batches (loss = -2.48)...
2023-07-16 20:38:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.50e+03 / 9.43e+03 batches (norm = +16.07)...
2023-07-16 20:39:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.60e+03 / 9.43e+03 batches (snr_loss = -4.17)...
2023-07-16 20:39:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.60e+03 / 9.43e+03 batches (ce_loss = +4.10)...
2023-07-16 20:39:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.60e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:39:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.60e+03 / 9.43e+03 batches (loss = -2.08)...
2023-07-16 20:39:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.60e+03 / 9.43e+03 batches (norm = +9.96)...
2023-07-16 20:39:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.70e+03 / 9.43e+03 batches (snr_loss = -4.17)...
2023-07-16 20:39:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.70e+03 / 9.43e+03 batches (ce_loss = +4.05)...
2023-07-16 20:39:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.70e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:39:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.70e+03 / 9.43e+03 batches (loss = -2.12)...
2023-07-16 20:39:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.70e+03 / 9.43e+03 batches (norm = +9.77)...
2023-07-16 20:40:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.80e+03 / 9.43e+03 batches (snr_loss = -3.83)...
2023-07-16 20:40:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.80e+03 / 9.43e+03 batches (ce_loss = +4.05)...
2023-07-16 20:40:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.80e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:40:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.80e+03 / 9.43e+03 batches (loss = -1.77)...
2023-07-16 20:40:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.80e+03 / 9.43e+03 batches (norm = +11.80)...
2023-07-16 20:40:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.90e+03 / 9.43e+03 batches (snr_loss = -3.47)...
2023-07-16 20:40:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.90e+03 / 9.43e+03 batches (ce_loss = +4.05)...
2023-07-16 20:40:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.90e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:40:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.90e+03 / 9.43e+03 batches (loss = -1.42)...
2023-07-16 20:40:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.90e+03 / 9.43e+03 batches (norm = +13.28)...
2023-07-16 20:41:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+03 / 9.43e+03 batches (snr_loss = -4.36)...
2023-07-16 20:41:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+03 / 9.43e+03 batches (ce_loss = +4.05)...
2023-07-16 20:41:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:41:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+03 / 9.43e+03 batches (loss = -2.31)...
2023-07-16 20:41:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+03 / 9.43e+03 batches (norm = +11.68)...
2023-07-16 20:41:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.10e+03 / 9.43e+03 batches (snr_loss = -4.30)...
2023-07-16 20:41:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.10e+03 / 9.43e+03 batches (ce_loss = +4.07)...
2023-07-16 20:41:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.10e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:41:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.10e+03 / 9.43e+03 batches (loss = -2.24)...
2023-07-16 20:41:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.10e+03 / 9.43e+03 batches (norm = +15.68)...
2023-07-16 20:42:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.20e+03 / 9.43e+03 batches (snr_loss = -4.52)...
2023-07-16 20:42:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.20e+03 / 9.43e+03 batches (ce_loss = +4.03)...
2023-07-16 20:42:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.20e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:42:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.20e+03 / 9.43e+03 batches (loss = -2.47)...
2023-07-16 20:42:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.20e+03 / 9.43e+03 batches (norm = +13.10)...
2023-07-16 20:42:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.30e+03 / 9.43e+03 batches (snr_loss = -4.18)...
2023-07-16 20:42:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.30e+03 / 9.43e+03 batches (ce_loss = +4.04)...
2023-07-16 20:42:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.30e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:42:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.30e+03 / 9.43e+03 batches (loss = -2.13)...
2023-07-16 20:42:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.30e+03 / 9.43e+03 batches (norm = +15.62)...
2023-07-16 20:43:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.40e+03 / 9.43e+03 batches (snr_loss = -3.64)...
2023-07-16 20:43:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.40e+03 / 9.43e+03 batches (ce_loss = +4.01)...
2023-07-16 20:43:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.40e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:43:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.40e+03 / 9.43e+03 batches (loss = -1.61)...
2023-07-16 20:43:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.40e+03 / 9.43e+03 batches (norm = +8.42)...
2023-07-16 20:43:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.50e+03 / 9.43e+03 batches (snr_loss = -4.10)...
2023-07-16 20:43:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.50e+03 / 9.43e+03 batches (ce_loss = +4.01)...
2023-07-16 20:43:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.50e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:43:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.50e+03 / 9.43e+03 batches (loss = -2.07)...
2023-07-16 20:43:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.50e+03 / 9.43e+03 batches (norm = +9.96)...
2023-07-16 20:44:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.60e+03 / 9.43e+03 batches (snr_loss = -4.21)...
2023-07-16 20:44:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.60e+03 / 9.43e+03 batches (ce_loss = +4.01)...
2023-07-16 20:44:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.60e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:44:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.60e+03 / 9.43e+03 batches (loss = -2.18)...
2023-07-16 20:44:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.60e+03 / 9.43e+03 batches (norm = +9.19)...
2023-07-16 20:44:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.70e+03 / 9.43e+03 batches (snr_loss = -4.60)...
2023-07-16 20:44:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.70e+03 / 9.43e+03 batches (ce_loss = +4.03)...
2023-07-16 20:44:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.70e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:44:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.70e+03 / 9.43e+03 batches (loss = -2.56)...
2023-07-16 20:44:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.70e+03 / 9.43e+03 batches (norm = +14.46)...
2023-07-16 20:45:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.80e+03 / 9.43e+03 batches (snr_loss = -4.43)...
2023-07-16 20:45:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.80e+03 / 9.43e+03 batches (ce_loss = +4.00)...
2023-07-16 20:45:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.80e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:45:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.80e+03 / 9.43e+03 batches (loss = -2.40)...
2023-07-16 20:45:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.80e+03 / 9.43e+03 batches (norm = +11.78)...
2023-07-16 20:45:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.90e+03 / 9.43e+03 batches (snr_loss = -4.44)...
2023-07-16 20:45:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.90e+03 / 9.43e+03 batches (ce_loss = +3.98)...
2023-07-16 20:45:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.90e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:45:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.90e+03 / 9.43e+03 batches (loss = -2.42)...
2023-07-16 20:45:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.90e+03 / 9.43e+03 batches (norm = +10.44)...
2023-07-16 20:46:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+03 / 9.43e+03 batches (snr_loss = -3.98)...
2023-07-16 20:46:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+03 / 9.43e+03 batches (ce_loss = +3.97)...
2023-07-16 20:46:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:46:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+03 / 9.43e+03 batches (loss = -1.96)...
2023-07-16 20:46:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+03 / 9.43e+03 batches (norm = +10.80)...
2023-07-16 20:47:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.10e+03 / 9.43e+03 batches (snr_loss = -4.17)...
2023-07-16 20:47:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.10e+03 / 9.43e+03 batches (ce_loss = +3.97)...
2023-07-16 20:47:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.10e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:47:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.10e+03 / 9.43e+03 batches (loss = -2.15)...
2023-07-16 20:47:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.10e+03 / 9.43e+03 batches (norm = +18.48)...
2023-07-16 20:47:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.20e+03 / 9.43e+03 batches (snr_loss = -4.55)...
2023-07-16 20:47:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.20e+03 / 9.43e+03 batches (ce_loss = +4.01)...
2023-07-16 20:47:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.20e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:47:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.20e+03 / 9.43e+03 batches (loss = -2.52)...
2023-07-16 20:47:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.20e+03 / 9.43e+03 batches (norm = +23.37)...
2023-07-16 20:48:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.30e+03 / 9.43e+03 batches (snr_loss = -4.23)...
2023-07-16 20:48:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.30e+03 / 9.43e+03 batches (ce_loss = +3.93)...
2023-07-16 20:48:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.30e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:48:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.30e+03 / 9.43e+03 batches (loss = -2.23)...
2023-07-16 20:48:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.30e+03 / 9.43e+03 batches (norm = +21.53)...
2023-07-16 20:48:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.40e+03 / 9.43e+03 batches (snr_loss = -4.48)...
2023-07-16 20:48:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.40e+03 / 9.43e+03 batches (ce_loss = +3.97)...
2023-07-16 20:48:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.40e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:48:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.40e+03 / 9.43e+03 batches (loss = -2.47)...
2023-07-16 20:48:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.40e+03 / 9.43e+03 batches (norm = +8.90)...
2023-07-16 20:49:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.50e+03 / 9.43e+03 batches (snr_loss = -3.88)...
2023-07-16 20:49:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.50e+03 / 9.43e+03 batches (ce_loss = +3.89)...
2023-07-16 20:49:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.50e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:49:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.50e+03 / 9.43e+03 batches (loss = -1.90)...
2023-07-16 20:49:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.50e+03 / 9.43e+03 batches (norm = +11.98)...
2023-07-16 20:49:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.60e+03 / 9.43e+03 batches (snr_loss = -3.95)...
2023-07-16 20:49:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.60e+03 / 9.43e+03 batches (ce_loss = +3.92)...
2023-07-16 20:49:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.60e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:49:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.60e+03 / 9.43e+03 batches (loss = -1.96)...
2023-07-16 20:49:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.60e+03 / 9.43e+03 batches (norm = +10.72)...
2023-07-16 20:50:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.70e+03 / 9.43e+03 batches (snr_loss = -3.86)...
2023-07-16 20:50:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.70e+03 / 9.43e+03 batches (ce_loss = +3.94)...
2023-07-16 20:50:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.70e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:50:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.70e+03 / 9.43e+03 batches (loss = -1.86)...
2023-07-16 20:50:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.70e+03 / 9.43e+03 batches (norm = +21.69)...
2023-07-16 20:50:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.80e+03 / 9.43e+03 batches (snr_loss = -3.64)...
2023-07-16 20:50:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.80e+03 / 9.43e+03 batches (ce_loss = +3.93)...
2023-07-16 20:50:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.80e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:50:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.80e+03 / 9.43e+03 batches (loss = -1.64)...
2023-07-16 20:50:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.80e+03 / 9.43e+03 batches (norm = +11.77)...
2023-07-16 20:51:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.90e+03 / 9.43e+03 batches (snr_loss = -4.39)...
2023-07-16 20:51:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.90e+03 / 9.43e+03 batches (ce_loss = +3.90)...
2023-07-16 20:51:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.90e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:51:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.90e+03 / 9.43e+03 batches (loss = -2.42)...
2023-07-16 20:51:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.90e+03 / 9.43e+03 batches (norm = +57.14)...
2023-07-16 20:51:55 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+03 / 9.43e+03 batches (snr_loss = -4.09)...
2023-07-16 20:51:55 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+03 / 9.43e+03 batches (ce_loss = +3.93)...
2023-07-16 20:51:55 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:51:55 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+03 / 9.43e+03 batches (loss = -2.10)...
2023-07-16 20:51:55 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+03 / 9.43e+03 batches (norm = +10.00)...
2023-07-16 20:52:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.10e+03 / 9.43e+03 batches (snr_loss = -4.33)...
2023-07-16 20:52:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.10e+03 / 9.43e+03 batches (ce_loss = +3.90)...
2023-07-16 20:52:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.10e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:52:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.10e+03 / 9.43e+03 batches (loss = -2.35)...
2023-07-16 20:52:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.10e+03 / 9.43e+03 batches (norm = +14.10)...
2023-07-16 20:53:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.20e+03 / 9.43e+03 batches (snr_loss = -4.76)...
2023-07-16 20:53:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.20e+03 / 9.43e+03 batches (ce_loss = +3.92)...
2023-07-16 20:53:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.20e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:53:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.20e+03 / 9.43e+03 batches (loss = -2.77)...
2023-07-16 20:53:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.20e+03 / 9.43e+03 batches (norm = +15.09)...
2023-07-16 20:53:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.30e+03 / 9.43e+03 batches (snr_loss = -4.49)...
2023-07-16 20:53:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.30e+03 / 9.43e+03 batches (ce_loss = +3.90)...
2023-07-16 20:53:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.30e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:53:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.30e+03 / 9.43e+03 batches (loss = -2.51)...
2023-07-16 20:53:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.30e+03 / 9.43e+03 batches (norm = +12.57)...
2023-07-16 20:54:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.40e+03 / 9.43e+03 batches (snr_loss = -3.85)...
2023-07-16 20:54:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.40e+03 / 9.43e+03 batches (ce_loss = +3.88)...
2023-07-16 20:54:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.40e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 20:54:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.40e+03 / 9.43e+03 batches (loss = -1.88)...
2023-07-16 20:54:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.40e+03 / 9.43e+03 batches (norm = +9.51)...
2023-07-16 20:54:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=1.000e-03) - Epoch  1: train = -1.6589(46.47m/9428)
2023-07-16 20:54:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-16 20:54:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 2.29e+03 batches (snr_loss = -4.05)...
2023-07-16 20:54:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-16 20:54:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 20:54:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 2.29e+03 batches (loss = +1.06)...
2023-07-16 20:55:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 2.29e+03 batches (snr_loss = -3.98)...
2023-07-16 20:55:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-16 20:55:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 20:55:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 2.29e+03 batches (loss = +1.13)...
2023-07-16 20:55:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 2.29e+03 batches (snr_loss = -4.51)...
2023-07-16 20:55:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-16 20:55:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 20:55:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 2.29e+03 batches (loss = +0.60)...
2023-07-16 20:55:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 2.29e+03 batches (snr_loss = -4.06)...
2023-07-16 20:55:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-16 20:55:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 20:55:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 2.29e+03 batches (loss = +1.05)...
2023-07-16 20:55:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 2.29e+03 batches (snr_loss = -3.98)...
2023-07-16 20:55:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-16 20:55:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 20:55:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 2.29e+03 batches (loss = +1.13)...
2023-07-16 20:56:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 2.29e+03 batches (snr_loss = -4.23)...
2023-07-16 20:56:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-16 20:56:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 20:56:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 2.29e+03 batches (loss = +0.88)...
2023-07-16 20:56:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 2.29e+03 batches (snr_loss = -4.34)...
2023-07-16 20:56:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-16 20:56:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 20:56:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 2.29e+03 batches (loss = +0.77)...
2023-07-16 20:56:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 2.29e+03 batches (snr_loss = -3.77)...
2023-07-16 20:56:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-16 20:56:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 20:56:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 2.29e+03 batches (loss = +1.34)...
2023-07-16 20:56:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 2.29e+03 batches (snr_loss = -4.56)...
2023-07-16 20:56:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-16 20:56:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 20:56:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 2.29e+03 batches (loss = +0.56)...
2023-07-16 20:57:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 2.29e+03 batches (snr_loss = -4.68)...
2023-07-16 20:57:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-16 20:57:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 20:57:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 2.29e+03 batches (loss = +0.43)...
2023-07-16 20:57:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 2.29e+03 batches (snr_loss = -4.48)...
2023-07-16 20:57:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-16 20:57:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 20:57:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 2.29e+03 batches (loss = +0.63)...
2023-07-16 20:57:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.20e+03 / 2.29e+03 batches (snr_loss = -4.27)...
2023-07-16 20:57:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.20e+03 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-16 20:57:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.20e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 20:57:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.20e+03 / 2.29e+03 batches (loss = +0.84)...
2023-07-16 20:58:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.30e+03 / 2.29e+03 batches (snr_loss = -3.84)...
2023-07-16 20:58:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.30e+03 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-16 20:58:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.30e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 20:58:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.30e+03 / 2.29e+03 batches (loss = +1.28)...
2023-07-16 20:58:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.40e+03 / 2.29e+03 batches (snr_loss = -4.23)...
2023-07-16 20:58:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.40e+03 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-16 20:58:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.40e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 20:58:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.40e+03 / 2.29e+03 batches (loss = +0.88)...
2023-07-16 20:58:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.50e+03 / 2.29e+03 batches (snr_loss = -4.29)...
2023-07-16 20:58:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.50e+03 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-16 20:58:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.50e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 20:58:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.50e+03 / 2.29e+03 batches (loss = +0.83)...
2023-07-16 20:58:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.60e+03 / 2.29e+03 batches (snr_loss = -3.97)...
2023-07-16 20:58:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.60e+03 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-16 20:58:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.60e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 20:58:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.60e+03 / 2.29e+03 batches (loss = +1.15)...
2023-07-16 20:59:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.70e+03 / 2.29e+03 batches (snr_loss = -4.30)...
2023-07-16 20:59:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.70e+03 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-16 20:59:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.70e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 20:59:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.70e+03 / 2.29e+03 batches (loss = +0.82)...
2023-07-16 20:59:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.80e+03 / 2.29e+03 batches (snr_loss = -4.20)...
2023-07-16 20:59:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.80e+03 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-16 20:59:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.80e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 20:59:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.80e+03 / 2.29e+03 batches (loss = +0.92)...
2023-07-16 20:59:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.90e+03 / 2.29e+03 batches (snr_loss = -3.62)...
2023-07-16 20:59:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.90e+03 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-16 20:59:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.90e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 20:59:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.90e+03 / 2.29e+03 batches (loss = +1.50)...
2023-07-16 20:59:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+03 / 2.29e+03 batches (snr_loss = -3.91)...
2023-07-16 20:59:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+03 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-16 20:59:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 20:59:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+03 / 2.29e+03 batches (loss = +1.20)...
2023-07-16 21:00:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.10e+03 / 2.29e+03 batches (snr_loss = -4.55)...
2023-07-16 21:00:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.10e+03 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-16 21:00:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.10e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:00:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.10e+03 / 2.29e+03 batches (loss = +0.56)...
2023-07-16 21:00:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.20e+03 / 2.29e+03 batches (snr_loss = -4.14)...
2023-07-16 21:00:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.20e+03 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-16 21:00:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.20e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:00:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.20e+03 / 2.29e+03 batches (loss = +0.97)...
2023-07-16 21:00:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 2290 batches: 1.12,-0.22,1.35,3.83,6.85,3.98,5.15,0.79,1.51,2.13,3.88,1.80,3.11,1.07,4.14,3.16,1.32,1.41,2.38,4.56,1.01,2.30,2.82,2.56,2.59,-1.18,-0.89,0.87,0.06,-1.72,2.89,2.13,2.85,-1.33,1.83,1.91,-4.84,2.19,-1.29,-2.88,-2.09,0.10,0.57,4.09,-3.41,0.02,0.06,-1.01,0.37,0.73,5.79,1.26,4.56,1.13,7.12,2.75,-3.07,1.09,0.21,0.59,-1.81,1.88,2.72,-2.97,3.84,-2.68,0.70,0.92,5.86,1.90,0.78,0.29,3.58,4.46,1.91,-3.73,3.95,1.23,1.18,0.59,-1.50,0.31,-1.22,0.29,-1.23,1.85,-0.49,5.67,-4.64,0.49,-0.80,-0.56,-0.35,0.74,-1.60,3.68,-5.80,-2.61,3.38,0.18,4.89,-1.87,3.19,2.41,1.38,6.37,3.02,-1.34,-5.22,1.81,-0.88,2.58,2.02,2.21,5.03,-0.60,0.23,-1.06,6.75,-0.54,2.96,0.57,-2.89,0.00,0.31,-1.06,0.63,-0.38,4.47,2.30,-2.04,1.31,2.31,-0.68,4.75,1.76,-0.22,1.62,3.01,-2.36,-1.97,-0.90,6.31,3.23,-1.60,-1.06,4.57,-2.15,-6.34,3.00,2.20,0.85,4.55,2.56,3.75,-2.15,-3.93,0.47,1.26,4.89,1.70,2.48,-0.08,-2.45,0.21,-0.80,2.18,2.78,-0.45,-3.33,-2.34,6.22,5.36,1.14,6.55,1.65,1.56,2.11,0.71,4.97,4.27,3.05,4.65,-1.96,0.41,4.38,0.06,2.31,0.21,-4.83,0.57,4.24,-6.19,4.78,-0.68,-0.56,3.58,-1.84,-0.70,2.92,-0.25,0.87,1.05,-4.02,6.01,-2.11,-3.59,4.90,1.57,1.74,2.87,-3.13,-0.36,-3.77,0.31,5.77,-1.52,2.39,-2.11,-0.94,-1.16,0.42,-1.43,0.68,1.04,-2.33,-2.30,-2.54,-2.91,0.94,3.74,-2.51,1.42,-3.26,4.67,4.11,-4.09,0.54,1.13,2.58,-0.93,0.39,0.89,2.78,-0.33,-0.85,0.51,1.91,1.03,4.20,3.63,4.20,-0.68,-1.33,3.33,0.58,-0.73,0.61,1.97,2.38,-3.28,3.08,0.78,1.95,2.87,1.59,-0.25,3.90,0.67,-2.19,-1.71,-1.83,1.89,1.62,5.43,3.31,2.41,-0.81,-1.56,-2.34,5.17,-0.70,3.07,-2.05,-0.54,-1.32,-1.81,-2.35,7.54,2.62,0.38,0.39,-0.49,-0.45,0.80,-0.58,0.98,2.82,1.29,1.85,-0.48,0.26,4.90,2.03,-2.66,-2.32,3.80,2.09,0.08,-0.55,-3.88,-0.88,0.92,2.04,0.79,3.99,5.66,4.41,1.30,0.21,1.06,-0.11,-0.19,1.17,2.79,3.90,1.40,-0.55,-0.83,-2.70,6.58,-1.95,1.80,0.55,-1.13,-1.33,1.35,2.06,2.38,5.15,0.59,-0.49,2.65,7.54,5.15,0.37,1.60,0.72,5.66,-2.38,1.44,1.33,-0.24,-1.88,3.03,-0.34,-3.52,2.55,-0.31,4.33,0.11,3.91,1.87,1.20,3.34,0.47,1.77,1.80,2.60,-1.04,0.13,-1.87,-1.47,2.25,3.10,-3.20,-3.18,2.93,1.26,0.46,1.11,0.44,-2.95,1.64,0.60,1.33,0.43,1.51,4.13,2.72,3.12,0.90,2.34,0.92,0.88,-2.63,-1.18,1.65,0.02,1.13,0.36,-0.25,1.65,2.29,-1.95,-2.56,-2.59,-0.48,3.91,2.70,2.34,0.76,1.85,3.93,0.96,1.79,-2.63,1.00,1.59,0.95,4.00,-4.12,1.26,-2.76,1.03,-1.22,-2.39,1.43,3.77,9.34,-4.87,-3.89,3.10,-2.40,5.53,0.42,5.23,2.16,-2.09,3.30,4.48,4.72,1.75,3.56,2.99,-4.03,5.30,1.97,1.89,2.36,-4.89,-3.04,-0.07,-1.85,2.66,2.45,1.60,0.43,4.81,-0.67,2.91,2.60,-1.28,-1.39,4.26,2.25,3.00,3.88,2.01,2.43,0.19,0.37,4.75,1.96,3.57,-1.41,2.94,1.00,-1.72,3.36,5.63,3.51,3.78,1.80,2.04,0.61,2.28,-1.07,4.07,0.10,2.70,-6.05,-3.78,2.64,4.46,-4.18,-1.95,1.58,-0.20,0.49,4.86,-0.57,2.81,-2.12,0.28,2.49,-1.24,1.42,0.90,0.28,-1.59,1.47,-2.71,1.81,7.31,3.12,2.01,-3.08,5.54,1.76,2.46,-0.93,3.12,-0.82,0.92,1.53,1.79,2.39,9.60,-3.24,0.81,-0.89,1.08,2.03,-2.95,1.52,0.08,1.75,3.56,1.03,3.55,-4.65,2.89,0.40,-1.75,-2.43,0.17,-2.68,2.43,0.57,-0.53,1.12,2.92,-0.54,3.51,-2.19,-0.51,0.95,-1.62,2.48,1.11,1.18,1.83,4.67,4.15,-2.90,3.24,3.75,0.81,4.93,0.98,1.17,2.09,3.33,1.78,-0.56,0.28,3.50,0.93,-1.13,-0.99,3.40,-0.74,0.61,-5.15,1.16,-6.01,0.11,-0.31,-0.94,-0.75,0.01,1.06,3.98,-4.29,-1.38,1.61,2.35,4.85,0.27,-0.35,-0.04,-1.13,2.09,1.39,-1.83,2.60,0.63,2.56,-3.94,1.56,-1.74,-1.62,-3.77,1.43,-6.50,2.62,6.07,1.67,-2.46,0.04,-1.21,-0.15,0.29,2.62,2.48,2.72,3.51,3.73,-2.14,-0.49,-1.88,2.55,1.58,4.73,3.07,-1.38,1.62,1.74,0.94,-1.67,1.25,1.17,1.70,-0.60,-2.37,-4.50,2.42,0.19,1.73,3.48,2.59,-1.19,0.97,-1.24,3.91,3.82,-4.43,0.90,1.06,2.92,5.17,-2.37,3.42,1.61,8.37,-0.54,-0.14,-0.24,6.07,1.64,2.27,3.21,3.53,2.40,-0.46,-3.63,5.80,-4.72,2.66,-1.58,0.36,-1.01,-3.26,6.21,-0.50,4.03,3.59,5.28,1.84,-0.04,-2.11,3.70,-2.64,-1.67,-0.70,-1.78,-0.70,-0.53,-0.86,1.35,-0.81,3.95,4.05,3.72,3.75,0.92,3.69,1.21,1.37,-0.10,2.22,1.24,0.13,3.89,-0.74,4.69,-5.23,1.59,4.16,-0.67,1.70,1.15,-5.87,4.10,3.44,1.83,2.79,-0.32,1.82,3.15,-0.10,2.99,-3.55,-0.26,1.16,1.04,2.53,3.15,0.04,-1.57,0.11,1.70,4.25,2.02,-0.83,0.42,1.79,0.48,2.21,0.76,3.92,2.75,-0.67,8.01,0.47,-2.34,7.68,-1.38,2.98,1.63,1.51,0.41,-0.26,1.50,2.69,0.45,-3.10,2.81,-0.22,2.02,-5.36,-0.46,-2.39,0.80,2.36,-0.11,0.79,5.90,2.96,1.01,-0.35,1.45,3.45,2.56,3.21,8.46,1.63,2.18,-3.76,6.48,3.74,0.62,1.02,1.96,-0.44,3.36,0.40,-2.68,-2.49,4.53,0.56,-1.15,-0.05,3.14,0.06,-3.66,-0.48,2.60,1.73,-7.18,-2.28,1.01,-1.40,6.15,1.93,3.03,-0.38,2.69,-0.01,-0.03,2.09,3.19,4.94,-1.24,-6.08,0.08,-1.52,7.03,3.91,-0.82,3.65,9.50,1.61,4.00,-4.22,-0.52,2.65,-1.77,0.08,0.37,-4.61,-1.17,3.36,-1.28,-0.83,4.66,-5.34,1.11,-3.68,0.75,2.87,0.07,-0.63,1.16,1.16,4.70,6.03,1.25,3.31,3.53,-3.66,4.25,-0.27,0.16,2.07,-1.43,0.23,-1.98,2.01,-0.72,-0.94,-1.90,4.57,3.60,-3.61,-3.04,0.96,-0.35,-5.89,1.28,-0.66,0.13,-4.11,2.04,5.39,1.64,3.46,-0.88,1.89,-1.04,-2.56,0.84,1.67,-1.57,-2.77,-2.75,4.63,-1.90,2.61,1.24,-1.56,-3.34,2.29,2.04,6.14,1.55,0.14,2.95,-1.87,1.45,-0.26,-2.19,1.69,2.51,0.35,3.07,0.50,-3.74,4.96,1.10,5.01,2.12,1.18,-1.98,1.84,0.40,1.26,-1.44,-0.64,0.77,-1.73,-1.47,-1.52,-3.62,-2.15,3.57,1.86,0.37,2.12,-2.80,2.26,-0.46,-1.34,-2.58,1.36,2.64,-2.84,4.80,-0.93,-1.30,2.48,-0.17,-0.91,1.93,3.77,4.46,0.27,1.54,1.26,3.83,-0.59,3.15,-1.06,-0.36,-0.05,0.60,-3.39,3.34,-0.34,-0.77,2.56,-5.77,-2.27,-1.96,2.11,1.49,-0.98,-0.99,1.86,0.55,-5.21,6.24,-3.16,-1.31,0.90,1.36,-0.03,2.23,-7.15,4.61,3.44,2.37,1.54,-2.81,-0.24,-1.17,-1.30,1.40,2.40,-1.53,5.24,-2.15,0.10,3.83,3.27,5.02,0.90,1.96,2.46,-0.25,-1.02,1.28,-0.50,3.87,5.80,-0.37,3.46,2.16,-1.45,0.51,0.37,-1.78,-0.36,-0.03,1.06,-1.85,4.01,-0.04,3.27,-3.17,2.64,-0.29,3.31,0.73,-1.84,-1.22,-0.66,-0.87,-2.32,4.24,-3.71,-0.70,1.37,-0.28,-0.99,3.88,0.15,0.35,-1.09,2.04,1.07,1.14,2.32,-1.17,-0.51,-0.08,-2.08,4.08,1.64,-0.58,-0.18,-1.20,-1.54,-2.94,-0.64,-4.62,0.47,0.60,-1.91,1.12,4.36,3.25,-0.55,1.80,-1.18,-0.29,2.76,-2.13,3.52,2.16,5.48,-0.72,-0.46,2.74,0.31,4.07,1.16,-2.36,1.24,0.78,1.91,3.63,2.16,-3.20,3.51,-4.03,-0.11,0.17,-0.89,2.08,4.39,-3.24,3.80,-2.24,-0.50,1.21,4.92,3.17,0.55,3.16,4.20,1.97,4.03,1.44,1.61,-0.31,1.08,-0.69,-3.89,-0.65,-3.09,0.80,4.43,-3.36,1.29,-3.34,3.30,3.89,1.20,2.93,-1.55,1.87,2.21,0.17,1.07,0.41,1.88,3.27,1.03,-0.01,3.22,3.01,3.70,3.84,-0.16,-0.74,0.94,2.67,-0.41,1.68,-0.03,-2.22,0.07,3.15,-4.25,-1.22,0.99,-0.56,1.65,-0.21,-0.04,2.33,3.06,0.10,-1.64,-1.81,-2.17,3.16,0.89,2.86,0.92,-0.18,2.24,3.69,-1.62,-0.74,1.34,0.34,0.88,-0.02,0.14,2.02,-3.42,-1.57,0.46,-1.47,-3.44,0.21,7.00,1.52,0.23,0.70,1.26,2.00,0.60,-1.64,-0.29,3.28,3.04,0.54,4.64,4.19,5.06,-1.32,5.64,1.88,2.02,1.71,1.40,2.05,-0.11,1.78,-1.33,2.08,0.39,-2.39,0.92,-0.08,0.07,3.38,0.10,8.89,4.33,1.55,5.17,0.78,3.58,-2.60,2.99,2.60,2.12,2.26,0.00,6.14,0.93,2.83,1.16,0.94,-1.40,2.25,2.13,2.92,2.40,1.36,0.03,1.88,2.84,0.54,1.81,-3.91,4.70,-3.41,-5.48,2.75,-0.15,3.90,-1.76,-5.54,0.98,3.46,1.08,4.93,0.11,-2.10,0.64,-4.11,0.05,1.78,5.08,0.97,3.12,-0.45,-0.36,-3.36,0.73,-1.42,2.56,4.44,1.82,0.96,1.86,2.08,3.42,1.82,-3.47,-4.58,-1.08,0.10,3.21,3.92,-0.80,4.27,-0.24,0.01,2.29,1.93,5.37,1.80,0.61,-3.95,-2.37,-0.27,-0.79,-1.80,1.30,0.42,7.64,4.49,-2.09,1.87,6.14,2.32,-1.12,4.51,2.91,-0.84,-2.17,1.77,0.55,3.77,3.36,1.74,-3.34,0.91,-0.06,-2.23,-0.07,5.08,2.89,-0.42,3.70,-4.80,4.59,0.93,3.84,-1.26,0.68,-2.76,-1.41,-0.34,-0.02,-1.02,-5.01,0.49,-0.73,1.72,1.61,-2.54,2.99,-0.14,2.14,1.07,-2.86,5.06,-0.05,-3.23,4.88,1.11,-0.13,1.15,-0.93,1.58,-1.15,2.73,-1.43,-0.46,0.02,-3.29,-0.35,3.96,-1.99,2.86,0.39,3.04,0.03,1.35,-0.49,-0.64,-1.41,-1.08,0.85,4.69,4.88,8.44,-1.14,0.11,7.99,0.76,-0.89,5.81,1.94,1.44,-2.22,4.02,2.69,5.64,4.48,-1.07,-3.31,6.20,0.07,3.44,0.93,1.88,-0.68,-2.88,2.68,-3.25,-0.11,1.55,1.26,4.89,-1.41,1.14,0.63,-1.54,3.02,3.86,0.45,1.95,-2.70,1.53,-1.80,5.79,5.59,-2.32,4.41,-2.97,3.84,-1.04,-1.60,-3.89,-1.67,-0.04,0.74,0.35,1.46,4.61,1.23,0.64,2.53,-2.74,-3.89,2.77,2.95,3.54,2.66,-1.67,2.64,1.39,-2.14,-2.88,-2.23,-0.36,-1.33,-2.98,-1.29,4.39,4.18,2.33,0.11,1.21,-0.38,-0.59,-0.14,3.03,3.51,0.65,1.85,1.51,3.11,-0.16,7.58,3.75,-1.75,1.37,2.86,5.88,2.06,-2.73,-0.31,3.68,-3.21,3.58,2.08,-2.27,1.16,0.19,0.30,3.26,-0.09,-2.72,4.51,-2.56,-3.58,3.13,0.76,-0.22,-1.84,1.25,-0.28,-2.44,1.25,1.21,-2.46,3.23,4.70,-0.58,-0.41,-3.86,0.64,5.01,0.60,5.63,0.94,1.37,0.72,3.51,1.00,1.96,0.92,1.09,-0.21,0.86,0.96,1.08,-3.64,-1.03,2.61,2.06,2.71,-0.40,1.19,-1.07,3.71,2.75,4.70,-0.65,-2.24,4.73,1.24,-0.42,1.21,1.63,-0.98,1.66,3.70,1.38,2.65,-2.31,3.08,3.37,5.37,2.73,1.23,-2.67,4.04,-1.18,-0.87,4.87,2.56,3.83,-0.15,-3.99,2.56,4.65,-4.74,-0.61,2.33,-0.02,5.35,3.56,3.29,1.72,3.10,3.59,-0.40,-0.45,-4.25,0.89,0.54,4.59,2.93,0.76,1.14,-1.83,-3.34,0.97,-3.25,-2.58,-0.46,-1.25,1.22,2.78,2.74,1.08,4.77,2.87,5.25,1.34,-1.59,4.53,1.33,-0.00,-1.31,-2.21,1.60,2.00,-1.00,1.69,4.84,-0.54,2.23,-4.02,-3.56,3.93,-1.51,0.78,0.04,-0.76,2.46,0.95,2.50,1.05,0.35,2.25,1.71,2.97,1.02,1.65,0.79,-3.94,3.67,-0.71,1.75,4.99,3.04,-3.38,-2.82,1.56,-3.23,3.66,-3.94,2.46,4.29,-0.28,-0.56,2.28,-1.29,3.55,0.48,-2.20,0.80,3.56,5.28,-0.02,4.22,3.86,1.11,-2.49,-1.11,2.98,2.11,-0.63,-4.33,-1.53,4.13,1.93,0.44,6.13,1.21,-3.58,4.78,-3.22,6.09,-2.55,-2.14,3.52,1.59,0.95,1.57,1.80,-1.20,3.29,3.95,2.36,3.29,-2.12,2.77,-3.19,3.54,-0.70,-1.27,-3.32,0.51,2.32,2.18,2.12,-4.19,2.16,0.34,1.30,0.01,1.90,4.07,-0.15,-1.34,3.96,-0.35,-0.20,-1.40,0.77,2.59,-0.75,1.44,1.02,3.48,5.19,-3.82,1.51,0.06,2.69,-4.43,4.49,-0.22,0.61,-3.18,-4.26,-0.12,2.08,-2.80,1.89,-2.84,1.45,3.32,-2.93,2.98,3.50,2.19,2.37,-2.59,-1.05,1.78,-2.03,4.05,1.44,-1.75,0.32,2.56,3.74,-0.46,6.45,-0.25,0.81,1.44,2.83,-1.18,3.65,0.95,4.30,-1.38,3.99,4.22,4.52,4.68,-2.78,-3.61,-1.81,2.83,0.41,-1.14,1.86,-0.32,-1.67,7.22,0.24,1.93,4.45,-2.88,0.80,0.50,3.05,-0.34,0.83,0.57,2.24,-0.28,2.84,0.07,2.31,2.66,-1.22,-2.72,-3.99,-0.12,3.20,4.23,1.79,0.78,1.21,0.50,3.27,-1.12,0.34,1.05,-2.91,1.88,0.85,6.03,-0.59,0.64,5.15,1.83,1.29,2.74,1.70,0.45,4.27,5.04,1.42,2.07,-1.14,-1.11,2.49,0.85,3.64,2.07,0.28,-0.86,-1.18,2.26,-3.75,-1.46,2.01,1.40,6.76,2.06,-1.69,-2.02,2.44,-2.23,3.57,0.10,3.68,3.83,0.26,-2.11,7.05,4.93,0.74,-1.82,2.32,3.20,3.44,-0.02,3.90,2.94,2.19,2.42,-0.67,4.48,1.94,8.09,0.81,0.79,5.77,2.12,0.53,1.33,4.31,5.66,-3.49,3.66,3.79,2.48,-1.11,2.89,-2.85,2.29,-0.52,0.43,6.37,1.25,2.92,0.53,0.47,-2.37,6.26,2.92,-0.15,-0.76,2.28,1.85,1.74,1.44,0.78,-6.97,0.35,-0.25,2.37,1.39,-0.75,2.46,2.07,0.85,3.11,0.76,-0.60,1.70,1.73,3.52,-0.09,4.46,-0.22,1.49,-1.68,-0.05,2.19,7.36,0.40,2.53,-2.03,3.48,-2.67,2.57,1.71,2.74,1.50,2.54,1.19,0.30,-4.04,2.65,2.66,3.89,0.23,0.53,-3.00,11.25,0.93,-1.10,1.00,-0.27,1.25,2.74,0.48,0.09,0.55,1.72,-2.35,-2.90,1.93,0.34,1.14,1.23,3.33,-1.55,-1.75,0.98,-1.92,6.23,-3.58,0.38,2.06,-0.26,0.95,2.99,-0.95,1.50,3.26,0.16,2.43,4.17,-0.52,1.57,0.65,3.27,0.97,3.18,4.03,1.27,3.95,-0.55,6.04,-0.76,-0.88,-1.29,2.24,3.25,2.41,0.54,3.05,2.12,2.00,2.05,-1.65,-2.26,-2.03,2.01,4.23,-4.74,2.12,-3.34,-0.11,0.38,3.39,0.13,2.81,1.25,-1.80,0.90,3.86,-0.66,-0.42,-2.75,-0.54,0.67,-1.92,-3.76,1.97,-1.76,0.73,2.08,-0.09,3.60,0.18,2.72,-1.11,1.48,2.25,3.91,3.63,2.99,3.07,1.74,1.34,-0.40,-2.46,3.37,0.28,0.59,-0.98,4.16,-0.46,1.40,5.05,0.15,-0.04,1.75,-0.76,0.66,4.13,-0.69,-4.66,-1.70,1.89,0.02,1.63,5.54,-0.77,-2.22,-0.26,-3.53,0.62,1.60,1.80,-1.30,-3.84,-0.60,3.05,-2.06,0.69,-1.97,3.58,-0.21,-1.66,4.50,2.84,-1.10,-1.49,-1.61,3.19,-5.30,0.28,2.43,2.38,-2.00,1.29,2.64,2.16,0.51,-0.33,-3.72,1.57,3.64,-4.14,0.67,1.34,6.51,5.88,3.14,1.59,4.47,-0.12,5.82,1.58,2.74,1.32,0.73,-0.19,0.23,-1.39,-3.23,1.10,0.86,3.09,3.26,0.79,1.72,-1.56,-2.47,1.64,-3.77,-4.99,2.38,2.47,-2.94,1.15,1.10,0.85,-0.62,4.75,3.51,-0.19,0.46,-3.63,5.08,-1.65,1.46,-0.64,3.65,2.42,1.84,2.49,-0.23,-0.21,2.91,1.49,-2.14,5.55,1.08,1.65,3.29,3.18,2.60,-0.97,3.96,3.21,2.05,-0.74,4.66,1.57,0.15,-0.31,1.03,0.56,2.66,0.84,-0.84,0.03,-2.09,2.25,0.85,0.70,2.78,-2.31,-0.30,-0.70,3.33,1.31,-0.49,-2.19,3.54,-1.26,-0.57,0.40,-0.67,4.41,3.60,-6.31,-0.18,4.86,5.29,3.36,-0.97,1.04,-0.85,-4.26,-0.88,0.97,1.47,5.60,2.63,1.05,2.30,3.38,-0.91,-1.94,0.40,2.85,0.12,2.98,0.32,-2.15,-1.30,5.26,3.11,6.00,0.06,-0.45,-0.98,-1.66,-1.93,0.99,1.35,3.18,3.41,0.84,-2.24,-0.45,-0.35,0.70,3.21,2.58,5.03,5.29,-0.87,0.22,1.38,1.00,-0.71,-0.06,-2.58,2.86,4.95,-1.85,1.13,-0.17,3.64,1.74,0.49,1.06,0.87,2.86,-0.67,1.03,0.55,4.60,5.12,2.66,3.13,0.56,2.26,3.14,0.89,1.52,-4.19,1.22,1.56,-4.69,-6.47,2.04,-2.49,-0.31,-0.48,5.11,5.64,2.11,5.93,-2.97,-0.68,2.80,-2.48,0.13,4.12,1.27,2.77,2.84,1.27
2023-07-16 21:00:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint best.pt.tar
2023-07-16 21:00:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=1.000e-03) - Epoch  1: eval = 0.9420(6.12m/2290)
2023-07-16 21:00:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-16 21:00:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-16 21:01:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 9.43e+03 batches (snr_loss = -3.81)...
2023-07-16 21:01:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 9.43e+03 batches (ce_loss = +3.87)...
2023-07-16 21:01:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:01:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 9.43e+03 batches (loss = -1.84)...
2023-07-16 21:01:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 9.43e+03 batches (norm = +14.59)...
2023-07-16 21:01:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 9.43e+03 batches (snr_loss = -4.54)...
2023-07-16 21:01:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 9.43e+03 batches (ce_loss = +3.87)...
2023-07-16 21:01:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:01:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 9.43e+03 batches (loss = -2.58)...
2023-07-16 21:01:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 9.43e+03 batches (norm = +12.57)...
2023-07-16 21:02:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 9.43e+03 batches (snr_loss = -4.05)...
2023-07-16 21:02:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 9.43e+03 batches (ce_loss = +3.86)...
2023-07-16 21:02:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:02:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 9.43e+03 batches (loss = -2.09)...
2023-07-16 21:02:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 9.43e+03 batches (norm = +16.40)...
2023-07-16 21:02:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 9.43e+03 batches (snr_loss = -4.45)...
2023-07-16 21:02:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 9.43e+03 batches (ce_loss = +3.85)...
2023-07-16 21:02:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:02:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 9.43e+03 batches (loss = -2.50)...
2023-07-16 21:02:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 9.43e+03 batches (norm = +27.55)...
2023-07-16 21:03:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 9.43e+03 batches (snr_loss = -4.58)...
2023-07-16 21:03:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 9.43e+03 batches (ce_loss = +3.85)...
2023-07-16 21:03:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:03:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 9.43e+03 batches (loss = -2.63)...
2023-07-16 21:03:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 9.43e+03 batches (norm = +11.84)...
2023-07-16 21:03:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 9.43e+03 batches (snr_loss = -4.33)...
2023-07-16 21:03:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 9.43e+03 batches (ce_loss = +3.90)...
2023-07-16 21:03:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:03:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 9.43e+03 batches (loss = -2.36)...
2023-07-16 21:03:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 9.43e+03 batches (norm = +12.89)...
2023-07-16 21:04:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 9.43e+03 batches (snr_loss = -4.09)...
2023-07-16 21:04:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 9.43e+03 batches (ce_loss = +3.84)...
2023-07-16 21:04:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:04:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 9.43e+03 batches (loss = -2.14)...
2023-07-16 21:04:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 9.43e+03 batches (norm = +10.88)...
2023-07-16 21:04:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 9.43e+03 batches (snr_loss = -4.21)...
2023-07-16 21:04:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 9.43e+03 batches (ce_loss = +3.85)...
2023-07-16 21:04:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:04:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 9.43e+03 batches (loss = -2.25)...
2023-07-16 21:04:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 9.43e+03 batches (norm = +11.74)...
2023-07-16 21:05:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 9.43e+03 batches (snr_loss = -4.54)...
2023-07-16 21:05:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 9.43e+03 batches (ce_loss = +3.86)...
2023-07-16 21:05:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:05:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 9.43e+03 batches (loss = -2.58)...
2023-07-16 21:05:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 9.43e+03 batches (norm = +15.40)...
2023-07-16 21:05:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 9.43e+03 batches (snr_loss = -4.03)...
2023-07-16 21:05:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 9.43e+03 batches (ce_loss = +3.81)...
2023-07-16 21:05:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:05:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 9.43e+03 batches (loss = -2.10)...
2023-07-16 21:05:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 9.43e+03 batches (norm = +13.62)...
2023-07-16 21:06:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 9.43e+03 batches (snr_loss = -4.31)...
2023-07-16 21:06:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 9.43e+03 batches (ce_loss = +3.85)...
2023-07-16 21:06:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:06:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 9.43e+03 batches (loss = -2.36)...
2023-07-16 21:06:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 9.43e+03 batches (norm = +18.05)...
2023-07-16 21:06:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.20e+03 / 9.43e+03 batches (snr_loss = -4.22)...
2023-07-16 21:06:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.20e+03 / 9.43e+03 batches (ce_loss = +3.85)...
2023-07-16 21:06:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.20e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:06:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.20e+03 / 9.43e+03 batches (loss = -2.26)...
2023-07-16 21:06:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.20e+03 / 9.43e+03 batches (norm = +18.50)...
2023-07-16 21:06:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.30e+03 / 9.43e+03 batches (snr_loss = -3.97)...
2023-07-16 21:06:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.30e+03 / 9.43e+03 batches (ce_loss = +3.79)...
2023-07-16 21:06:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.30e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:06:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.30e+03 / 9.43e+03 batches (loss = -2.05)...
2023-07-16 21:06:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.30e+03 / 9.43e+03 batches (norm = +17.13)...
2023-07-16 21:07:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.40e+03 / 9.43e+03 batches (snr_loss = -4.47)...
2023-07-16 21:07:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.40e+03 / 9.43e+03 batches (ce_loss = +3.80)...
2023-07-16 21:07:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.40e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:07:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.40e+03 / 9.43e+03 batches (loss = -2.54)...
2023-07-16 21:07:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.40e+03 / 9.43e+03 batches (norm = +12.53)...
2023-07-16 21:07:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.50e+03 / 9.43e+03 batches (snr_loss = -4.59)...
2023-07-16 21:07:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.50e+03 / 9.43e+03 batches (ce_loss = +3.82)...
2023-07-16 21:07:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.50e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:07:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.50e+03 / 9.43e+03 batches (loss = -2.65)...
2023-07-16 21:07:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.50e+03 / 9.43e+03 batches (norm = +17.62)...
2023-07-16 21:14:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-16 21:14:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-16 21:14:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 1
2023-07-16 21:14:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: gradient clipping by 5.0, default L2
2023-07-16 21:14:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-16 21:15:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 2.29e+03 batches (snr_loss = -3.95)...
2023-07-16 21:15:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-16 21:15:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:15:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 2.29e+03 batches (loss = +1.16)...
2023-07-16 21:15:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 2.29e+03 batches (snr_loss = -3.89)...
2023-07-16 21:15:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-16 21:15:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:15:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 2.29e+03 batches (loss = +1.23)...
2023-07-16 21:15:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 2.29e+03 batches (snr_loss = -4.00)...
2023-07-16 21:15:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-16 21:15:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:15:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 2.29e+03 batches (loss = +1.11)...
2023-07-16 21:16:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 2.29e+03 batches (snr_loss = -4.01)...
2023-07-16 21:16:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-16 21:16:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:16:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 2.29e+03 batches (loss = +1.11)...
2023-07-16 21:16:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 2.29e+03 batches (snr_loss = -4.72)...
2023-07-16 21:16:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-16 21:16:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:16:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 2.29e+03 batches (loss = +0.40)...
2023-07-16 21:16:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 2.29e+03 batches (snr_loss = -4.22)...
2023-07-16 21:16:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-16 21:16:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:16:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 2.29e+03 batches (loss = +0.89)...
2023-07-16 21:16:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 2.29e+03 batches (snr_loss = -4.43)...
2023-07-16 21:16:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-16 21:16:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:16:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 2.29e+03 batches (loss = +0.68)...
2023-07-16 21:17:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 2.29e+03 batches (snr_loss = -4.26)...
2023-07-16 21:17:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-16 21:17:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:17:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 2.29e+03 batches (loss = +0.85)...
2023-07-16 21:17:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 2.29e+03 batches (snr_loss = -4.45)...
2023-07-16 21:17:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-16 21:17:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:17:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 2.29e+03 batches (loss = +0.66)...
2023-07-16 21:17:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 2.29e+03 batches (snr_loss = -4.24)...
2023-07-16 21:17:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-16 21:17:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:17:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 2.29e+03 batches (loss = +0.87)...
2023-07-16 21:17:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 2.29e+03 batches (snr_loss = -3.96)...
2023-07-16 21:17:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-16 21:17:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:17:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 2.29e+03 batches (loss = +1.15)...
2023-07-16 21:17:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.20e+03 / 2.29e+03 batches (snr_loss = -4.00)...
2023-07-16 21:17:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.20e+03 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-16 21:17:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.20e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:17:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.20e+03 / 2.29e+03 batches (loss = +1.11)...
2023-07-16 21:18:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.30e+03 / 2.29e+03 batches (snr_loss = -4.47)...
2023-07-16 21:18:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.30e+03 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-16 21:18:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.30e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:18:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.30e+03 / 2.29e+03 batches (loss = +0.65)...
2023-07-16 21:18:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.40e+03 / 2.29e+03 batches (snr_loss = -4.49)...
2023-07-16 21:18:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.40e+03 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-16 21:18:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.40e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:18:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.40e+03 / 2.29e+03 batches (loss = +0.62)...
2023-07-16 21:18:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.50e+03 / 2.29e+03 batches (snr_loss = -4.68)...
2023-07-16 21:18:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.50e+03 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-16 21:18:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.50e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:18:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.50e+03 / 2.29e+03 batches (loss = +0.44)...
2023-07-16 21:18:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.60e+03 / 2.29e+03 batches (snr_loss = -4.32)...
2023-07-16 21:18:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.60e+03 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-16 21:18:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.60e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:18:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.60e+03 / 2.29e+03 batches (loss = +0.79)...
2023-07-16 21:18:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.70e+03 / 2.29e+03 batches (snr_loss = -4.01)...
2023-07-16 21:18:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.70e+03 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-16 21:18:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.70e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:18:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.70e+03 / 2.29e+03 batches (loss = +1.11)...
2023-07-16 21:19:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.80e+03 / 2.29e+03 batches (snr_loss = -4.11)...
2023-07-16 21:19:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.80e+03 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-16 21:19:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.80e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:19:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.80e+03 / 2.29e+03 batches (loss = +1.00)...
2023-07-16 21:19:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.90e+03 / 2.29e+03 batches (snr_loss = -4.38)...
2023-07-16 21:19:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.90e+03 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-16 21:19:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.90e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:19:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.90e+03 / 2.29e+03 batches (loss = +0.74)...
2023-07-16 21:19:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+03 / 2.29e+03 batches (snr_loss = -4.56)...
2023-07-16 21:19:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+03 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-16 21:19:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:19:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+03 / 2.29e+03 batches (loss = +0.56)...
2023-07-16 21:19:53 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.10e+03 / 2.29e+03 batches (snr_loss = -4.45)...
2023-07-16 21:19:53 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.10e+03 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-16 21:19:53 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.10e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:19:53 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.10e+03 / 2.29e+03 batches (loss = +0.66)...
2023-07-16 21:20:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.20e+03 / 2.29e+03 batches (snr_loss = -4.45)...
2023-07-16 21:20:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.20e+03 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-16 21:20:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.20e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 21:20:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.20e+03 / 2.29e+03 batches (loss = +0.66)...
2023-07-16 21:20:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 2290 batches: 1.61,-3.13,-1.65,1.53,-1.41,0.23,-1.77,-0.57,-0.93,4.79,-1.95,0.46,2.05,3.21,-4.41,3.87,0.82,2.27,-2.21,1.15,-3.72,1.66,3.74,2.39,1.54,5.35,2.67,3.13,1.22,3.42,5.40,2.44,4.09,-0.26,0.01,-0.51,3.66,-1.62,0.55,0.23,0.55,1.25,0.62,-1.75,1.26,4.45,2.01,1.18,2.44,-3.23,2.45,3.12,-0.26,2.42,-0.40,-0.49,5.03,12.56,0.49,3.80,0.37,-0.36,2.50,0.30,0.48,0.26,-0.90,1.15,3.79,0.87,2.03,3.90,2.33,-0.30,1.45,-4.71,-2.73,1.10,1.67,1.81,0.07,0.65,0.39,3.48,4.24,2.85,3.39,2.89,2.05,0.31,5.33,-2.86,-3.24,2.69,1.68,0.35,0.16,-0.09,1.75,-2.02,2.57,1.17,-0.68,-0.74,2.93,4.25,3.87,6.65,5.43,4.17,3.58,0.17,-1.63,0.78,1.92,1.65,-1.54,2.12,-2.36,2.17,3.08,1.78,6.90,1.63,-1.34,-1.42,3.63,3.51,0.71,-1.03,-0.57,-0.91,-0.24,2.15,0.98,-3.60,4.47,1.03,-2.38,4.02,-0.78,3.23,1.00,3.26,0.03,0.70,2.45,-0.65,1.30,1.66,4.01,1.76,-2.93,-0.61,-1.96,1.88,-1.03,3.39,0.39,1.86,2.69,1.05,-3.46,0.43,5.65,-0.84,1.98,-3.55,-1.98,1.72,8.16,-3.91,-1.32,9.51,3.06,3.98,2.11,2.34,2.35,-2.02,1.09,-2.20,2.14,4.16,-1.54,-3.26,-0.29,4.63,3.10,1.99,-1.78,-3.25,4.09,4.96,0.52,1.81,0.38,1.84,-1.85,0.26,3.94,0.95,0.97,-0.22,-1.25,3.42,-1.11,2.49,1.74,-3.50,-1.88,-3.67,-2.79,-2.00,2.32,4.34,3.39,-0.29,1.16,1.60,0.33,1.85,4.18,5.12,2.52,-0.46,-4.30,-1.82,3.88,-0.71,-1.72,6.43,0.72,7.24,2.83,-1.09,1.19,-2.05,2.06,3.72,1.71,4.87,-0.62,-0.63,2.32,5.61,1.10,-0.77,1.88,0.28,1.79,-1.20,-2.44,-0.63,2.45,2.15,2.06,2.05,0.02,-0.95,2.68,4.19,6.34,-0.61,2.07,0.46,-0.62,1.71,1.28,0.94,0.33,-0.29,1.21,1.88,4.72,2.29,-1.06,1.72,0.50,3.98,2.56,-6.11,-2.58,5.70,2.93,3.26,4.07,-0.18,1.39,-5.00,2.69,0.89,2.38,-2.07,3.41,-1.79,-0.15,2.96,2.69,0.13,4.99,-0.42,4.25,2.74,-1.78,1.41,0.14,1.49,2.16,0.17,-1.09,-2.15,0.15,1.87,3.60,0.79,2.43,-0.96,0.44,-4.37,4.53,0.39,0.87,1.16,0.71,4.28,0.21,-3.32,1.61,-2.09,8.12,-4.35,2.98,-1.20,1.87,5.19,-1.25,-1.35,1.66,3.32,0.30,-4.85,0.12,-1.80,0.51,1.49,3.09,0.86,0.72,0.77,1.52,3.20,0.53,-5.52,2.83,0.89,1.54,5.77,-0.29,1.54,2.78,0.53,2.12,-0.61,-1.69,2.88,3.52,-1.11,1.26,1.33,5.40,-0.40,2.38,1.91,0.13,3.19,2.83,1.52,3.41,2.92,1.17,1.12,-0.82,0.46,4.15,1.24,0.63,2.12,-1.22,4.79,2.68,3.86,2.47,-1.42,3.15,1.99,-0.24,5.39,-2.49,-5.04,1.66,2.58,0.80,-0.61,4.21,4.31,-4.40,-0.71,-4.77,0.40,-1.72,-0.80,-1.48,0.03,1.29,2.37,0.39,3.19,1.32,-0.76,-0.13,-2.40,-0.04,-4.17,4.09,-0.43,1.06,3.21,-5.34,-4.98,1.97,2.79,-1.06,0.87,4.10,3.79,0.20,-1.27,-0.14,-1.05,-2.45,2.33,-4.68,0.17,0.75,1.10,-1.67,1.64,-0.82,2.63,5.13,-0.64,3.67,-0.05,0.93,4.19,1.61,-0.76,1.95,3.08,-1.89,1.73,0.26,-0.90,5.74,-0.02,1.53,-0.29,3.78,-6.14,-0.27,1.84,-2.06,-2.35,-2.03,0.84,-5.79,-1.03,2.58,-2.35,4.64,-1.41,6.06,1.18,2.63,1.46,0.09,1.17,0.79,4.91,-2.86,-1.32,1.84,-2.22,-3.88,2.27,1.33,-3.89,4.00,3.09,0.13,2.77,2.49,-1.06,4.02,1.94,3.18,-1.03,-0.53,-2.94,2.81,-1.69,3.18,2.23,-1.10,0.19,1.86,1.96,0.28,-1.75,1.26,1.60,-3.05,-1.90,1.03,1.73,-0.22,-2.98,5.48,-1.34,2.37,-3.59,5.39,3.27,-0.45,0.83,-0.06,4.12,-1.58,1.12,3.66,1.84,5.91,-0.71,3.08,-0.31,5.65,2.37,0.90,-0.65,-3.70,-2.53,2.18,4.68,-1.16,3.55,-0.44,3.16,1.27,2.40,-1.31,-1.24,-1.49,0.73,-1.31,1.43,-0.29,0.64,-1.98,3.28,-0.32,4.57,-2.70,0.02,-3.70,2.91,1.30,-1.60,2.25,0.30,2.44,3.32,1.44,-3.26,-1.40,0.98,0.26,0.50,-1.01,1.69,2.39,4.56,-0.96,3.31,1.29,2.66,0.40,3.69,0.61,3.53,3.26,1.82,1.06,0.66,1.69,-1.04,-2.99,1.11,2.08,1.98,0.24,0.67,3.06,-1.75,-1.66,0.89,-3.90,0.29,4.65,2.62,0.35,-1.60,0.14,0.43,-1.00,2.17,-1.35,1.38,2.85,-5.41,3.64,1.50,3.87,0.24,6.04,1.48,2.83,0.97,1.18,0.13,2.08,3.90,-1.26,2.06,-1.97,-5.83,0.69,1.14,2.16,1.94,0.19,-1.56,1.49,-0.49,1.98,-2.39,2.04,1.92,0.76,0.57,-0.13,-0.65,0.20,0.48,2.51,-1.69,2.64,2.39,2.03,-0.08,3.03,-2.94,-1.17,1.74,2.33,0.67,-0.59,0.23,3.73,-4.63,0.98,-2.68,3.79,5.10,-2.94,-1.47,-1.23,-2.08,-1.46,4.68,-1.03,0.04,1.94,-0.06,1.43,1.29,0.35,4.45,1.84,1.08,-0.34,3.53,0.87,4.74,0.93,0.65,-4.09,0.57,0.71,6.61,0.52,0.77,-1.97,0.38,0.87,1.94,2.27,0.63,-3.04,-1.31,0.33,-2.09,-2.28,1.36,4.40,1.76,-0.64,2.62,-0.18,1.41,2.23,1.72,-1.34,-3.56,2.67,3.20,-3.18,-0.19,0.21,4.23,3.33,2.44,-2.35,0.51,1.11,2.40,11.80,1.76,-0.16,-5.05,-3.90,1.50,5.72,0.92,0.21,0.35,-4.25,-2.15,5.42,0.86,3.75,-1.80,-4.48,2.74,3.02,-3.12,1.63,2.53,2.20,0.51,-4.74,2.48,-3.29,3.96,-0.48,-2.70,-0.01,1.89,0.87,3.40,5.70,-3.30,1.48,0.44,0.89,4.26,2.29,1.34,2.82,2.87,2.59,1.63,10.76,-4.83,-5.36,-3.77,-0.30,3.69,0.06,4.71,-0.94,0.97,3.63,0.92,2.32,0.23,1.39,-4.10,3.08,-4.74,5.61,-2.65,1.82,2.39,0.60,-0.42,3.70,-0.14,-3.12,-0.27,4.17,5.10,4.18,-1.32,5.09,-1.99,0.05,-0.54,-1.60,0.84,0.56,-0.51,-3.17,3.50,5.97,-2.52,0.24,2.64,1.29,-0.84,-1.76,1.36,-1.92,4.03,1.25,1.02,0.66,3.38,0.97,-2.95,-1.30,-1.76,1.66,3.55,0.64,-2.93,-1.80,2.59,2.64,3.57,-1.98,3.87,0.77,2.83,2.14,3.67,1.85,0.42,-1.65,-0.95,2.00,4.68,0.84,-2.12,-0.27,-0.93,4.32,-0.82,4.57,-1.60,-0.61,0.39,-4.99,4.73,0.67,-1.10,-0.45,0.13,-0.34,1.74,-1.49,-3.33,0.32,-1.70,-2.79,-1.96,-2.33,1.10,5.96,5.96,1.67,2.09,3.93,0.87,-1.55,-2.86,-0.68,3.16,1.56,2.78,-1.29,3.73,1.61,2.76,0.25,2.24,-1.15,4.41,-0.21,-0.62,1.05,-2.01,1.12,5.18,4.04,3.83,1.71,2.09,-3.63,-0.52,0.14,0.74,0.39,0.86,1.59,0.95,2.97,0.88,-0.46,2.99,1.17,-2.83,-0.40,-1.92,5.03,-0.26,0.35,1.04,-1.97,-3.05,1.22,1.70,-1.31,5.20,-3.59,2.63,-5.95,1.39,1.33,0.23,2.05,-1.30,3.49,-0.25,1.95,-2.79,-2.85,-1.23,3.17,-0.59,1.54,6.60,0.07,-2.79,6.57,1.83,4.06,3.61,4.08,1.22,4.01,-2.96,-4.68,0.93,-2.55,1.90,0.40,0.09,0.47,-6.63,1.17,0.87,3.43,5.43,-2.65,6.17,2.06,1.45,2.74,0.28,-1.33,-0.53,-0.10,1.21,-0.54,2.78,0.29,-3.01,0.95,4.44,-0.44,-1.32,1.42,1.59,4.16,6.42,0.17,-4.27,1.69,6.57,2.97,-1.70,0.52,1.06,-1.02,5.36,-1.21,0.84,0.74,2.44,1.61,2.83,0.77,1.96,3.36,-2.04,-0.85,-2.00,5.91,-0.23,2.92,1.82,-1.36,3.08,-3.81,1.59,3.54,3.92,0.06,2.82,0.60,1.50,2.50,-1.14,-1.70,-0.71,0.16,3.91,1.81,1.82,-2.48,2.34,-1.07,3.50,-2.38,-0.75,-1.30,4.26,1.35,-0.27,-1.65,3.41,2.48,2.61,2.37,3.09,0.83,4.00,3.01,-2.76,3.68,3.23,1.37,-2.06,2.30,-3.32,-1.03,4.79,-1.79,1.50,-1.06,1.79,3.86,0.79,0.06,0.15,2.75,1.22,7.27,4.26,1.59,0.92,0.49,-3.39,-0.50,-2.77,-0.27,-2.59,1.56,-0.53,2.86,-0.11,-2.05,2.59,5.57,3.93,1.80,-0.84,1.20,-1.42,1.03,-4.93,4.80,1.48,2.80,1.81,-0.39,-1.91,1.12,4.43,2.71,0.36,-1.39,5.72,0.00,1.24,-2.84,1.08,-3.45,2.59,-1.45,4.20,3.63,-0.88,2.15,-1.72,-2.49,4.53,0.36,-1.97,4.17,-0.03,0.60,5.33,4.03,0.07,3.22,-2.99,2.07,1.20,-0.12,3.81,2.14,1.04,2.84,1.87,1.31,0.71,0.79,3.19,-2.08,-3.10,3.05,-1.28,1.11,1.36,10.81,-1.71,1.36,3.33,6.24,3.80,-0.80,1.95,0.01,2.00,-2.98,-0.55,2.46,4.57,-0.80,0.26,-1.84,-0.58,1.15,1.19,2.35,7.49,5.45,0.60,-2.23,5.35,2.72,1.39,1.45,2.49,-1.51,2.46,1.08,0.08,2.02,1.92,0.09,-0.74,6.38,-4.03,3.28,-2.76,1.52,-2.57,1.07,-1.19,-0.69,-2.67,-5.49,0.55,-0.95,1.08,2.32,-1.27,-4.89,4.35,1.82,0.35,3.49,1.88,3.60,-2.59,2.56,-1.45,-0.28,-3.21,2.74,1.73,-2.76,4.54,0.36,-0.63,1.34,2.55,2.16,-3.80,0.64,3.09,-1.68,-2.88,1.50,-2.90,0.44,4.54,-0.89,-4.01,-0.79,5.23,1.80,-1.70,-1.75,2.75,0.65,1.41,-0.38,1.68,0.36,1.82,0.71,5.23,2.58,3.38,-0.33,1.05,0.72,-4.80,0.45,0.64,4.87,2.82,-1.84,4.36,-5.35,2.57,-1.07,3.25,2.03,-1.76,1.40,0.94,1.42,2.08,2.52,3.06,2.92,-1.68,-0.52,0.98,-2.38,-4.18,1.51,4.75,-5.27,-1.58,0.82,3.01,-3.47,5.76,3.65,1.74,3.43,-0.03,2.57,-0.92,1.52,4.33,-0.83,-1.87,1.36,3.14,0.68,-2.79,1.98,3.05,-1.23,0.35,-1.50,-2.11,2.70,-2.04,-2.60,1.25,3.29,0.16,-5.95,-4.38,4.71,0.74,4.00,-0.88,-3.36,-1.64,-0.36,2.56,-0.03,4.15,1.51,-1.24,2.64,1.42,2.84,3.48,-1.66,0.95,-1.48,-0.85,-2.85,-1.27,-0.91,-0.69,-0.37,-1.76,1.42,1.01,-1.77,4.88,2.69,1.56,2.97,0.16,-1.25,5.63,7.64,-0.87,-1.67,-1.81,6.55,0.75,1.63,3.18,1.63,-0.84,-0.73,-3.25,-1.63,-2.16,2.26,-0.61,0.26,4.48,0.37,3.85,0.58,6.11,3.29,-4.73,0.45,-2.49,2.46,0.84,-0.57,-1.26,-2.81,-3.04,0.75,0.86,-1.40,3.68,1.06,-1.74,1.09,-1.45,-0.15,3.22,1.73,0.96,6.33,-0.47,3.05,-0.81,-2.77,5.02,0.77,2.67,-1.89,1.61,0.04,5.41,-2.47,-2.13,3.01,-0.39,-1.43,-3.26,0.60,-6.99,-1.42,1.86,-1.05,4.28,3.30,-1.07,2.61,0.43,3.26,-1.15,1.42,3.08,-0.84,-3.31,-2.90,-1.51,4.98,1.83,-3.02,3.82,3.37,3.14,1.67,-4.88,-1.29,-0.55,-0.02,1.19,-0.19,-0.97,1.76,2.72,2.27,1.12,0.49,-2.16,2.99,2.92,4.96,-1.48,3.09,3.14,3.27,-2.76,0.92,0.79,2.31,-2.08,-0.17,-3.32,-0.65,-1.84,-0.00,3.97,0.11,-4.83,2.82,0.90,-0.21,0.05,3.01,2.08,-0.40,1.79,2.42,-5.49,2.19,-0.85,-1.49,2.75,-1.12,-1.90,2.90,3.56,-2.92,-0.30,0.73,-1.08,-0.09,1.47,3.88,2.52,0.49,1.95,-3.85,1.91,-2.64,2.40,2.50,-0.75,3.64,-0.77,-3.74,5.11,-0.05,4.33,2.16,-0.76,2.56,2.89,0.76,3.07,-0.97,3.60,-2.50,4.04,-0.47,5.05,2.59,1.97,3.64,-1.42,-2.10,-0.15,1.24,-0.55,2.92,-0.00,1.52,5.63,-4.85,1.74,6.79,2.56,0.43,0.12,-0.46,2.45,4.56,1.12,-3.23,-0.18,-0.66,-0.63,-5.60,-2.99,2.09,12.12,0.34,3.05,0.51,-3.73,1.30,2.86,-2.70,4.31,-1.04,1.79,-1.47,1.19,1.09,2.63,-3.55,0.40,1.13,-2.64,-1.64,0.72,-0.32,0.42,2.57,-2.48,6.11,-0.28,3.41,-0.88,-0.61,-0.45,-1.05,-0.70,-3.26,4.73,1.01,-0.49,1.78,-2.43,-0.31,2.49,3.76,1.13,-2.29,3.30,0.82,2.23,-0.74,0.76,2.54,3.78,-1.88,2.03,0.98,1.19,0.62,0.65,-4.53,2.22,-0.27,0.00,-4.78,3.39,-0.42,-0.12,4.18,2.44,4.92,-0.25,-0.67,2.65,1.79,1.82,0.63,-1.06,0.60,3.51,0.13,-3.21,2.13,3.33,-4.90,1.38,1.26,2.05,5.01,0.94,-0.67,3.73,4.20,1.89,0.18,-1.05,2.47,3.57,3.15,6.09,-2.41,6.57,3.23,-0.76,0.59,2.29,-1.76,3.00,2.58,4.45,0.91,0.25,5.14,4.13,1.49,7.44,1.88,-3.80,-0.85,0.25,1.75,-0.03,-5.38,4.03,4.32,-3.25,-0.50,-3.08,-1.16,-0.07,1.64,-0.66,0.24,0.87,-0.67,-2.98,-1.65,3.55,0.92,1.97,-1.12,1.98,-4.02,4.99,4.71,2.32,3.60,0.78,0.46,0.20,2.98,1.96,0.18,1.55,0.50,0.89,-0.54,-0.03,-0.24,2.56,2.69,3.13,0.35,2.21,-1.98,-2.92,1.97,-5.28,2.69,-1.53,-1.02,6.48,0.28,1.14,-3.50,4.11,3.12,2.99,4.56,0.88,3.92,2.13,5.29,-0.07,0.08,1.82,3.84,-0.76,0.69,-2.83,3.90,5.21,1.62,0.43,-1.17,0.32,1.28,5.15,1.68,-1.09,0.87,1.42,1.40,1.15,2.06,-2.50,1.39,1.33,-3.19,0.92,4.35,3.13,2.95,3.52,1.17,-0.27,2.53,1.01,-0.26,0.07,-0.97,0.58,2.67,-0.56,-2.09,1.15,-1.25,1.24,3.39,2.58,-3.03,1.51,0.29,1.83,0.83,-1.73,-1.20,5.77,3.02,-2.64,2.81,-3.81,-2.40,-1.80,-0.46,-0.27,1.28,5.90,-0.35,0.10,3.36,0.28,-0.78,3.76,2.76,-0.03,-4.79,1.17,5.17,-0.60,0.68,-0.05,1.36,0.08,-1.30,-2.25,5.58,6.21,-1.34,1.56,-2.20,-2.57,0.61,-1.32,1.50,-2.46,-2.25,1.50,-1.70,1.30,2.86,-3.36,-3.31,1.48,3.79,-1.93,-0.50,1.31,1.01,2.14,5.68,1.86,1.19,2.49,2.41,0.79,1.91,-0.30,0.89,0.48,-2.64,-2.39,-1.30,0.98,3.88,1.01,-2.56,2.87,-1.81,6.26,3.16,4.12,7.24,-1.51,3.04,1.18,2.38,-0.39,1.53,1.99,2.19,-0.10,-0.76,0.34,-3.89,-1.39,-1.12,0.42,5.70,3.15,0.52,0.65,-0.96,2.91,4.12,5.32,2.71,1.41,3.95,1.09,2.18,-4.71,1.74,-0.38,2.30,-2.79,-2.47,-3.64,0.47,-2.54,0.41,3.57,1.48,1.86,1.30,0.24,-1.21,-3.44,0.64,-1.12,-0.73,0.67,5.25,3.46,3.01,0.40,6.21,1.22,1.56,-2.14,-2.74,-2.48,3.97,0.08,-6.22,2.35,-0.68,-0.85,0.48,4.86,3.88,2.55,-2.48,-1.94,2.15,1.24,-0.67,0.38,-0.98,-1.81,2.88,-1.48,-1.48,0.46,0.99,-3.68,2.31,1.57,-2.85,-3.35,1.75,5.00,-2.18,4.50,-1.97,2.79,0.05,-0.69,1.64,2.02,-2.79,-1.37,-3.06,3.90,-1.87,3.02,4.74,3.12,-0.50,1.15,0.61,-0.90,0.84,2.13,4.06,3.10,0.61,-2.50,-1.32,3.26,2.42,-1.99,-2.61,2.66,-1.98,2.89,-2.14,-3.84,-2.21,1.47,-1.12,-1.40,6.85,2.31,-4.18,-1.05,0.87,-3.27,-2.17,5.51,2.46,-0.40,3.01,0.57,0.49,4.13,3.49,0.82,-0.02,-1.37,-1.40,5.08,0.93,2.99,1.51,6.54,-0.33,0.78,1.37,1.86,-1.02,2.58,3.43,-1.33,4.62,0.08,1.19,-3.02,3.23,2.72,1.46,-3.01,2.88,-4.22,-3.44,3.34,-1.74,3.27,-2.14,1.49,5.06,-0.58,-0.82,4.67,3.11,-1.52,-2.48,3.49,2.71,2.41,3.64,-1.90,-0.72,-4.40,-0.25,1.80,2.75,-3.83,-3.99,3.26,5.55,-3.82,-2.66,-3.94,2.69,-1.46,-1.83,-3.02,2.38,2.65,-0.86,3.08,4.02,3.34,1.69,2.67,0.27,3.76,1.52,1.79,-2.45,4.98,0.60,1.06,-0.63,-1.74,-2.53,-2.16,-1.28,3.36,2.04,-3.88,1.32,-3.20,-1.90,1.50,-2.52,2.53,-2.99,-0.68,4.30,0.75,-0.47,2.90,0.87,-0.17,-0.33,3.14,3.41,-1.13,2.45,-0.55,-0.20,2.49,-0.94,-1.72,3.62,0.67,-0.14,-2.32,0.62,-0.12,0.18,-0.30,-4.03,3.14,-1.17,1.14,-1.04,3.83,1.84,-0.34,2.87,-2.58,3.24,-0.18,6.23,-0.81,1.45,1.30,-0.95,-0.20,1.26,0.40,3.81,-2.37,3.12,0.11,3.95,-3.86,3.39,-2.35,0.75,2.48,0.62,1.41,-1.71,4.69,2.52,-0.32,-0.97,-0.42,-0.06,3.43,2.04,3.84,-0.82,2.70,3.47,2.26,-5.39,0.55,2.30,1.53,1.46,-3.24,2.83,0.86,0.06,2.05,0.48,-3.97,1.81,2.38,1.62,-1.44,-1.87,0.55,1.39,1.83,-0.04,-1.93,0.17,3.66,1.99,2.95,2.88,2.97,-1.67,2.66,-2.85,1.31,-3.42,0.59,2.08,-0.97,0.31,-2.06,0.72,-1.53,-0.18,-0.84,2.16,1.18,1.01,-0.53,-0.78,2.09,3.42,1.93,3.40,-0.04,2.21,-2.95,-0.52,-2.58,1.69,4.85,-0.62,-0.33,3.86,-0.37,1.32,-1.43,0.83,6.14,0.61,2.94,-0.04,-0.32,-0.70,8.21,0.71,0.53,2.04,0.14,0.72,-2.54,4.67,-1.68,2.81,1.26,-4.14,2.50,3.89,5.78,-1.78,-0.01,-0.86,-2.01,2.34,-4.43,2.40,0.62
2023-07-16 21:20:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: start from epoch 1, loss = 0.8322
2023-07-16 21:20:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-16 21:20:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 9.43e+03 batches (snr_loss = -3.71)...
2023-07-16 21:20:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 9.43e+03 batches (ce_loss = +3.88)...
2023-07-16 21:20:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:20:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 9.43e+03 batches (loss = -1.74)...
2023-07-16 21:20:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 9.43e+03 batches (norm = +8.20)...
2023-07-16 21:21:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 9.43e+03 batches (snr_loss = -4.25)...
2023-07-16 21:21:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 9.43e+03 batches (ce_loss = +3.84)...
2023-07-16 21:21:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:21:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 9.43e+03 batches (loss = -2.30)...
2023-07-16 21:21:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 9.43e+03 batches (norm = +11.38)...
2023-07-16 21:21:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 9.43e+03 batches (snr_loss = -4.13)...
2023-07-16 21:21:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 9.43e+03 batches (ce_loss = +3.85)...
2023-07-16 21:21:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:21:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 9.43e+03 batches (loss = -2.17)...
2023-07-16 21:21:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 9.43e+03 batches (norm = +10.09)...
2023-07-16 21:21:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 9.43e+03 batches (snr_loss = -4.50)...
2023-07-16 21:21:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 9.43e+03 batches (ce_loss = +3.86)...
2023-07-16 21:21:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:21:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 9.43e+03 batches (loss = -2.54)...
2023-07-16 21:21:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 9.43e+03 batches (norm = +13.82)...
2023-07-16 21:22:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 9.43e+03 batches (snr_loss = -4.50)...
2023-07-16 21:22:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 9.43e+03 batches (ce_loss = +3.86)...
2023-07-16 21:22:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:22:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 9.43e+03 batches (loss = -2.53)...
2023-07-16 21:22:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 9.43e+03 batches (norm = +9.66)...
2023-07-16 21:22:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 9.43e+03 batches (snr_loss = -4.52)...
2023-07-16 21:22:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 9.43e+03 batches (ce_loss = +3.84)...
2023-07-16 21:22:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:22:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 9.43e+03 batches (loss = -2.57)...
2023-07-16 21:22:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 9.43e+03 batches (norm = +8.68)...
2023-07-16 21:22:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 9.43e+03 batches (snr_loss = -3.86)...
2023-07-16 21:22:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 9.43e+03 batches (ce_loss = +3.81)...
2023-07-16 21:22:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:22:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 9.43e+03 batches (loss = -1.92)...
2023-07-16 21:22:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 9.43e+03 batches (norm = +11.19)...
2023-07-16 21:23:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 9.43e+03 batches (snr_loss = -3.80)...
2023-07-16 21:23:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 9.43e+03 batches (ce_loss = +3.84)...
2023-07-16 21:23:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:23:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 9.43e+03 batches (loss = -1.85)...
2023-07-16 21:23:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 9.43e+03 batches (norm = +15.13)...
2023-07-16 21:23:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 9.43e+03 batches (snr_loss = -4.00)...
2023-07-16 21:23:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 9.43e+03 batches (ce_loss = +3.82)...
2023-07-16 21:23:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:23:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 9.43e+03 batches (loss = -2.06)...
2023-07-16 21:23:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 9.43e+03 batches (norm = +25.06)...
2023-07-16 21:24:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 9.43e+03 batches (snr_loss = -4.36)...
2023-07-16 21:24:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 9.43e+03 batches (ce_loss = +3.81)...
2023-07-16 21:24:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:24:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 9.43e+03 batches (loss = -2.43)...
2023-07-16 21:24:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 9.43e+03 batches (norm = +17.66)...
2023-07-16 21:24:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 9.43e+03 batches (snr_loss = -4.20)...
2023-07-16 21:24:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 9.43e+03 batches (ce_loss = +3.82)...
2023-07-16 21:24:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:24:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 9.43e+03 batches (loss = -2.26)...
2023-07-16 21:24:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 9.43e+03 batches (norm = +9.63)...
2023-07-16 21:24:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.20e+03 / 9.43e+03 batches (snr_loss = -4.12)...
2023-07-16 21:24:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.20e+03 / 9.43e+03 batches (ce_loss = +3.77)...
2023-07-16 21:24:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.20e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:24:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.20e+03 / 9.43e+03 batches (loss = -2.20)...
2023-07-16 21:24:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.20e+03 / 9.43e+03 batches (norm = +33.81)...
2023-07-16 21:25:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.30e+03 / 9.43e+03 batches (snr_loss = -4.47)...
2023-07-16 21:25:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.30e+03 / 9.43e+03 batches (ce_loss = +3.83)...
2023-07-16 21:25:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.30e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:25:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.30e+03 / 9.43e+03 batches (loss = -2.53)...
2023-07-16 21:25:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.30e+03 / 9.43e+03 batches (norm = +14.57)...
2023-07-16 21:25:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.40e+03 / 9.43e+03 batches (snr_loss = -4.30)...
2023-07-16 21:25:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.40e+03 / 9.43e+03 batches (ce_loss = +3.77)...
2023-07-16 21:25:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.40e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:25:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.40e+03 / 9.43e+03 batches (loss = -2.39)...
2023-07-16 21:25:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.40e+03 / 9.43e+03 batches (norm = +12.66)...
2023-07-16 21:25:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.50e+03 / 9.43e+03 batches (snr_loss = -3.75)...
2023-07-16 21:25:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.50e+03 / 9.43e+03 batches (ce_loss = +3.80)...
2023-07-16 21:25:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.50e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:25:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.50e+03 / 9.43e+03 batches (loss = -1.82)...
2023-07-16 21:25:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.50e+03 / 9.43e+03 batches (norm = +13.69)...
2023-07-16 21:26:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.60e+03 / 9.43e+03 batches (snr_loss = -3.96)...
2023-07-16 21:26:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.60e+03 / 9.43e+03 batches (ce_loss = +3.78)...
2023-07-16 21:26:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.60e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:26:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.60e+03 / 9.43e+03 batches (loss = -2.04)...
2023-07-16 21:26:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.60e+03 / 9.43e+03 batches (norm = +11.66)...
2023-07-16 21:26:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.70e+03 / 9.43e+03 batches (snr_loss = -4.31)...
2023-07-16 21:26:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.70e+03 / 9.43e+03 batches (ce_loss = +3.77)...
2023-07-16 21:26:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.70e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:26:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.70e+03 / 9.43e+03 batches (loss = -2.40)...
2023-07-16 21:26:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.70e+03 / 9.43e+03 batches (norm = +17.22)...
2023-07-16 21:27:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.80e+03 / 9.43e+03 batches (snr_loss = -4.27)...
2023-07-16 21:27:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.80e+03 / 9.43e+03 batches (ce_loss = +3.79)...
2023-07-16 21:27:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.80e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:27:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.80e+03 / 9.43e+03 batches (loss = -2.35)...
2023-07-16 21:27:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.80e+03 / 9.43e+03 batches (norm = +19.78)...
2023-07-16 21:27:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.90e+03 / 9.43e+03 batches (snr_loss = -4.66)...
2023-07-16 21:27:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.90e+03 / 9.43e+03 batches (ce_loss = +3.81)...
2023-07-16 21:27:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.90e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:27:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.90e+03 / 9.43e+03 batches (loss = -2.73)...
2023-07-16 21:27:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.90e+03 / 9.43e+03 batches (norm = +19.86)...
2023-07-16 21:27:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+03 / 9.43e+03 batches (snr_loss = -4.69)...
2023-07-16 21:27:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+03 / 9.43e+03 batches (ce_loss = +3.75)...
2023-07-16 21:27:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:27:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+03 / 9.43e+03 batches (loss = -2.79)...
2023-07-16 21:27:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+03 / 9.43e+03 batches (norm = +14.96)...
2023-07-16 21:28:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.10e+03 / 9.43e+03 batches (snr_loss = -4.41)...
2023-07-16 21:28:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.10e+03 / 9.43e+03 batches (ce_loss = +3.81)...
2023-07-16 21:28:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.10e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:28:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.10e+03 / 9.43e+03 batches (loss = -2.47)...
2023-07-16 21:28:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.10e+03 / 9.43e+03 batches (norm = +9.89)...
2023-07-16 21:28:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.20e+03 / 9.43e+03 batches (snr_loss = -4.97)...
2023-07-16 21:28:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.20e+03 / 9.43e+03 batches (ce_loss = +3.72)...
2023-07-16 21:28:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.20e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:28:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.20e+03 / 9.43e+03 batches (loss = -3.09)...
2023-07-16 21:28:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.20e+03 / 9.43e+03 batches (norm = +15.80)...
2023-07-16 21:29:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.30e+03 / 9.43e+03 batches (snr_loss = -4.37)...
2023-07-16 21:29:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.30e+03 / 9.43e+03 batches (ce_loss = +3.77)...
2023-07-16 21:29:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.30e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:29:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.30e+03 / 9.43e+03 batches (loss = -2.46)...
2023-07-16 21:29:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.30e+03 / 9.43e+03 batches (norm = +14.15)...
2023-07-16 21:29:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.40e+03 / 9.43e+03 batches (snr_loss = -4.73)...
2023-07-16 21:29:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.40e+03 / 9.43e+03 batches (ce_loss = +3.74)...
2023-07-16 21:29:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.40e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:29:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.40e+03 / 9.43e+03 batches (loss = -2.83)...
2023-07-16 21:29:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.40e+03 / 9.43e+03 batches (norm = +12.69)...
2023-07-16 21:30:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.50e+03 / 9.43e+03 batches (snr_loss = -4.64)...
2023-07-16 21:30:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.50e+03 / 9.43e+03 batches (ce_loss = +3.71)...
2023-07-16 21:30:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.50e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:30:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.50e+03 / 9.43e+03 batches (loss = -2.76)...
2023-07-16 21:30:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.50e+03 / 9.43e+03 batches (norm = +22.95)...
2023-07-16 21:30:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.60e+03 / 9.43e+03 batches (snr_loss = -4.60)...
2023-07-16 21:30:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.60e+03 / 9.43e+03 batches (ce_loss = +3.71)...
2023-07-16 21:30:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.60e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:30:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.60e+03 / 9.43e+03 batches (loss = -2.72)...
2023-07-16 21:30:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.60e+03 / 9.43e+03 batches (norm = +11.90)...
2023-07-16 21:31:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.70e+03 / 9.43e+03 batches (snr_loss = -4.73)...
2023-07-16 21:31:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.70e+03 / 9.43e+03 batches (ce_loss = +3.75)...
2023-07-16 21:31:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.70e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:31:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.70e+03 / 9.43e+03 batches (loss = -2.83)...
2023-07-16 21:31:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.70e+03 / 9.43e+03 batches (norm = +11.52)...
2023-07-16 21:31:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.80e+03 / 9.43e+03 batches (snr_loss = -4.45)...
2023-07-16 21:31:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.80e+03 / 9.43e+03 batches (ce_loss = +3.72)...
2023-07-16 21:31:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.80e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:31:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.80e+03 / 9.43e+03 batches (loss = -2.56)...
2023-07-16 21:31:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.80e+03 / 9.43e+03 batches (norm = +13.07)...
2023-07-16 21:32:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.90e+03 / 9.43e+03 batches (snr_loss = -4.80)...
2023-07-16 21:32:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.90e+03 / 9.43e+03 batches (ce_loss = +3.75)...
2023-07-16 21:32:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.90e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:32:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.90e+03 / 9.43e+03 batches (loss = -2.89)...
2023-07-16 21:32:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.90e+03 / 9.43e+03 batches (norm = +13.74)...
2023-07-16 21:32:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+03 / 9.43e+03 batches (snr_loss = -4.37)...
2023-07-16 21:32:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+03 / 9.43e+03 batches (ce_loss = +3.72)...
2023-07-16 21:32:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:32:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+03 / 9.43e+03 batches (loss = -2.48)...
2023-07-16 21:32:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+03 / 9.43e+03 batches (norm = +11.35)...
2023-07-16 21:32:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.10e+03 / 9.43e+03 batches (snr_loss = -3.89)...
2023-07-16 21:32:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.10e+03 / 9.43e+03 batches (ce_loss = +3.65)...
2023-07-16 21:32:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.10e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:32:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.10e+03 / 9.43e+03 batches (loss = -2.04)...
2023-07-16 21:32:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.10e+03 / 9.43e+03 batches (norm = +11.17)...
2023-07-16 21:33:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.20e+03 / 9.43e+03 batches (snr_loss = -4.15)...
2023-07-16 21:33:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.20e+03 / 9.43e+03 batches (ce_loss = +3.65)...
2023-07-16 21:33:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.20e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:33:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.20e+03 / 9.43e+03 batches (loss = -2.29)...
2023-07-16 21:33:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.20e+03 / 9.43e+03 batches (norm = +16.22)...
2023-07-16 21:33:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.30e+03 / 9.43e+03 batches (snr_loss = -4.50)...
2023-07-16 21:33:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.30e+03 / 9.43e+03 batches (ce_loss = +3.66)...
2023-07-16 21:33:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.30e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:33:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.30e+03 / 9.43e+03 batches (loss = -2.64)...
2023-07-16 21:33:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.30e+03 / 9.43e+03 batches (norm = +11.07)...
2023-07-16 21:33:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.40e+03 / 9.43e+03 batches (snr_loss = -4.56)...
2023-07-16 21:33:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.40e+03 / 9.43e+03 batches (ce_loss = +3.74)...
2023-07-16 21:33:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.40e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:33:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.40e+03 / 9.43e+03 batches (loss = -2.66)...
2023-07-16 21:33:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.40e+03 / 9.43e+03 batches (norm = +14.70)...
2023-07-16 21:34:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.50e+03 / 9.43e+03 batches (snr_loss = -4.40)...
2023-07-16 21:34:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.50e+03 / 9.43e+03 batches (ce_loss = +3.69)...
2023-07-16 21:34:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.50e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:34:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.50e+03 / 9.43e+03 batches (loss = -2.53)...
2023-07-16 21:34:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.50e+03 / 9.43e+03 batches (norm = +11.24)...
2023-07-16 21:34:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.60e+03 / 9.43e+03 batches (snr_loss = -4.87)...
2023-07-16 21:34:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.60e+03 / 9.43e+03 batches (ce_loss = +3.70)...
2023-07-16 21:34:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.60e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:34:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.60e+03 / 9.43e+03 batches (loss = -2.99)...
2023-07-16 21:34:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.60e+03 / 9.43e+03 batches (norm = +22.09)...
2023-07-16 21:35:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.70e+03 / 9.43e+03 batches (snr_loss = -4.38)...
2023-07-16 21:35:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.70e+03 / 9.43e+03 batches (ce_loss = +3.68)...
2023-07-16 21:35:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.70e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:35:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.70e+03 / 9.43e+03 batches (loss = -2.51)...
2023-07-16 21:35:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.70e+03 / 9.43e+03 batches (norm = +12.85)...
2023-07-16 21:35:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.80e+03 / 9.43e+03 batches (snr_loss = -4.78)...
2023-07-16 21:35:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.80e+03 / 9.43e+03 batches (ce_loss = +3.67)...
2023-07-16 21:35:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.80e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:35:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.80e+03 / 9.43e+03 batches (loss = -2.92)...
2023-07-16 21:35:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.80e+03 / 9.43e+03 batches (norm = +12.72)...
2023-07-16 21:35:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.90e+03 / 9.43e+03 batches (snr_loss = -4.45)...
2023-07-16 21:35:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.90e+03 / 9.43e+03 batches (ce_loss = +3.65)...
2023-07-16 21:35:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.90e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:35:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.90e+03 / 9.43e+03 batches (loss = -2.60)...
2023-07-16 21:35:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.90e+03 / 9.43e+03 batches (norm = +11.86)...
2023-07-16 21:36:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+03 / 9.43e+03 batches (snr_loss = -4.05)...
2023-07-16 21:36:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+03 / 9.43e+03 batches (ce_loss = +3.68)...
2023-07-16 21:36:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:36:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+03 / 9.43e+03 batches (loss = -2.18)...
2023-07-16 21:36:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+03 / 9.43e+03 batches (norm = +15.63)...
2023-07-16 21:36:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.10e+03 / 9.43e+03 batches (snr_loss = -4.62)...
2023-07-16 21:36:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.10e+03 / 9.43e+03 batches (ce_loss = +3.62)...
2023-07-16 21:36:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.10e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:36:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.10e+03 / 9.43e+03 batches (loss = -2.78)...
2023-07-16 21:36:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.10e+03 / 9.43e+03 batches (norm = +12.36)...
2023-07-16 21:37:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.20e+03 / 9.43e+03 batches (snr_loss = -4.10)...
2023-07-16 21:37:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.20e+03 / 9.43e+03 batches (ce_loss = +3.65)...
2023-07-16 21:37:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.20e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:37:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.20e+03 / 9.43e+03 batches (loss = -2.25)...
2023-07-16 21:37:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.20e+03 / 9.43e+03 batches (norm = +9.49)...
2023-07-16 21:37:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.30e+03 / 9.43e+03 batches (snr_loss = -4.19)...
2023-07-16 21:37:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.30e+03 / 9.43e+03 batches (ce_loss = +3.65)...
2023-07-16 21:37:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.30e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:37:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.30e+03 / 9.43e+03 batches (loss = -2.33)...
2023-07-16 21:37:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.30e+03 / 9.43e+03 batches (norm = +14.69)...
2023-07-16 21:38:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.40e+03 / 9.43e+03 batches (snr_loss = -4.16)...
2023-07-16 21:38:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.40e+03 / 9.43e+03 batches (ce_loss = +3.65)...
2023-07-16 21:38:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.40e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:38:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.40e+03 / 9.43e+03 batches (loss = -2.30)...
2023-07-16 21:38:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.40e+03 / 9.43e+03 batches (norm = +9.76)...
2023-07-16 21:38:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.50e+03 / 9.43e+03 batches (snr_loss = -4.43)...
2023-07-16 21:38:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.50e+03 / 9.43e+03 batches (ce_loss = +3.58)...
2023-07-16 21:38:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.50e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:38:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.50e+03 / 9.43e+03 batches (loss = -2.61)...
2023-07-16 21:38:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.50e+03 / 9.43e+03 batches (norm = +13.17)...
2023-07-16 21:39:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.60e+03 / 9.43e+03 batches (snr_loss = -4.10)...
2023-07-16 21:39:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.60e+03 / 9.43e+03 batches (ce_loss = +3.62)...
2023-07-16 21:39:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.60e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:39:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.60e+03 / 9.43e+03 batches (loss = -2.26)...
2023-07-16 21:39:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.60e+03 / 9.43e+03 batches (norm = +13.64)...
2023-07-16 21:39:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.70e+03 / 9.43e+03 batches (snr_loss = -4.10)...
2023-07-16 21:39:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.70e+03 / 9.43e+03 batches (ce_loss = +3.66)...
2023-07-16 21:39:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.70e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:39:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.70e+03 / 9.43e+03 batches (loss = -2.25)...
2023-07-16 21:39:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.70e+03 / 9.43e+03 batches (norm = +78.60)...
2023-07-16 21:40:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.80e+03 / 9.43e+03 batches (snr_loss = -4.04)...
2023-07-16 21:40:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.80e+03 / 9.43e+03 batches (ce_loss = +3.59)...
2023-07-16 21:40:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.80e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:40:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.80e+03 / 9.43e+03 batches (loss = -2.21)...
2023-07-16 21:40:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.80e+03 / 9.43e+03 batches (norm = +10.05)...
2023-07-16 21:40:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.90e+03 / 9.43e+03 batches (snr_loss = -3.92)...
2023-07-16 21:40:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.90e+03 / 9.43e+03 batches (ce_loss = +3.66)...
2023-07-16 21:40:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.90e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:40:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.90e+03 / 9.43e+03 batches (loss = -2.07)...
2023-07-16 21:40:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.90e+03 / 9.43e+03 batches (norm = +26.42)...
2023-07-16 21:41:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+03 / 9.43e+03 batches (snr_loss = -4.53)...
2023-07-16 21:41:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+03 / 9.43e+03 batches (ce_loss = +3.60)...
2023-07-16 21:41:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:41:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+03 / 9.43e+03 batches (loss = -2.70)...
2023-07-16 21:41:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+03 / 9.43e+03 batches (norm = +12.43)...
2023-07-16 21:42:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.10e+03 / 9.43e+03 batches (snr_loss = -5.10)...
2023-07-16 21:42:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.10e+03 / 9.43e+03 batches (ce_loss = +3.63)...
2023-07-16 21:42:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.10e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:42:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.10e+03 / 9.43e+03 batches (loss = -3.25)...
2023-07-16 21:42:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.10e+03 / 9.43e+03 batches (norm = +13.33)...
2023-07-16 21:42:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.20e+03 / 9.43e+03 batches (snr_loss = -4.52)...
2023-07-16 21:42:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.20e+03 / 9.43e+03 batches (ce_loss = +3.63)...
2023-07-16 21:42:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.20e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:42:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.20e+03 / 9.43e+03 batches (loss = -2.67)...
2023-07-16 21:42:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.20e+03 / 9.43e+03 batches (norm = +10.31)...
2023-07-16 21:43:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.30e+03 / 9.43e+03 batches (snr_loss = -4.07)...
2023-07-16 21:43:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.30e+03 / 9.43e+03 batches (ce_loss = +3.62)...
2023-07-16 21:43:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.30e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:43:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.30e+03 / 9.43e+03 batches (loss = -2.24)...
2023-07-16 21:43:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.30e+03 / 9.43e+03 batches (norm = +11.58)...
2023-07-16 21:44:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.40e+03 / 9.43e+03 batches (snr_loss = -4.64)...
2023-07-16 21:44:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.40e+03 / 9.43e+03 batches (ce_loss = +3.59)...
2023-07-16 21:44:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.40e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:44:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.40e+03 / 9.43e+03 batches (loss = -2.82)...
2023-07-16 21:44:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.40e+03 / 9.43e+03 batches (norm = +65.94)...
2023-07-16 21:44:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.50e+03 / 9.43e+03 batches (snr_loss = -3.77)...
2023-07-16 21:44:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.50e+03 / 9.43e+03 batches (ce_loss = +3.63)...
2023-07-16 21:44:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.50e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:44:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.50e+03 / 9.43e+03 batches (loss = -1.92)...
2023-07-16 21:44:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.50e+03 / 9.43e+03 batches (norm = +109.49)...
2023-07-16 21:44:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.60e+03 / 9.43e+03 batches (snr_loss = -4.64)...
2023-07-16 21:44:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.60e+03 / 9.43e+03 batches (ce_loss = +3.61)...
2023-07-16 21:44:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.60e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:44:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.60e+03 / 9.43e+03 batches (loss = -2.80)...
2023-07-16 21:44:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.60e+03 / 9.43e+03 batches (norm = +13.09)...
2023-07-16 21:45:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.70e+03 / 9.43e+03 batches (snr_loss = -4.47)...
2023-07-16 21:45:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.70e+03 / 9.43e+03 batches (ce_loss = +3.59)...
2023-07-16 21:45:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.70e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:45:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.70e+03 / 9.43e+03 batches (loss = -2.65)...
2023-07-16 21:45:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.70e+03 / 9.43e+03 batches (norm = +16.82)...
2023-07-16 21:45:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.80e+03 / 9.43e+03 batches (snr_loss = -4.71)...
2023-07-16 21:45:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.80e+03 / 9.43e+03 batches (ce_loss = +3.63)...
2023-07-16 21:45:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.80e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:45:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.80e+03 / 9.43e+03 batches (loss = -2.87)...
2023-07-16 21:45:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.80e+03 / 9.43e+03 batches (norm = +10.89)...
2023-07-16 21:46:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.90e+03 / 9.43e+03 batches (snr_loss = -4.81)...
2023-07-16 21:46:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.90e+03 / 9.43e+03 batches (ce_loss = +3.54)...
2023-07-16 21:46:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.90e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:46:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.90e+03 / 9.43e+03 batches (loss = -3.01)...
2023-07-16 21:46:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.90e+03 / 9.43e+03 batches (norm = +21.51)...
2023-07-16 21:47:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+03 / 9.43e+03 batches (snr_loss = -4.52)...
2023-07-16 21:47:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+03 / 9.43e+03 batches (ce_loss = +3.54)...
2023-07-16 21:47:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:47:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+03 / 9.43e+03 batches (loss = -2.72)...
2023-07-16 21:47:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+03 / 9.43e+03 batches (norm = +346.07)...
2023-07-16 21:47:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.10e+03 / 9.43e+03 batches (snr_loss = -5.03)...
2023-07-16 21:47:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.10e+03 / 9.43e+03 batches (ce_loss = +3.57)...
2023-07-16 21:47:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.10e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:47:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.10e+03 / 9.43e+03 batches (loss = -3.21)...
2023-07-16 21:47:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.10e+03 / 9.43e+03 batches (norm = +14.34)...
2023-07-16 21:48:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.20e+03 / 9.43e+03 batches (snr_loss = -4.46)...
2023-07-16 21:48:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.20e+03 / 9.43e+03 batches (ce_loss = +3.58)...
2023-07-16 21:48:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.20e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:48:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.20e+03 / 9.43e+03 batches (loss = -2.65)...
2023-07-16 21:48:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.20e+03 / 9.43e+03 batches (norm = +27.00)...
2023-07-16 21:48:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.30e+03 / 9.43e+03 batches (snr_loss = -4.75)...
2023-07-16 21:48:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.30e+03 / 9.43e+03 batches (ce_loss = +3.55)...
2023-07-16 21:48:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.30e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:48:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.30e+03 / 9.43e+03 batches (loss = -2.94)...
2023-07-16 21:48:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.30e+03 / 9.43e+03 batches (norm = +15.53)...
2023-07-16 21:49:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.40e+03 / 9.43e+03 batches (snr_loss = -4.77)...
2023-07-16 21:49:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.40e+03 / 9.43e+03 batches (ce_loss = +3.56)...
2023-07-16 21:49:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.40e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:49:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.40e+03 / 9.43e+03 batches (loss = -2.97)...
2023-07-16 21:49:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.40e+03 / 9.43e+03 batches (norm = +17.79)...
2023-07-16 21:49:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.50e+03 / 9.43e+03 batches (snr_loss = -4.53)...
2023-07-16 21:49:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.50e+03 / 9.43e+03 batches (ce_loss = +3.55)...
2023-07-16 21:49:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.50e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:49:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.50e+03 / 9.43e+03 batches (loss = -2.72)...
2023-07-16 21:49:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.50e+03 / 9.43e+03 batches (norm = +14.03)...
2023-07-16 21:50:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.60e+03 / 9.43e+03 batches (snr_loss = -4.37)...
2023-07-16 21:50:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.60e+03 / 9.43e+03 batches (ce_loss = +3.51)...
2023-07-16 21:50:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.60e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:50:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.60e+03 / 9.43e+03 batches (loss = -2.59)...
2023-07-16 21:50:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.60e+03 / 9.43e+03 batches (norm = +13.14)...
2023-07-16 21:50:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.70e+03 / 9.43e+03 batches (snr_loss = -4.84)...
2023-07-16 21:50:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.70e+03 / 9.43e+03 batches (ce_loss = +3.54)...
2023-07-16 21:50:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.70e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:50:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.70e+03 / 9.43e+03 batches (loss = -3.04)...
2023-07-16 21:50:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.70e+03 / 9.43e+03 batches (norm = +50.44)...
2023-07-16 21:51:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.80e+03 / 9.43e+03 batches (snr_loss = -4.91)...
2023-07-16 21:51:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.80e+03 / 9.43e+03 batches (ce_loss = +3.49)...
2023-07-16 21:51:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.80e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:51:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.80e+03 / 9.43e+03 batches (loss = -3.14)...
2023-07-16 21:51:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.80e+03 / 9.43e+03 batches (norm = +15.44)...
2023-07-16 21:51:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.90e+03 / 9.43e+03 batches (snr_loss = -4.62)...
2023-07-16 21:51:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.90e+03 / 9.43e+03 batches (ce_loss = +3.50)...
2023-07-16 21:51:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.90e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:51:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.90e+03 / 9.43e+03 batches (loss = -2.84)...
2023-07-16 21:51:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.90e+03 / 9.43e+03 batches (norm = +11.70)...
2023-07-16 21:52:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+03 / 9.43e+03 batches (snr_loss = -4.70)...
2023-07-16 21:52:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+03 / 9.43e+03 batches (ce_loss = +3.54)...
2023-07-16 21:52:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:52:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+03 / 9.43e+03 batches (loss = -2.90)...
2023-07-16 21:52:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+03 / 9.43e+03 batches (norm = +9.21)...
2023-07-16 21:52:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.10e+03 / 9.43e+03 batches (snr_loss = -4.50)...
2023-07-16 21:52:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.10e+03 / 9.43e+03 batches (ce_loss = +3.49)...
2023-07-16 21:52:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.10e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:52:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.10e+03 / 9.43e+03 batches (loss = -2.72)...
2023-07-16 21:52:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.10e+03 / 9.43e+03 batches (norm = +10.42)...
2023-07-16 21:53:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.20e+03 / 9.43e+03 batches (snr_loss = -4.55)...
2023-07-16 21:53:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.20e+03 / 9.43e+03 batches (ce_loss = +3.51)...
2023-07-16 21:53:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.20e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:53:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.20e+03 / 9.43e+03 batches (loss = -2.76)...
2023-07-16 21:53:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.20e+03 / 9.43e+03 batches (norm = +19.69)...
2023-07-16 21:53:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.30e+03 / 9.43e+03 batches (snr_loss = -4.39)...
2023-07-16 21:53:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.30e+03 / 9.43e+03 batches (ce_loss = +3.52)...
2023-07-16 21:53:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.30e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:53:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.30e+03 / 9.43e+03 batches (loss = -2.60)...
2023-07-16 21:53:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.30e+03 / 9.43e+03 batches (norm = +14.11)...
2023-07-16 21:53:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.40e+03 / 9.43e+03 batches (snr_loss = -4.54)...
2023-07-16 21:53:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.40e+03 / 9.43e+03 batches (ce_loss = +3.53)...
2023-07-16 21:53:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.40e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:53:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.40e+03 / 9.43e+03 batches (loss = -2.74)...
2023-07-16 21:53:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.40e+03 / 9.43e+03 batches (norm = +13.53)...
2023-07-16 21:54:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.50e+03 / 9.43e+03 batches (snr_loss = -4.77)...
2023-07-16 21:54:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.50e+03 / 9.43e+03 batches (ce_loss = +3.51)...
2023-07-16 21:54:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.50e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:54:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.50e+03 / 9.43e+03 batches (loss = -2.99)...
2023-07-16 21:54:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.50e+03 / 9.43e+03 batches (norm = +22.20)...
2023-07-16 21:54:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.60e+03 / 9.43e+03 batches (snr_loss = -4.56)...
2023-07-16 21:54:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.60e+03 / 9.43e+03 batches (ce_loss = +3.52)...
2023-07-16 21:54:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.60e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:54:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.60e+03 / 9.43e+03 batches (loss = -2.77)...
2023-07-16 21:54:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.60e+03 / 9.43e+03 batches (norm = +20.06)...
2023-07-16 21:55:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.70e+03 / 9.43e+03 batches (snr_loss = -4.41)...
2023-07-16 21:55:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.70e+03 / 9.43e+03 batches (ce_loss = +3.52)...
2023-07-16 21:55:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.70e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:55:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.70e+03 / 9.43e+03 batches (loss = -2.62)...
2023-07-16 21:55:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.70e+03 / 9.43e+03 batches (norm = +21.37)...
2023-07-16 21:55:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.80e+03 / 9.43e+03 batches (snr_loss = -4.73)...
2023-07-16 21:55:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.80e+03 / 9.43e+03 batches (ce_loss = +3.46)...
2023-07-16 21:55:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.80e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:55:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.80e+03 / 9.43e+03 batches (loss = -2.97)...
2023-07-16 21:55:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.80e+03 / 9.43e+03 batches (norm = +17.94)...
2023-07-16 21:56:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.90e+03 / 9.43e+03 batches (snr_loss = -4.03)...
2023-07-16 21:56:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.90e+03 / 9.43e+03 batches (ce_loss = +3.47)...
2023-07-16 21:56:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.90e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:56:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.90e+03 / 9.43e+03 batches (loss = -2.27)...
2023-07-16 21:56:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.90e+03 / 9.43e+03 batches (norm = +13.79)...
2023-07-16 21:56:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+03 / 9.43e+03 batches (snr_loss = -4.30)...
2023-07-16 21:56:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+03 / 9.43e+03 batches (ce_loss = +3.50)...
2023-07-16 21:56:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:56:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+03 / 9.43e+03 batches (loss = -2.53)...
2023-07-16 21:56:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+03 / 9.43e+03 batches (norm = +16.90)...
2023-07-16 21:57:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.10e+03 / 9.43e+03 batches (snr_loss = -3.70)...
2023-07-16 21:57:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.10e+03 / 9.43e+03 batches (ce_loss = +3.49)...
2023-07-16 21:57:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.10e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:57:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.10e+03 / 9.43e+03 batches (loss = -1.92)...
2023-07-16 21:57:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.10e+03 / 9.43e+03 batches (norm = +14.84)...
2023-07-16 21:57:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.20e+03 / 9.43e+03 batches (snr_loss = -4.04)...
2023-07-16 21:57:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.20e+03 / 9.43e+03 batches (ce_loss = +3.43)...
2023-07-16 21:57:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.20e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:57:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.20e+03 / 9.43e+03 batches (loss = -2.30)...
2023-07-16 21:57:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.20e+03 / 9.43e+03 batches (norm = +11.64)...
2023-07-16 21:57:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.30e+03 / 9.43e+03 batches (snr_loss = -4.37)...
2023-07-16 21:57:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.30e+03 / 9.43e+03 batches (ce_loss = +3.47)...
2023-07-16 21:57:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.30e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:57:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.30e+03 / 9.43e+03 batches (loss = -2.60)...
2023-07-16 21:57:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.30e+03 / 9.43e+03 batches (norm = +9.95)...
2023-07-16 21:58:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.40e+03 / 9.43e+03 batches (snr_loss = -4.39)...
2023-07-16 21:58:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.40e+03 / 9.43e+03 batches (ce_loss = +3.47)...
2023-07-16 21:58:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.40e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:58:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.40e+03 / 9.43e+03 batches (loss = -2.63)...
2023-07-16 21:58:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.40e+03 / 9.43e+03 batches (norm = +13.96)...
2023-07-16 21:58:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.50e+03 / 9.43e+03 batches (snr_loss = -4.70)...
2023-07-16 21:58:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.50e+03 / 9.43e+03 batches (ce_loss = +3.47)...
2023-07-16 21:58:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.50e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:58:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.50e+03 / 9.43e+03 batches (loss = -2.94)...
2023-07-16 21:58:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.50e+03 / 9.43e+03 batches (norm = +10.55)...
2023-07-16 21:59:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.60e+03 / 9.43e+03 batches (snr_loss = -4.08)...
2023-07-16 21:59:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.60e+03 / 9.43e+03 batches (ce_loss = +3.49)...
2023-07-16 21:59:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.60e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:59:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.60e+03 / 9.43e+03 batches (loss = -2.31)...
2023-07-16 21:59:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.60e+03 / 9.43e+03 batches (norm = +15.92)...
2023-07-16 21:59:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.70e+03 / 9.43e+03 batches (snr_loss = -4.45)...
2023-07-16 21:59:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.70e+03 / 9.43e+03 batches (ce_loss = +3.47)...
2023-07-16 21:59:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.70e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 21:59:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.70e+03 / 9.43e+03 batches (loss = -2.68)...
2023-07-16 21:59:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.70e+03 / 9.43e+03 batches (norm = +24.03)...
2023-07-16 22:00:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.80e+03 / 9.43e+03 batches (snr_loss = -4.07)...
2023-07-16 22:00:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.80e+03 / 9.43e+03 batches (ce_loss = +3.45)...
2023-07-16 22:00:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.80e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 22:00:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.80e+03 / 9.43e+03 batches (loss = -2.32)...
2023-07-16 22:00:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.80e+03 / 9.43e+03 batches (norm = +13.75)...
2023-07-16 22:00:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.90e+03 / 9.43e+03 batches (snr_loss = -4.72)...
2023-07-16 22:00:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.90e+03 / 9.43e+03 batches (ce_loss = +3.49)...
2023-07-16 22:00:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.90e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 22:00:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.90e+03 / 9.43e+03 batches (loss = -2.95)...
2023-07-16 22:00:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.90e+03 / 9.43e+03 batches (norm = +18.46)...
2023-07-16 22:01:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+03 / 9.43e+03 batches (snr_loss = -4.55)...
2023-07-16 22:01:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+03 / 9.43e+03 batches (ce_loss = +3.45)...
2023-07-16 22:01:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 22:01:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+03 / 9.43e+03 batches (loss = -2.79)...
2023-07-16 22:01:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+03 / 9.43e+03 batches (norm = +10.53)...
2023-07-16 22:01:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.10e+03 / 9.43e+03 batches (snr_loss = -4.82)...
2023-07-16 22:01:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.10e+03 / 9.43e+03 batches (ce_loss = +3.42)...
2023-07-16 22:01:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.10e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 22:01:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.10e+03 / 9.43e+03 batches (loss = -3.09)...
2023-07-16 22:01:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.10e+03 / 9.43e+03 batches (norm = +14.05)...
2023-07-16 22:02:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.20e+03 / 9.43e+03 batches (snr_loss = -4.13)...
2023-07-16 22:02:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.20e+03 / 9.43e+03 batches (ce_loss = +3.42)...
2023-07-16 22:02:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.20e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 22:02:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.20e+03 / 9.43e+03 batches (loss = -2.39)...
2023-07-16 22:02:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.20e+03 / 9.43e+03 batches (norm = +14.12)...
2023-07-16 22:02:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.30e+03 / 9.43e+03 batches (snr_loss = -4.69)...
2023-07-16 22:02:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.30e+03 / 9.43e+03 batches (ce_loss = +3.47)...
2023-07-16 22:02:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.30e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 22:02:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.30e+03 / 9.43e+03 batches (loss = -2.93)...
2023-07-16 22:02:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.30e+03 / 9.43e+03 batches (norm = +14.74)...
2023-07-16 22:03:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.40e+03 / 9.43e+03 batches (snr_loss = -4.70)...
2023-07-16 22:03:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.40e+03 / 9.43e+03 batches (ce_loss = +3.42)...
2023-07-16 22:03:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.40e+03 / 9.43e+03 batches (mae_loss = +0.03)...
2023-07-16 22:03:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.40e+03 / 9.43e+03 batches (loss = -2.96)...
2023-07-16 22:03:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.40e+03 / 9.43e+03 batches (norm = +20.26)...
2023-07-16 22:03:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.991e-04) - Epoch  2: train = -2.5713(43.28m/9428)
2023-07-16 22:03:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-16 22:03:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 2.29e+03 batches (snr_loss = -4.69)...
2023-07-16 22:03:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 2.29e+03 batches (ce_loss = +10.44)...
2023-07-16 22:03:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 22:03:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 2.29e+03 batches (loss = +0.56)...
2023-07-16 22:03:53 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 2.29e+03 batches (snr_loss = -4.80)...
2023-07-16 22:03:53 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 2.29e+03 batches (ce_loss = +10.44)...
2023-07-16 22:03:53 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 22:03:53 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 2.29e+03 batches (loss = +0.45)...
2023-07-16 22:04:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 2.29e+03 batches (snr_loss = -4.76)...
2023-07-16 22:04:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 2.29e+03 batches (ce_loss = +10.45)...
2023-07-16 22:04:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 22:04:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 2.29e+03 batches (loss = +0.49)...
2023-07-16 22:04:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 2.29e+03 batches (snr_loss = -4.69)...
2023-07-16 22:04:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 2.29e+03 batches (ce_loss = +10.43)...
2023-07-16 22:04:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 22:04:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 2.29e+03 batches (loss = +0.55)...
2023-07-16 22:04:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 2.29e+03 batches (snr_loss = -4.85)...
2023-07-16 22:04:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 2.29e+03 batches (ce_loss = +10.45)...
2023-07-16 22:04:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 22:04:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 2.29e+03 batches (loss = +0.40)...
2023-07-16 22:04:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 2.29e+03 batches (snr_loss = -4.83)...
2023-07-16 22:04:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 2.29e+03 batches (ce_loss = +10.44)...
2023-07-16 22:04:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 22:04:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 2.29e+03 batches (loss = +0.42)...
2023-07-16 22:04:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 2.29e+03 batches (snr_loss = -4.56)...
2023-07-16 22:04:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 2.29e+03 batches (ce_loss = +10.45)...
2023-07-16 22:04:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 22:04:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 2.29e+03 batches (loss = +0.69)...
2023-07-16 22:04:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 2.29e+03 batches (snr_loss = -4.72)...
2023-07-16 22:04:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 2.29e+03 batches (ce_loss = +10.45)...
2023-07-16 22:04:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 22:04:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 2.29e+03 batches (loss = +0.53)...
2023-07-16 22:05:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 2.29e+03 batches (snr_loss = -4.41)...
2023-07-16 22:05:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 2.29e+03 batches (ce_loss = +10.44)...
2023-07-16 22:05:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 22:05:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 2.29e+03 batches (loss = +0.83)...
2023-07-16 22:05:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 2.29e+03 batches (snr_loss = -4.68)...
2023-07-16 22:05:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 2.29e+03 batches (ce_loss = +10.44)...
2023-07-16 22:05:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 22:05:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 2.29e+03 batches (loss = +0.57)...
2023-07-16 22:05:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 2.29e+03 batches (snr_loss = -4.59)...
2023-07-16 22:05:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 2.29e+03 batches (ce_loss = +10.44)...
2023-07-16 22:05:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 22:05:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 2.29e+03 batches (loss = +0.66)...
2023-07-16 22:05:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.20e+03 / 2.29e+03 batches (snr_loss = -4.53)...
2023-07-16 22:05:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.20e+03 / 2.29e+03 batches (ce_loss = +10.44)...
2023-07-16 22:05:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.20e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 22:05:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.20e+03 / 2.29e+03 batches (loss = +0.72)...
2023-07-16 22:06:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.30e+03 / 2.29e+03 batches (snr_loss = -4.36)...
2023-07-16 22:06:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.30e+03 / 2.29e+03 batches (ce_loss = +10.45)...
2023-07-16 22:06:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.30e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 22:06:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.30e+03 / 2.29e+03 batches (loss = +0.89)...
2023-07-16 22:06:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.40e+03 / 2.29e+03 batches (snr_loss = -4.59)...
2023-07-16 22:06:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.40e+03 / 2.29e+03 batches (ce_loss = +10.44)...
2023-07-16 22:06:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.40e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-16 22:06:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.40e+03 / 2.29e+03 batches (loss = +0.66)...
2023-07-18 01:18:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-18 01:18:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-18 01:18:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 1
2023-07-18 01:18:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: gradient clipping by 5.0, default L2
2023-07-18 01:18:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 01:19:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 2.29e+03 batches (snr_loss = -4.32)...
2023-07-18 01:19:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-18 01:19:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-18 01:19:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 2.29e+03 batches (loss = +0.79)...
2023-07-18 01:19:55 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 2.29e+03 batches (snr_loss = -4.00)...
2023-07-18 01:19:55 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-18 01:19:55 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-18 01:19:55 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 2.29e+03 batches (loss = +1.11)...
2023-07-18 01:20:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 2.29e+03 batches (snr_loss = -4.35)...
2023-07-18 01:20:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-18 01:20:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-18 01:20:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 2.29e+03 batches (loss = +0.76)...
2023-07-18 01:20:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 2.29e+03 batches (snr_loss = -4.18)...
2023-07-18 01:20:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-18 01:20:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-18 01:20:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 2.29e+03 batches (loss = +0.93)...
2023-07-18 01:20:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 2.29e+03 batches (snr_loss = -4.01)...
2023-07-18 01:20:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-18 01:20:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-18 01:20:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 2.29e+03 batches (loss = +1.10)...
2023-07-18 01:21:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 2.29e+03 batches (snr_loss = -3.82)...
2023-07-18 01:21:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-18 01:21:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-18 01:21:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 2.29e+03 batches (loss = +1.30)...
2023-07-18 01:21:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 2.29e+03 batches (snr_loss = -4.08)...
2023-07-18 01:21:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-18 01:21:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-18 01:21:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 2.29e+03 batches (loss = +1.04)...
2023-07-18 01:21:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 2.29e+03 batches (snr_loss = -4.41)...
2023-07-18 01:21:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-18 01:21:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-18 01:21:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 2.29e+03 batches (loss = +0.70)...
2023-07-18 01:21:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 2.29e+03 batches (snr_loss = -4.34)...
2023-07-18 01:21:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-18 01:21:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-18 01:21:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 2.29e+03 batches (loss = +0.77)...
2023-07-18 01:22:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 2.29e+03 batches (snr_loss = -4.33)...
2023-07-18 01:22:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-18 01:22:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-18 01:22:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 2.29e+03 batches (loss = +0.78)...
2023-07-18 01:22:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 2.29e+03 batches (snr_loss = -4.08)...
2023-07-18 01:22:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-18 01:22:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-18 01:22:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 2.29e+03 batches (loss = +1.04)...
2023-07-18 01:22:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.20e+03 / 2.29e+03 batches (snr_loss = -4.03)...
2023-07-18 01:22:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.20e+03 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-18 01:22:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.20e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-18 01:22:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.20e+03 / 2.29e+03 batches (loss = +1.09)...
2023-07-18 01:22:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.30e+03 / 2.29e+03 batches (snr_loss = -4.25)...
2023-07-18 01:22:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.30e+03 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-18 01:22:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.30e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-18 01:22:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.30e+03 / 2.29e+03 batches (loss = +0.87)...
2023-07-18 01:23:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.40e+03 / 2.29e+03 batches (snr_loss = -4.29)...
2023-07-18 01:23:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.40e+03 / 2.29e+03 batches (ce_loss = +10.16)...
2023-07-18 01:23:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.40e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-18 01:23:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.40e+03 / 2.29e+03 batches (loss = +0.83)...
2023-07-18 01:23:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.50e+03 / 2.29e+03 batches (snr_loss = -4.07)...
2023-07-18 01:23:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.50e+03 / 2.29e+03 batches (ce_loss = +10.17)...
2023-07-18 01:23:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.50e+03 / 2.29e+03 batches (mae_loss = +0.03)...
2023-07-18 01:23:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.50e+03 / 2.29e+03 batches (loss = +1.05)...
2023-07-18 01:24:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-18 01:24:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-18 01:24:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 1
2023-07-18 01:25:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: gradient clipping by 5.0, default L2
2023-07-18 01:25:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 01:27:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 5.72e+02 batches (snr_loss = -4.32)...
2023-07-18 01:27:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 5.72e+02 batches (ce_loss = +10.17)...
2023-07-18 01:27:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 5.72e+02 batches (mae_loss = +0.03)...
2023-07-18 01:27:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 5.72e+02 batches (loss = +0.80)...
2023-07-18 01:28:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 5.72e+02 batches (snr_loss = -4.25)...
2023-07-18 01:28:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 5.72e+02 batches (ce_loss = +10.17)...
2023-07-18 01:28:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 5.72e+02 batches (mae_loss = +0.03)...
2023-07-18 01:28:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 5.72e+02 batches (loss = +0.87)...
2023-07-18 01:29:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 5.72e+02 batches (snr_loss = -4.15)...
2023-07-18 01:29:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 5.72e+02 batches (ce_loss = +10.17)...
2023-07-18 01:29:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 5.72e+02 batches (mae_loss = +0.03)...
2023-07-18 01:29:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 5.72e+02 batches (loss = +0.97)...
2023-07-18 01:30:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 5.72e+02 batches (snr_loss = -4.14)...
2023-07-18 01:30:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 5.72e+02 batches (ce_loss = +10.16)...
2023-07-18 01:30:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 5.72e+02 batches (mae_loss = +0.03)...
2023-07-18 01:30:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 5.72e+02 batches (loss = +0.97)...
2023-07-18 01:31:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 5.72e+02 batches (snr_loss = -4.16)...
2023-07-18 01:31:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 5.72e+02 batches (ce_loss = +10.17)...
2023-07-18 01:31:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 5.72e+02 batches (mae_loss = +0.03)...
2023-07-18 01:31:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 5.72e+02 batches (loss = +0.95)...
2023-07-18 01:32:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 572 batches: 1.47,0.85,-0.41,0.18,2.38,1.62,0.43,3.69,-0.20,0.93,0.41,-1.36,2.11,0.02,1.37,0.12,2.02,-0.63,-0.44,2.64,-1.62,-0.42,1.66,2.95,0.72,1.70,1.58,-3.29,-1.97,3.35,1.21,1.00,1.12,0.54,-0.68,-0.52,0.33,1.86,1.89,1.48,0.28,-1.45,0.87,0.42,-0.19,1.38,2.07,0.88,-1.54,2.16,-1.48,0.98,0.13,2.09,1.75,1.88,1.21,0.21,1.66,0.27,2.30,0.49,2.00,1.08,-0.78,2.53,0.87,2.44,2.86,0.78,1.81,2.65,2.96,0.55,0.29,-0.04,-1.61,3.08,2.75,-1.73,-0.49,-1.52,-1.36,1.53,0.92,3.21,0.75,1.57,2.39,0.33,-1.59,-1.00,0.26,-0.35,0.15,1.91,0.07,-0.12,2.90,1.21,0.42,1.46,0.42,0.65,-0.31,3.19,0.32,1.32,-0.22,-0.92,-1.23,1.89,0.41,-0.43,0.16,3.14,2.40,-0.96,-0.13,0.12,0.31,3.52,4.06,1.85,1.66,1.81,-0.35,-0.43,0.33,-1.32,1.69,0.84,-2.39,1.11,1.90,1.24,-0.29,3.76,-0.36,2.33,-0.16,1.13,1.38,0.77,0.85,1.79,0.99,3.96,-0.34,1.29,1.41,1.89,-0.93,-1.30,1.43,0.70,-1.01,1.60,2.36,0.55,0.98,-0.79,1.06,-0.63,0.01,2.65,3.35,1.51,0.47,1.72,1.38,0.31,2.27,0.50,-1.97,0.17,0.14,0.41,3.13,1.88,0.43,2.83,-1.17,-2.24,2.24,0.97,-0.43,2.23,0.55,0.69,2.49,0.33,0.90,1.23,0.46,0.79,0.55,1.33,3.02,-0.33,2.67,1.39,2.66,-0.33,0.97,0.49,1.57,0.73,1.21,0.20,0.96,-0.04,1.60,-0.41,1.13,2.27,0.04,-0.10,-0.63,3.44,-1.20,2.58,3.33,-0.39,2.75,0.64,-0.21,2.70,0.55,-0.47,-0.90,-1.15,0.69,1.16,1.56,1.47,2.85,2.13,-0.29,1.76,2.75,0.77,0.73,-0.32,-0.85,0.62,-1.76,1.43,1.41,-2.07,1.34,-0.15,2.39,-0.94,1.62,1.58,2.08,0.10,-0.30,-1.23,-0.44,1.62,0.56,1.82,0.34,0.87,2.74,3.01,1.50,0.51,1.60,-2.25,1.95,-0.51,0.59,2.04,-1.50,2.28,1.02,2.88,0.53,-1.55,3.65,2.24,1.22,1.24,3.31,0.90,3.83,1.69,-0.51,-0.66,1.20,0.92,3.66,1.37,-0.50,2.28,1.13,1.53,3.59,0.40,-0.14,4.15,-1.34,0.71,-0.03,3.26,1.03,0.90,2.97,0.97,2.06,0.40,-0.24,1.98,2.35,-1.68,1.65,0.91,1.29,-2.10,1.66,0.93,0.37,0.63,1.30,1.74,-0.58,-0.30,3.40,2.68,4.39,0.74,2.87,1.32,0.70,-0.29,1.28,2.02,1.34,0.47,1.65,-1.04,-1.19,-0.51,2.33,-0.89,0.47,1.03,0.57,0.72,0.03,1.33,-0.98,0.95,0.55,1.97,-0.41,1.01,0.24,2.48,1.02,-1.03,1.64,0.28,2.13,1.63,0.91,0.32,0.31,0.52,-1.05,-0.36,1.19,2.87,1.02,1.82,0.47,-0.30,1.20,1.66,1.41,1.20,2.63,0.88,1.45,1.39,1.04,-2.18,-0.86,2.67,1.63,-0.07,1.08,0.90,4.04,0.65,0.47,2.15,1.75,-0.18,-0.04,0.81,0.06,2.19,-1.49,-2.02,0.48,0.46,0.52,0.09,1.70,1.39,-1.51,0.08,-0.02,0.47,0.79,0.64,0.90,0.82,1.41,2.05,0.59,2.08,-0.58,0.13,1.28,-1.38,2.71,0.79,-1.01,2.45,-1.10,0.49,1.43,0.41,-0.04,2.45,-0.03,1.34,1.50,-0.22,0.17,1.57,2.21,0.45,-0.75,0.17,-0.53,1.50,2.05,3.49,-0.66,-0.55,2.57,0.77,3.23,0.58,2.23,0.20,1.65,0.43,-1.26,2.42,2.06,-0.38,3.31,2.51,1.02,-0.13,-0.83,3.45,1.73,-0.00,4.75,2.21,1.37,1.88,1.11,3.67,1.81,1.26,1.17,2.58,1.29,1.27,0.48,1.00,1.01,1.93,1.00,1.63,-1.03,2.48,-1.83,3.20,0.85,0.96,1.36,-0.09,2.17,1.74,3.08,0.94,0.43,1.01,-0.05,-2.05,-0.11,0.63,0.81,1.44,0.37,0.88,1.02,-1.52,2.24,3.61,1.64,0.71,1.06,0.99,3.90,-0.57,1.20,1.25,0.66,2.26,-0.46,2.12,1.15,0.15,0.29,-2.14,2.41,0.52,2.07,-0.62,0.66,0.73,1.59,0.09,1.38,2.24,2.75,1.32,1.64,1.16,1.25,1.41,-0.52,1.77,0.66,4.35,0.76,3.80,1.71,1.12,2.67,1.71,1.63,0.07,1.85,3.54,1.63,0.43,-0.97,-0.56,-0.11,0.85
2023-07-18 01:32:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: start from epoch 1, loss = 0.9342
2023-07-18 01:32:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 01:34:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 2.36e+03 batches (snr_loss = -4.11)...
2023-07-18 01:34:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 2.36e+03 batches (ce_loss = +3.88)...
2023-07-18 01:34:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 2.36e+03 batches (mae_loss = +0.03)...
2023-07-18 01:34:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 2.36e+03 batches (loss = -2.14)...
2023-07-18 01:34:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 2.36e+03 batches (norm = +12.96)...
2023-07-18 01:35:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 2.36e+03 batches (snr_loss = -4.34)...
2023-07-18 01:35:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 2.36e+03 batches (ce_loss = +3.88)...
2023-07-18 01:35:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 2.36e+03 batches (mae_loss = +0.03)...
2023-07-18 01:35:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 2.36e+03 batches (loss = -2.37)...
2023-07-18 01:35:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 2.36e+03 batches (norm = +15.26)...
2023-07-18 01:36:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 2.36e+03 batches (snr_loss = -4.29)...
2023-07-18 01:36:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 2.36e+03 batches (ce_loss = +3.86)...
2023-07-18 01:36:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 2.36e+03 batches (mae_loss = +0.03)...
2023-07-18 01:36:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 2.36e+03 batches (loss = -2.33)...
2023-07-18 01:36:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 2.36e+03 batches (norm = +70.94)...
2023-07-18 01:37:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 2.36e+03 batches (snr_loss = -4.73)...
2023-07-18 01:37:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 2.36e+03 batches (ce_loss = +3.84)...
2023-07-18 01:37:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 2.36e+03 batches (mae_loss = +0.03)...
2023-07-18 01:37:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 2.36e+03 batches (loss = -2.78)...
2023-07-18 01:37:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 2.36e+03 batches (norm = +9.37)...
2023-07-18 01:38:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 2.36e+03 batches (snr_loss = -4.67)...
2023-07-18 01:38:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 2.36e+03 batches (ce_loss = +3.83)...
2023-07-18 01:38:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 2.36e+03 batches (mae_loss = +0.03)...
2023-07-18 01:38:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 2.36e+03 batches (loss = -2.73)...
2023-07-18 01:38:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 2.36e+03 batches (norm = +15.70)...
2023-07-18 01:39:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 2.36e+03 batches (snr_loss = -4.49)...
2023-07-18 01:39:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 2.36e+03 batches (ce_loss = +3.85)...
2023-07-18 01:39:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 2.36e+03 batches (mae_loss = +0.03)...
2023-07-18 01:39:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 2.36e+03 batches (loss = -2.53)...
2023-07-18 01:39:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 2.36e+03 batches (norm = +7.99)...
2023-07-18 01:41:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 2.36e+03 batches (snr_loss = -4.51)...
2023-07-18 01:41:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 2.36e+03 batches (ce_loss = +3.82)...
2023-07-18 01:41:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 2.36e+03 batches (mae_loss = +0.03)...
2023-07-18 01:41:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 2.36e+03 batches (loss = -2.58)...
2023-07-18 01:41:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 2.36e+03 batches (norm = +10.42)...
2023-07-18 01:42:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 2.36e+03 batches (snr_loss = -4.55)...
2023-07-18 01:42:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 2.36e+03 batches (ce_loss = +3.81)...
2023-07-18 01:42:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 2.36e+03 batches (mae_loss = +0.03)...
2023-07-18 01:42:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 2.36e+03 batches (loss = -2.61)...
2023-07-18 01:42:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 2.36e+03 batches (norm = +13.37)...
2023-07-18 01:45:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-18 01:45:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-18 01:45:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 1
2023-07-18 01:45:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: gradient clipping by 5.0, default L2
2023-07-18 01:45:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 01:46:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 1.14e+03 batches (snr_loss = -4.15)...
2023-07-18 01:46:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 1.14e+03 batches (ce_loss = +10.16)...
2023-07-18 01:46:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 1.14e+03 batches (mae_loss = +0.03)...
2023-07-18 01:46:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 1.14e+03 batches (loss = +0.96)...
2023-07-18 01:46:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 1.14e+03 batches (snr_loss = -4.19)...
2023-07-18 01:46:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 1.14e+03 batches (ce_loss = +10.17)...
2023-07-18 01:46:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 1.14e+03 batches (mae_loss = +0.03)...
2023-07-18 01:46:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 1.14e+03 batches (loss = +0.92)...
2023-07-18 01:46:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 1.14e+03 batches (snr_loss = -4.35)...
2023-07-18 01:46:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 1.14e+03 batches (ce_loss = +10.17)...
2023-07-18 01:46:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 1.14e+03 batches (mae_loss = +0.03)...
2023-07-18 01:46:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 1.14e+03 batches (loss = +0.76)...
2023-07-18 01:47:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 1.14e+03 batches (snr_loss = -3.84)...
2023-07-18 01:47:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 1.14e+03 batches (ce_loss = +10.16)...
2023-07-18 01:47:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 1.14e+03 batches (mae_loss = +0.03)...
2023-07-18 01:47:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 1.14e+03 batches (loss = +1.27)...
2023-07-18 01:48:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-18 01:48:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-18 01:48:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 1
2023-07-18 01:48:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: gradient clipping by 5.0, default L2
2023-07-18 01:48:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 01:49:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 7.63e+02 batches (snr_loss = -4.06)...
2023-07-18 01:49:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 7.63e+02 batches (ce_loss = +10.17)...
2023-07-18 01:49:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 7.63e+02 batches (mae_loss = +0.03)...
2023-07-18 01:49:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 7.63e+02 batches (loss = +1.06)...
2023-07-18 01:55:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-18 01:55:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-18 01:55:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 1
2023-07-18 01:57:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-18 01:57:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-18 01:57:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 1
2023-07-18 01:57:55 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: gradient clipping by 5.0, default L2
2023-07-18 01:57:55 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 01:59:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 5.72e+02 batches (snr_loss = -4.08)...
2023-07-18 01:59:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 5.72e+02 batches (ce_loss = +10.16)...
2023-07-18 01:59:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 5.72e+02 batches (mae_loss = +0.03)...
2023-07-18 01:59:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 5.72e+02 batches (loss = +1.03)...
2023-07-18 02:00:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 5.72e+02 batches (snr_loss = -4.11)...
2023-07-18 02:00:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 5.72e+02 batches (ce_loss = +10.17)...
2023-07-18 02:00:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 5.72e+02 batches (mae_loss = +0.03)...
2023-07-18 02:00:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 5.72e+02 batches (loss = +1.01)...
2023-07-18 02:01:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-18 02:01:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-18 02:01:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 1
2023-07-18 02:01:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 5.72e+02 batches (snr_loss = -4.18)...
2023-07-18 02:01:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 5.72e+02 batches (ce_loss = +10.16)...
2023-07-18 02:01:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 5.72e+02 batches (mae_loss = +0.03)...
2023-07-18 02:01:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 5.72e+02 batches (loss = +0.93)...
2023-07-18 02:02:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-18 02:02:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-18 02:02:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 1
2023-07-18 02:03:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: gradient clipping by 5.0, default L2
2023-07-18 02:03:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 02:05:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-18 02:05:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-18 02:05:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 1
2023-07-18 02:05:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: gradient clipping by 5.0, default L2
2023-07-18 02:05:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 02:12:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 71 batches: 0.93,0.73,1.52,1.03,0.69,0.75,0.81,1.15,0.83,0.25,0.77,1.45,1.31,1.07,0.32,0.66,1.80,0.93,0.55,0.67,0.61,1.64,0.81,1.22,0.91,0.47,1.09,0.79,0.98,1.04,0.69,1.30,0.36,0.69,1.11,0.70,1.61,0.51,0.37,0.53,0.03,1.79,1.12,1.38,1.07,0.61,2.57,1.02,0.46,0.49,0.82,0.47,1.74,0.91,0.87,0.90,0.79,0.62,1.05,0.74,0.77,0.66,0.61,0.95,1.15,1.08,0.72,0.57,1.09,1.17,0.88
2023-07-18 02:12:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: start from epoch 1, loss = 0.9113
2023-07-18 02:12:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 09:32:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-18 09:32:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-18 09:32:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 1
2023-07-18 09:32:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: gradient clipping by 5.0, default L2
2023-07-18 09:32:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 09:37:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 71 batches: 1.04,2.18,1.16,0.86,0.82,0.52,0.93,0.44,0.95,0.45,1.20,0.75,1.27,1.04,1.16,0.72,1.02,-0.35,1.34,1.03,1.34,0.93,0.54,0.21,1.40,0.94,0.79,0.53,1.33,0.81,1.80,1.26,1.17,1.02,0.54,0.29,0.97,1.49,1.27,0.97,1.55,1.33,1.78,0.49,0.94,1.41,0.92,1.09,1.06,1.46,1.03,1.73,0.83,0.52,1.11,0.41,1.15,1.39,1.03,1.03,1.46,0.98,-0.23,0.73,1.63,1.76,0.60,0.28,0.66,0.65,0.77
2023-07-18 09:37:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: start from epoch 1, loss = 0.9815
2023-07-18 09:37:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 09:40:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-18 09:40:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-18 09:40:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 1
2023-07-18 09:41:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: gradient clipping by 5.0, default L2
2023-07-18 09:41:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 09:45:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 1.43e+02 batches (snr_loss = -4.11)...
2023-07-18 09:45:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 1.43e+02 batches (ce_loss = +10.17)...
2023-07-18 09:45:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 1.43e+02 batches (mae_loss = +0.03)...
2023-07-18 09:45:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 1.43e+02 batches (loss = +1.01)...
2023-07-18 09:46:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 143 batches: 1.27,0.54,1.88,1.37,1.00,1.60,0.47,1.79,0.92,1.39,0.50,0.52,2.19,1.11,1.13,0.04,0.38,0.69,1.59,2.41,0.41,1.08,1.72,0.36,0.40,0.59,1.13,1.76,0.95,1.82,1.45,1.00,-0.07,0.68,-0.04,2.20,2.00,0.19,1.25,0.67,1.28,1.41,1.36,1.15,0.26,1.59,0.57,0.24,0.81,1.16,0.98,-0.11,0.74,0.80,1.49,1.00,1.22,0.85,0.88,-0.04,0.69,2.45,1.70,1.27,0.85,0.55,1.77,0.90,1.26,0.82,1.18,1.19,1.77,1.79,0.67,0.79,1.69,0.59,0.87,1.56,-0.44,1.24,0.71,0.96,1.15,1.39,1.66,0.71,0.71,1.09,0.86,0.90,1.08,-0.29,-0.25,0.51,1.75,1.41,0.26,1.06,1.42,0.93,1.05,0.61,0.71,0.62,1.15,1.49,1.18,0.59,2.41,1.99,0.85,2.31,0.63,1.59,1.28,0.67,0.32,1.09,0.91,0.47,0.46,0.80,0.98,0.14,0.44,1.53,1.91,0.59,1.53,0.36,1.25,0.35,0.21,0.33,0.41,1.06,0.80,0.22,1.92,0.73,-0.22
2023-07-18 09:46:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: start from epoch 1, loss = 0.9848
2023-07-18 09:46:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 09:48:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-18 09:48:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-18 09:48:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 1
2023-07-18 09:48:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: gradient clipping by 5.0, default L2
2023-07-18 09:48:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 09:53:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 91 batches: 0.99,0.49,0.57,0.45,0.62,0.96,1.28,1.07,1.78,0.94,1.40,0.75,0.83,1.68,0.91,0.99,1.11,1.00,1.80,0.02,1.47,0.87,1.69,0.84,0.90,1.67,0.65,1.04,1.53,0.35,1.16,-0.13,1.24,-0.06,2.00,1.22,0.38,0.95,0.63,1.21,1.03,1.69,0.37,0.09,1.28,-0.69,0.46,0.43,1.09,0.01,1.05,1.07,1.41,0.16,0.20,1.57,0.49,1.58,1.61,0.46,0.66,1.14,0.80,0.41,1.43,0.48,0.18,1.19,0.79,0.88,1.07,0.65,0.32,1.41,1.29,0.54,1.15,0.54,1.20,1.01,0.12,-0.19,1.00,0.64,0.16,1.04,0.81,0.79,0.33,0.94,2.16
2023-07-18 09:53:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: start from epoch 1, loss = 0.8744
2023-07-18 09:53:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 09:57:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-18 09:57:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-18 09:57:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 1
2023-07-18 09:57:53 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: gradient clipping by 5.0, default L2
2023-07-18 09:57:53 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 10:02:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 1.22e+02 batches (snr_loss = -4.22)...
2023-07-18 10:02:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 1.22e+02 batches (ce_loss = +10.17)...
2023-07-18 10:02:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 1.22e+02 batches (mae_loss = +0.03)...
2023-07-18 10:02:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 1.22e+02 batches (loss = +0.89)...
2023-07-18 10:02:55 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 122 batches: 0.49,0.73,0.28,0.10,0.92,0.70,1.34,1.34,-0.75,-0.17,0.06,0.40,0.28,0.40,1.77,0.47,1.05,1.08,-0.00,0.93,0.91,1.14,0.70,0.16,1.52,0.06,0.67,1.53,1.51,1.56,0.36,2.59,1.26,0.41,1.53,0.09,1.07,1.87,1.04,0.39,2.17,-0.03,0.79,0.32,0.57,-0.05,1.76,1.38,0.75,-0.04,0.78,0.36,1.35,1.35,1.35,1.59,0.18,0.58,-0.40,0.48,0.01,0.85,2.07,1.43,1.56,1.33,1.03,1.22,1.46,0.98,0.63,0.12,1.51,1.39,0.39,0.81,2.52,1.36,1.18,0.87,1.05,1.08,1.07,0.77,0.74,1.50,0.54,0.08,0.76,0.12,0.50,1.85,1.47,1.13,1.05,1.14,1.98,1.37,0.94,0.04,0.62,0.76,0.70,1.95,0.87,0.97,1.61,-0.03,0.47,0.72,0.72,1.54,0.49,1.34,2.11,1.58,0.04,0.75,0.77,0.89,0.81,0.58
2023-07-18 10:02:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: start from epoch 1, loss = 0.8950
2023-07-18 10:02:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 10:07:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 5.02e+02 batches (snr_loss = -4.45)...
2023-07-18 10:07:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 5.02e+02 batches (ce_loss = +3.86)...
2023-07-18 10:07:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 10:07:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 5.02e+02 batches (loss = -2.49)...
2023-07-18 10:07:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 5.02e+02 batches (norm = +10.00)...
2023-07-18 10:12:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 5.02e+02 batches (snr_loss = -4.48)...
2023-07-18 10:12:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 5.02e+02 batches (ce_loss = +3.85)...
2023-07-18 10:12:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 10:12:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 5.02e+02 batches (loss = -2.53)...
2023-07-18 10:12:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 5.02e+02 batches (norm = +7.10)...
2023-07-18 10:17:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 5.02e+02 batches (snr_loss = -4.59)...
2023-07-18 10:17:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 5.02e+02 batches (ce_loss = +3.84)...
2023-07-18 10:17:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 10:17:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 5.02e+02 batches (loss = -2.64)...
2023-07-18 10:17:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 5.02e+02 batches (norm = +10.06)...
2023-07-18 10:23:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 5.02e+02 batches (snr_loss = -4.57)...
2023-07-18 10:23:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 5.02e+02 batches (ce_loss = +3.82)...
2023-07-18 10:23:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 10:23:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 5.02e+02 batches (loss = -2.63)...
2023-07-18 10:23:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 5.02e+02 batches (norm = +13.19)...
2023-07-18 10:28:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 5.02e+02 batches (snr_loss = -4.73)...
2023-07-18 10:28:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 5.02e+02 batches (ce_loss = +3.83)...
2023-07-18 10:28:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 10:28:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 5.02e+02 batches (loss = -2.79)...
2023-07-18 10:28:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 5.02e+02 batches (norm = +14.19)...
2023-07-18 10:28:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.991e-04) - Epoch  2: train = -2.6154(25.56m/502)
2023-07-18 10:28:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 10:32:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 1.22e+02 batches (snr_loss = -4.63)...
2023-07-18 10:32:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 1.22e+02 batches (ce_loss = +10.25)...
2023-07-18 10:32:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 1.22e+02 batches (mae_loss = +0.03)...
2023-07-18 10:32:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 1.22e+02 batches (loss = +0.52)...
2023-07-18 10:32:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 122 batches: 0.15,0.82,0.68,0.04,0.95,1.17,0.65,1.36,0.20,0.34,1.71,1.09,0.65,0.50,1.01,-0.08,-0.19,0.15,-0.44,-0.82,-0.71,0.39,0.78,-0.10,0.37,0.72,-0.87,0.65,-0.09,0.37,0.41,0.02,0.65,0.49,0.54,0.16,0.35,0.27,-0.71,0.95,1.08,0.88,0.82,0.12,1.14,0.47,2.16,0.47,0.85,0.58,0.71,1.21,0.17,0.73,0.59,0.95,1.14,-0.30,0.16,-0.04,0.49,0.43,0.76,-0.26,1.91,1.12,0.36,0.35,0.61,0.19,1.02,0.04,0.24,0.94,-0.42,0.53,0.46,-0.52,0.54,0.33,1.38,1.74,0.73,1.40,-0.25,1.30,0.93,-0.41,2.26,0.18,0.24,-0.02,0.59,1.59,0.55,0.34,0.46,0.37,0.55,0.30,0.43,0.57,0.99,0.39,0.85,-0.61,1.46,0.33,1.47,0.86,1.07,0.91,0.58,1.55,0.35,0.91,1.12,0.25,1.13,0.61,-0.58,0.50
2023-07-18 10:32:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint best.pt.tar
2023-07-18 10:32:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.991e-04) - Epoch  2: eval = 0.5485(4.08m/122)
2023-07-18 10:32:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-18 10:32:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 10:37:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+02 / 5.02e+02 batches (snr_loss = -4.61)...
2023-07-18 10:37:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+02 / 5.02e+02 batches (ce_loss = +3.82)...
2023-07-18 10:37:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 10:37:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+02 / 5.02e+02 batches (loss = -2.68)...
2023-07-18 10:37:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+02 / 5.02e+02 batches (norm = +18.83)...
2023-07-18 10:41:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 2.00e+02 / 5.02e+02 batches (snr_loss = -4.62)...
2023-07-18 10:41:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 2.00e+02 / 5.02e+02 batches (ce_loss = +3.83)...
2023-07-18 10:41:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 2.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 10:41:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 2.00e+02 / 5.02e+02 batches (loss = -2.68)...
2023-07-18 10:41:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 2.00e+02 / 5.02e+02 batches (norm = +24.78)...
2023-07-18 10:47:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 3.00e+02 / 5.02e+02 batches (snr_loss = -4.63)...
2023-07-18 10:47:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 3.00e+02 / 5.02e+02 batches (ce_loss = +3.80)...
2023-07-18 10:47:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 3.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 10:47:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 3.00e+02 / 5.02e+02 batches (loss = -2.70)...
2023-07-18 10:47:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 3.00e+02 / 5.02e+02 batches (norm = +88.20)...
2023-07-18 10:53:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 4.00e+02 / 5.02e+02 batches (snr_loss = -4.70)...
2023-07-18 10:53:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 4.00e+02 / 5.02e+02 batches (ce_loss = +3.78)...
2023-07-18 10:53:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 4.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 10:53:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 4.00e+02 / 5.02e+02 batches (loss = -2.78)...
2023-07-18 10:53:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 4.00e+02 / 5.02e+02 batches (norm = +7.32)...
2023-07-18 10:58:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 5.00e+02 / 5.02e+02 batches (snr_loss = -4.62)...
2023-07-18 10:58:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 5.00e+02 / 5.02e+02 batches (ce_loss = +3.79)...
2023-07-18 10:58:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 5.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 10:58:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 5.00e+02 / 5.02e+02 batches (loss = -2.70)...
2023-07-18 10:58:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 5.00e+02 / 5.02e+02 batches (norm = +27.47)...
2023-07-18 10:58:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.997e-04) - Epoch  3: train = -2.7078(25.54m/502)
2023-07-18 10:58:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 11:01:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+02 / 1.22e+02 batches (snr_loss = -4.77)...
2023-07-18 11:01:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+02 / 1.22e+02 batches (ce_loss = +10.07)...
2023-07-18 11:01:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+02 / 1.22e+02 batches (mae_loss = +0.03)...
2023-07-18 11:01:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+02 / 1.22e+02 batches (loss = +0.29)...
2023-07-18 11:02:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 122 batches: 0.07,1.10,0.82,-0.35,0.92,-0.63,0.03,0.44,-0.62,-1.40,-0.29,0.64,0.37,2.03,-0.20,0.00,0.04,0.57,0.31,0.69,0.43,0.14,0.24,0.14,0.33,0.13,0.46,0.48,-0.00,0.20,1.60,1.25,0.30,-0.29,-0.30,-0.49,-0.97,0.32,-1.31,1.28,0.23,1.22,-0.12,-0.71,0.74,-0.61,-0.13,-0.11,0.60,-0.38,0.21,0.86,0.32,-0.56,0.59,0.09,1.29,-0.10,-0.34,-0.11,0.08,0.87,0.15,-0.15,-0.27,0.34,1.06,-0.99,0.24,0.95,1.16,-0.18,0.97,0.40,0.38,1.13,0.91,0.25,-0.28,-0.05,0.69,0.02,0.26,-1.07,0.33,0.77,0.02,0.22,1.14,0.34,0.55,-0.20,1.40,0.73,0.55,1.49,1.16,0.43,1.27,0.35,0.07,0.70,0.25,-0.03,0.01,0.25,0.82,1.11,0.56,0.72,-0.34,0.48,0.39,0.75,-0.30,0.56,0.11,-0.07,1.02,1.15,0.09,-0.64
2023-07-18 11:02:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint best.pt.tar
2023-07-18 11:02:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.997e-04) - Epoch  3: eval = 0.2996(4.06m/122)
2023-07-18 11:02:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-18 11:02:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 11:08:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 5.02e+02 batches (snr_loss = -4.61)...
2023-07-18 11:08:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 5.02e+02 batches (ce_loss = +3.77)...
2023-07-18 11:08:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 11:08:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 5.02e+02 batches (loss = -2.70)...
2023-07-18 11:08:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 5.02e+02 batches (norm = +12.12)...
2023-07-18 11:14:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 2.00e+02 / 5.02e+02 batches (snr_loss = -4.84)...
2023-07-18 11:14:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 2.00e+02 / 5.02e+02 batches (ce_loss = +3.75)...
2023-07-18 11:14:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 2.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 11:14:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 2.00e+02 / 5.02e+02 batches (loss = -2.94)...
2023-07-18 11:14:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 2.00e+02 / 5.02e+02 batches (norm = +7.12)...
2023-07-18 11:21:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 3.00e+02 / 5.02e+02 batches (snr_loss = -4.71)...
2023-07-18 11:21:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 3.00e+02 / 5.02e+02 batches (ce_loss = +3.76)...
2023-07-18 11:21:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 3.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 11:21:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 3.00e+02 / 5.02e+02 batches (loss = -2.80)...
2023-07-18 11:21:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 3.00e+02 / 5.02e+02 batches (norm = +15.34)...
2023-07-18 11:27:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 4.00e+02 / 5.02e+02 batches (snr_loss = -4.81)...
2023-07-18 11:27:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 4.00e+02 / 5.02e+02 batches (ce_loss = +3.75)...
2023-07-18 11:27:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 4.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 11:27:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 4.00e+02 / 5.02e+02 batches (loss = -2.91)...
2023-07-18 11:27:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 4.00e+02 / 5.02e+02 batches (norm = +13.31)...
2023-07-18 11:32:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 5.00e+02 / 5.02e+02 batches (snr_loss = -4.81)...
2023-07-18 11:32:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 5.00e+02 / 5.02e+02 batches (ce_loss = +3.75)...
2023-07-18 11:32:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 5.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 11:32:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 5.00e+02 / 5.02e+02 batches (loss = -2.91)...
2023-07-18 11:32:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 5.00e+02 / 5.02e+02 batches (norm = +13.38)...
2023-07-18 11:32:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.999e-04) - Epoch  4: train = -2.8476(29.78m/502)
2023-07-18 11:32:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 11:34:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 1.22e+02 batches (snr_loss = -4.78)...
2023-07-18 11:34:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 1.22e+02 batches (ce_loss = +10.20)...
2023-07-18 11:34:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 1.22e+02 batches (mae_loss = +0.03)...
2023-07-18 11:34:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 1.22e+02 batches (loss = +0.35)...
2023-07-18 11:35:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 122 batches: 0.31,0.19,0.15,0.36,0.66,0.45,0.36,0.87,-0.31,1.61,0.95,0.38,0.04,0.12,0.54,-0.92,0.35,0.14,0.54,1.72,0.02,1.22,0.88,1.18,-0.47,0.39,0.42,0.35,0.32,-0.15,-0.45,0.97,0.55,1.09,0.24,0.33,0.40,-0.01,0.76,1.56,0.10,-0.73,1.35,0.21,0.51,1.41,0.37,-0.87,0.50,-0.60,-0.06,0.01,-0.13,-0.42,0.13,0.22,0.09,0.34,-0.20,0.17,0.59,0.29,0.86,-0.26,0.37,0.97,0.53,-0.00,0.55,-0.46,-0.45,1.45,-0.31,0.70,0.15,0.59,0.70,1.00,-0.99,0.69,0.38,0.09,-0.05,-0.49,0.33,0.87,-0.43,0.63,0.62,0.25,-0.87,0.38,1.40,0.48,0.75,0.05,-0.71,1.46,1.62,0.83,-0.25,0.17,1.32,0.86,1.06,-1.04,0.87,0.58,-0.74,0.49,1.28,-0.08,0.45,0.89,-0.23,-0.38,-0.55,-0.12,0.78,0.92,1.18,2.33
2023-07-18 11:35:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.999e-04) - Epoch  4: eval = 0.3678(2.95m/122)| no impr, best = 0.8950
2023-07-18 11:35:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-18 11:35:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 11:38:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+02 / 5.02e+02 batches (snr_loss = -4.74)...
2023-07-18 11:38:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+02 / 5.02e+02 batches (ce_loss = +3.73)...
2023-07-18 11:38:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 11:38:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+02 / 5.02e+02 batches (loss = -2.84)...
2023-07-18 11:38:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+02 / 5.02e+02 batches (norm = +17.93)...
2023-07-18 11:42:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 2.00e+02 / 5.02e+02 batches (snr_loss = -4.69)...
2023-07-18 11:42:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 2.00e+02 / 5.02e+02 batches (ce_loss = +3.73)...
2023-07-18 11:42:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 2.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 11:42:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 2.00e+02 / 5.02e+02 batches (loss = -2.80)...
2023-07-18 11:42:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 2.00e+02 / 5.02e+02 batches (norm = +17.66)...
2023-07-18 11:45:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 3.00e+02 / 5.02e+02 batches (snr_loss = -4.72)...
2023-07-18 11:45:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 3.00e+02 / 5.02e+02 batches (ce_loss = +3.70)...
2023-07-18 11:45:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 3.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 11:45:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 3.00e+02 / 5.02e+02 batches (loss = -2.84)...
2023-07-18 11:45:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 3.00e+02 / 5.02e+02 batches (norm = +10.66)...
2023-07-18 11:48:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 4.00e+02 / 5.02e+02 batches (snr_loss = -4.73)...
2023-07-18 11:48:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 4.00e+02 / 5.02e+02 batches (ce_loss = +3.70)...
2023-07-18 11:48:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 4.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 11:48:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 4.00e+02 / 5.02e+02 batches (loss = -2.86)...
2023-07-18 11:48:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 4.00e+02 / 5.02e+02 batches (norm = +13.22)...
2023-07-18 11:52:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 5.00e+02 / 5.02e+02 batches (snr_loss = -4.64)...
2023-07-18 11:52:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 5.00e+02 / 5.02e+02 batches (ce_loss = +3.67)...
2023-07-18 11:52:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 5.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 11:52:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 5.00e+02 / 5.02e+02 batches (loss = -2.77)...
2023-07-18 11:52:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 5.00e+02 / 5.02e+02 batches (norm = +9.74)...
2023-07-18 11:52:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.999e-04) - Epoch  5: train = -2.8251(17.36m/502)
2023-07-18 11:52:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 11:55:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+02 / 1.22e+02 batches (snr_loss = -4.80)...
2023-07-18 11:55:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+02 / 1.22e+02 batches (ce_loss = +10.38)...
2023-07-18 11:55:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+02 / 1.22e+02 batches (mae_loss = +0.03)...
2023-07-18 11:55:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+02 / 1.22e+02 batches (loss = +0.42)...
2023-07-18 11:55:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 122 batches: 0.72,0.40,0.92,0.32,0.04,0.71,-0.86,0.44,0.28,0.42,-0.81,0.57,-0.53,0.27,2.04,0.58,1.67,0.14,1.12,0.67,0.58,-0.33,0.81,1.05,0.89,1.40,0.54,1.46,-0.25,-0.03,0.91,0.71,0.20,0.56,0.52,0.57,-0.53,1.40,-0.25,0.41,1.11,0.77,1.14,0.07,0.40,-0.19,0.54,-0.04,0.05,-0.05,-0.57,-0.72,1.05,0.81,-0.13,-0.61,0.69,0.07,-0.58,1.06,0.97,1.14,0.31,0.87,0.23,0.41,1.75,-0.20,0.15,0.64,1.22,0.88,1.00,-0.22,0.41,-0.61,0.77,0.18,-0.81,-0.00,-0.93,-0.55,1.25,1.38,0.78,0.09,0.89,0.81,1.41,0.90,-0.69,-0.86,-0.04,0.91,-0.42,0.66,-0.10,0.96,0.96,0.44,0.62,0.31,-0.69,0.13,-0.01,0.15,-0.44,-0.06,-0.54,-0.41,0.19,0.54,0.80,1.32,-0.50,-0.27,1.06,0.92,-0.75,0.27,0.08,0.71
2023-07-18 11:55:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.999e-04) - Epoch  5: eval = 0.3687(3.08m/122)| no impr, best = 0.8950
2023-07-18 11:55:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-18 11:55:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 12:02:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 1.00e+02 / 5.02e+02 batches (snr_loss = -4.75)...
2023-07-18 12:02:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 1.00e+02 / 5.02e+02 batches (ce_loss = +3.67)...
2023-07-18 12:02:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 1.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 12:02:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 1.00e+02 / 5.02e+02 batches (loss = -2.89)...
2023-07-18 12:02:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 1.00e+02 / 5.02e+02 batches (norm = +28.95)...
2023-07-18 12:06:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 2.00e+02 / 5.02e+02 batches (snr_loss = -4.82)...
2023-07-18 12:06:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 2.00e+02 / 5.02e+02 batches (ce_loss = +3.65)...
2023-07-18 12:06:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 2.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 12:06:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 2.00e+02 / 5.02e+02 batches (loss = -2.96)...
2023-07-18 12:06:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 2.00e+02 / 5.02e+02 batches (norm = +10.76)...
2023-07-18 12:11:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 3.00e+02 / 5.02e+02 batches (snr_loss = -4.75)...
2023-07-18 12:11:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 3.00e+02 / 5.02e+02 batches (ce_loss = +3.65)...
2023-07-18 12:11:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 3.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 12:11:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 3.00e+02 / 5.02e+02 batches (loss = -2.89)...
2023-07-18 12:11:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 3.00e+02 / 5.02e+02 batches (norm = +21.88)...
2023-07-18 12:17:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 4.00e+02 / 5.02e+02 batches (snr_loss = -4.75)...
2023-07-18 12:17:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 4.00e+02 / 5.02e+02 batches (ce_loss = +3.63)...
2023-07-18 12:17:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 4.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 12:17:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 4.00e+02 / 5.02e+02 batches (loss = -2.91)...
2023-07-18 12:17:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 4.00e+02 / 5.02e+02 batches (norm = +13.44)...
2023-07-18 12:25:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 5.00e+02 / 5.02e+02 batches (snr_loss = -4.88)...
2023-07-18 12:25:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 5.00e+02 / 5.02e+02 batches (ce_loss = +3.61)...
2023-07-18 12:25:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 5.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 12:25:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 5.00e+02 / 5.02e+02 batches (loss = -3.04)...
2023-07-18 12:25:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 5.00e+02 / 5.02e+02 batches (norm = +7.97)...
2023-07-18 12:25:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.999e-04) - Epoch  6: train = -2.9401(30.24m/502)
2023-07-18 12:25:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 12:28:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 1.00e+02 / 1.22e+02 batches (snr_loss = -4.74)...
2023-07-18 12:28:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 1.00e+02 / 1.22e+02 batches (ce_loss = +10.41)...
2023-07-18 12:28:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 1.00e+02 / 1.22e+02 batches (mae_loss = +0.03)...
2023-07-18 12:28:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:6 processed 1.00e+02 / 1.22e+02 batches (loss = +0.50)...
2023-07-18 12:28:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 122 batches: 0.46,-0.55,0.15,0.55,0.85,0.99,-0.23,0.53,0.92,0.39,0.38,-0.63,0.51,0.46,0.94,-0.42,0.66,-0.36,-0.53,1.41,1.27,0.05,0.50,0.50,0.34,0.15,0.58,0.18,0.77,0.28,0.50,0.96,0.47,1.76,-0.06,-0.31,1.69,0.83,0.26,1.01,0.09,0.11,1.73,0.07,0.35,0.36,0.87,-1.36,0.34,1.19,0.37,0.20,0.39,1.54,0.53,1.37,-0.23,1.57,-0.07,0.31,-0.16,-0.14,0.57,1.07,-0.27,1.35,0.46,2.22,0.04,0.22,0.33,-0.12,1.04,0.32,0.52,0.30,0.24,0.89,0.46,0.15,-0.74,0.68,1.11,-0.65,1.11,1.64,0.72,2.33,-0.13,0.53,-0.31,0.40,1.39,-0.40,1.45,0.94,0.89,-0.41,1.32,0.52,-0.31,1.03,-0.47,0.27,0.36,0.14,1.39,-0.51,0.09,1.03,0.34,0.54,0.23,0.91,0.44,0.60,0.17,-0.21,0.69,-1.60,-0.11,1.32
2023-07-18 12:28:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.999e-04) - Epoch  6: eval = 0.4603(3.16m/122)| no impr, best = 0.8950
2023-07-18 12:28:55 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-18 12:28:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 12:32:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 1.00e+02 / 5.02e+02 batches (snr_loss = -4.91)...
2023-07-18 12:32:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 1.00e+02 / 5.02e+02 batches (ce_loss = +3.59)...
2023-07-18 12:32:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 1.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 12:32:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 1.00e+02 / 5.02e+02 batches (loss = -3.08)...
2023-07-18 12:32:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 1.00e+02 / 5.02e+02 batches (norm = +10.80)...
2023-07-18 12:36:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 2.00e+02 / 5.02e+02 batches (snr_loss = -4.87)...
2023-07-18 12:36:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 2.00e+02 / 5.02e+02 batches (ce_loss = +3.59)...
2023-07-18 12:36:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 2.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 12:36:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 2.00e+02 / 5.02e+02 batches (loss = -3.05)...
2023-07-18 12:36:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 2.00e+02 / 5.02e+02 batches (norm = +31.01)...
2023-07-18 12:40:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 3.00e+02 / 5.02e+02 batches (snr_loss = -4.79)...
2023-07-18 12:40:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 3.00e+02 / 5.02e+02 batches (ce_loss = +3.57)...
2023-07-18 12:40:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 3.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 12:40:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 3.00e+02 / 5.02e+02 batches (loss = -2.98)...
2023-07-18 12:40:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 3.00e+02 / 5.02e+02 batches (norm = +12.27)...
2023-07-18 12:44:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 4.00e+02 / 5.02e+02 batches (snr_loss = -4.91)...
2023-07-18 12:44:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 4.00e+02 / 5.02e+02 batches (ce_loss = +3.55)...
2023-07-18 12:44:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 4.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 12:44:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 4.00e+02 / 5.02e+02 batches (loss = -3.11)...
2023-07-18 12:44:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 4.00e+02 / 5.02e+02 batches (norm = +9.11)...
2023-07-18 12:48:53 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 5.00e+02 / 5.02e+02 batches (snr_loss = -4.95)...
2023-07-18 12:48:53 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 5.00e+02 / 5.02e+02 batches (ce_loss = +3.55)...
2023-07-18 12:48:53 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 5.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 12:48:53 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 5.00e+02 / 5.02e+02 batches (loss = -3.14)...
2023-07-18 12:48:53 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 5.00e+02 / 5.02e+02 batches (norm = +12.26)...
2023-07-18 12:48:55 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.998e-04) - Epoch  7: train = -3.0720(20.00m/502)
2023-07-18 12:48:55 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 12:51:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 1.00e+02 / 1.22e+02 batches (snr_loss = -4.91)...
2023-07-18 12:51:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 1.00e+02 / 1.22e+02 batches (ce_loss = +10.45)...
2023-07-18 12:51:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 1.00e+02 / 1.22e+02 batches (mae_loss = +0.03)...
2023-07-18 12:51:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:7 processed 1.00e+02 / 1.22e+02 batches (loss = +0.35)...
2023-07-18 12:51:55 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 122 batches: 0.14,1.24,-0.09,-0.53,0.57,1.25,0.10,0.90,0.43,-0.17,0.12,0.86,-0.48,0.84,-0.84,0.61,1.78,0.07,0.96,0.01,0.30,1.11,0.24,0.68,0.41,-0.65,2.23,0.65,0.66,0.95,0.85,0.16,-0.14,0.82,-0.73,-0.16,-0.44,0.74,0.55,0.53,-0.95,-0.73,0.82,-0.06,-0.06,1.41,-0.05,0.41,0.66,0.30,0.79,-0.12,0.78,0.22,-0.27,-0.75,0.83,0.91,-0.59,-0.16,0.04,-0.20,0.21,0.08,-0.34,1.24,-0.07,-0.13,-0.25,0.43,0.59,0.56,-0.02,-0.64,0.27,0.90,0.17,2.08,0.90,-0.23,-0.13,0.05,-0.02,0.96,0.38,0.07,0.59,-0.60,0.32,0.47,1.24,0.21,1.96,-0.15,0.78,0.66,0.39,0.46,0.84,0.50,1.06,0.92,0.40,0.57,0.67,1.02,-1.02,2.06,0.53,0.55,0.34,1.14,0.24,-0.02,0.63,1.60,-0.24,0.25,-0.03,1.14,-0.21,1.21
2023-07-18 12:51:55 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.998e-04) - Epoch  7: eval = 0.3879(3.00m/122)| no impr, best = 0.8950
2023-07-18 12:51:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-18 12:51:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 12:55:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 1.00e+02 / 5.02e+02 batches (snr_loss = -4.82)...
2023-07-18 12:55:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 1.00e+02 / 5.02e+02 batches (ce_loss = +3.53)...
2023-07-18 12:55:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 1.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 12:55:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 1.00e+02 / 5.02e+02 batches (loss = -3.03)...
2023-07-18 12:55:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 1.00e+02 / 5.02e+02 batches (norm = +12.05)...
2023-07-18 12:59:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 2.00e+02 / 5.02e+02 batches (snr_loss = -5.00)...
2023-07-18 12:59:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 2.00e+02 / 5.02e+02 batches (ce_loss = +3.51)...
2023-07-18 12:59:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 2.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 12:59:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 2.00e+02 / 5.02e+02 batches (loss = -3.22)...
2023-07-18 12:59:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 2.00e+02 / 5.02e+02 batches (norm = +10.40)...
2023-07-18 13:03:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 3.00e+02 / 5.02e+02 batches (snr_loss = -4.94)...
2023-07-18 13:03:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 3.00e+02 / 5.02e+02 batches (ce_loss = +3.51)...
2023-07-18 13:03:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 3.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 13:03:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 3.00e+02 / 5.02e+02 batches (loss = -3.16)...
2023-07-18 13:03:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 3.00e+02 / 5.02e+02 batches (norm = +9.95)...
2023-07-18 13:07:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 4.00e+02 / 5.02e+02 batches (snr_loss = -4.89)...
2023-07-18 13:07:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 4.00e+02 / 5.02e+02 batches (ce_loss = +3.48)...
2023-07-18 13:07:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 4.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 13:07:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 4.00e+02 / 5.02e+02 batches (loss = -3.13)...
2023-07-18 13:07:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 4.00e+02 / 5.02e+02 batches (norm = +16.47)...
2023-07-18 13:11:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 5.00e+02 / 5.02e+02 batches (snr_loss = -4.90)...
2023-07-18 13:11:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 5.00e+02 / 5.02e+02 batches (ce_loss = +3.48)...
2023-07-18 13:11:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 5.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 13:11:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 5.00e+02 / 5.02e+02 batches (loss = -3.13)...
2023-07-18 13:11:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 5.00e+02 / 5.02e+02 batches (norm = +36.78)...
2023-07-18 13:11:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.999e-04) - Epoch  8: train = -3.1326(19.78m/502)
2023-07-18 13:11:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 13:15:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 1.00e+02 / 1.22e+02 batches (snr_loss = -5.02)...
2023-07-18 13:15:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 1.00e+02 / 1.22e+02 batches (ce_loss = +10.50)...
2023-07-18 13:15:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 1.00e+02 / 1.22e+02 batches (mae_loss = +0.03)...
2023-07-18 13:15:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:8 processed 1.00e+02 / 1.22e+02 batches (loss = +0.25)...
2023-07-18 13:15:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 122 batches: -0.24,-0.37,-0.54,0.92,0.63,1.09,1.19,-0.02,0.41,0.18,0.50,0.51,0.30,0.31,1.61,0.05,-0.33,0.64,-0.09,0.51,-0.91,-0.22,0.53,1.06,-0.69,0.37,0.80,0.06,-0.42,0.66,-0.36,-0.14,0.49,-0.36,0.10,0.57,0.16,1.58,1.05,0.23,0.70,0.67,1.15,0.01,0.25,-0.67,0.68,0.18,-0.30,0.30,0.30,0.58,0.34,0.84,0.26,0.97,0.62,-0.63,0.02,-0.57,-0.44,0.43,0.30,1.14,-0.18,0.71,1.45,0.65,0.91,-0.06,0.66,-0.13,-0.27,-0.20,0.53,-0.28,0.39,-0.64,-0.22,-0.04,-0.33,-0.14,0.18,-0.26,0.46,-0.07,0.84,0.42,-0.13,-0.18,0.18,0.06,0.47,0.29,0.35,0.37,-0.32,-0.46,0.83,0.67,1.49,0.31,0.12,-0.93,1.58,-0.56,0.21,0.88,1.08,1.05,-0.76,-1.02,0.73,0.86,0.18,0.44,-0.02,0.36,-0.14,1.41,-0.02,0.30
2023-07-18 13:15:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint best.pt.tar
2023-07-18 13:15:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.999e-04) - Epoch  8: eval = 0.2706(3.83m/122)
2023-07-18 13:15:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-18 13:15:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 13:20:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 1.00e+02 / 5.02e+02 batches (snr_loss = -4.94)...
2023-07-18 13:20:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 1.00e+02 / 5.02e+02 batches (ce_loss = +3.46)...
2023-07-18 13:20:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 1.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 13:20:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 1.00e+02 / 5.02e+02 batches (loss = -3.19)...
2023-07-18 13:20:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 1.00e+02 / 5.02e+02 batches (norm = +20.88)...
2023-07-18 13:24:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 2.00e+02 / 5.02e+02 batches (snr_loss = -5.06)...
2023-07-18 13:24:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 2.00e+02 / 5.02e+02 batches (ce_loss = +3.44)...
2023-07-18 13:24:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 2.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 13:24:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 2.00e+02 / 5.02e+02 batches (loss = -3.31)...
2023-07-18 13:24:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 2.00e+02 / 5.02e+02 batches (norm = +12.41)...
2023-07-18 13:28:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 3.00e+02 / 5.02e+02 batches (snr_loss = -5.05)...
2023-07-18 13:28:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 3.00e+02 / 5.02e+02 batches (ce_loss = +3.42)...
2023-07-18 13:28:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 3.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 13:28:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 3.00e+02 / 5.02e+02 batches (loss = -3.31)...
2023-07-18 13:28:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 3.00e+02 / 5.02e+02 batches (norm = +9.81)...
2023-07-18 13:32:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 4.00e+02 / 5.02e+02 batches (snr_loss = -5.05)...
2023-07-18 13:32:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 4.00e+02 / 5.02e+02 batches (ce_loss = +3.41)...
2023-07-18 13:32:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 4.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 13:32:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 4.00e+02 / 5.02e+02 batches (loss = -3.32)...
2023-07-18 13:32:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 4.00e+02 / 5.02e+02 batches (norm = +38.46)...
2023-07-18 13:38:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 5.00e+02 / 5.02e+02 batches (snr_loss = -4.98)...
2023-07-18 13:38:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 5.00e+02 / 5.02e+02 batches (ce_loss = +3.40)...
2023-07-18 13:38:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 5.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 13:38:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 5.00e+02 / 5.02e+02 batches (loss = -3.26)...
2023-07-18 13:38:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 5.00e+02 / 5.02e+02 batches (norm = +15.42)...
2023-07-18 13:38:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.999e-04) - Epoch  9: train = -3.2769(22.40m/502)
2023-07-18 13:38:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 13:40:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 1.00e+02 / 1.22e+02 batches (snr_loss = -5.10)...
2023-07-18 13:40:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 1.00e+02 / 1.22e+02 batches (ce_loss = +10.58)...
2023-07-18 13:40:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 1.00e+02 / 1.22e+02 batches (mae_loss = +0.03)...
2023-07-18 13:40:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:9 processed 1.00e+02 / 1.22e+02 batches (loss = +0.21)...
2023-07-18 13:40:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 122 batches: 0.08,-0.02,0.59,-0.19,-0.15,0.39,1.20,0.85,0.24,0.32,0.12,-0.95,0.02,0.53,0.33,-0.21,0.12,0.39,0.68,-0.38,-0.33,-0.48,0.35,0.89,0.23,0.52,-0.23,0.39,0.71,-1.13,0.11,-0.54,0.32,1.10,-0.28,0.93,0.63,-0.55,0.63,0.93,0.33,-0.42,-0.80,1.15,-0.65,0.65,0.93,-0.01,-0.14,-0.21,0.11,-0.14,-0.01,-0.58,0.94,0.15,0.25,0.13,0.00,-0.62,0.31,1.36,-0.30,-0.08,0.61,0.07,1.00,0.28,0.92,-0.79,-0.05,-0.93,-0.08,-0.23,-0.53,0.28,1.18,1.34,0.48,0.96,-0.17,0.24,-0.26,0.79,0.69,0.52,-0.02,0.70,0.41,0.36,1.66,2.44,1.19,0.63,0.76,-0.87,-1.04,0.28,-0.59,-1.29,0.28,0.82,0.60,0.01,0.54,-0.47,0.43,0.23,-0.06,0.71,0.28,0.05,1.57,0.85,0.61,-1.06,0.09,1.54,0.23,0.52,-0.78,0.88
2023-07-18 13:40:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint best.pt.tar
2023-07-18 13:40:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.999e-04) - Epoch  9: eval = 0.2403(2.91m/122)
2023-07-18 13:40:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-18 13:40:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 13:44:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 1.00e+02 / 5.02e+02 batches (snr_loss = -5.04)...
2023-07-18 13:44:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 1.00e+02 / 5.02e+02 batches (ce_loss = +3.39)...
2023-07-18 13:44:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 1.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 13:44:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 1.00e+02 / 5.02e+02 batches (loss = -3.32)...
2023-07-18 13:44:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 1.00e+02 / 5.02e+02 batches (norm = +11.48)...
2023-07-18 13:47:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 2.00e+02 / 5.02e+02 batches (snr_loss = -4.89)...
2023-07-18 13:47:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 2.00e+02 / 5.02e+02 batches (ce_loss = +3.37)...
2023-07-18 13:47:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 2.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 13:47:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 2.00e+02 / 5.02e+02 batches (loss = -3.18)...
2023-07-18 13:47:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 2.00e+02 / 5.02e+02 batches (norm = +9.15)...
2023-07-18 13:51:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 3.00e+02 / 5.02e+02 batches (snr_loss = -5.06)...
2023-07-18 13:51:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 3.00e+02 / 5.02e+02 batches (ce_loss = +3.36)...
2023-07-18 13:51:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 3.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 13:51:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 3.00e+02 / 5.02e+02 batches (loss = -3.35)...
2023-07-18 13:51:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 3.00e+02 / 5.02e+02 batches (norm = +11.54)...
2023-07-18 13:56:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 4.00e+02 / 5.02e+02 batches (snr_loss = -5.11)...
2023-07-18 13:56:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 4.00e+02 / 5.02e+02 batches (ce_loss = +3.33)...
2023-07-18 13:56:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 4.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 13:56:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 4.00e+02 / 5.02e+02 batches (loss = -3.41)...
2023-07-18 13:56:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 4.00e+02 / 5.02e+02 batches (norm = +11.66)...
2023-07-18 14:00:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 5.00e+02 / 5.02e+02 batches (snr_loss = -5.13)...
2023-07-18 14:00:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 5.00e+02 / 5.02e+02 batches (ce_loss = +3.32)...
2023-07-18 14:00:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 5.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 14:00:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 5.00e+02 / 5.02e+02 batches (loss = -3.45)...
2023-07-18 14:00:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 5.00e+02 / 5.02e+02 batches (norm = +11.05)...
2023-07-18 14:00:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.999e-04) - Epoch 10: train = -3.3387(19.95m/502)
2023-07-18 14:00:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 14:03:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 1.00e+02 / 1.22e+02 batches (snr_loss = -5.17)...
2023-07-18 14:03:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 1.00e+02 / 1.22e+02 batches (ce_loss = +10.61)...
2023-07-18 14:03:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 1.00e+02 / 1.22e+02 batches (mae_loss = +0.03)...
2023-07-18 14:03:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:10 processed 1.00e+02 / 1.22e+02 batches (loss = +0.16)...
2023-07-18 14:04:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 122 batches: 0.93,0.07,-1.18,-0.26,0.10,0.42,0.52,0.57,-0.41,0.39,-0.31,-0.11,-0.31,1.20,-0.37,-0.27,0.31,0.08,0.74,1.07,0.92,-0.07,-0.73,0.22,0.09,-0.75,-0.56,-0.30,-0.08,0.52,1.45,-0.82,1.11,0.17,0.38,0.43,-0.56,0.24,-0.09,0.62,-0.30,-0.45,-0.61,-1.30,-0.22,0.15,1.13,-0.40,-0.48,-0.25,0.18,1.06,-0.37,0.42,0.57,-0.43,0.74,-0.36,0.53,-0.01,-0.27,1.38,0.55,0.77,-0.82,0.89,-0.12,-0.28,0.47,0.48,1.11,0.49,-0.60,-0.37,-0.06,0.60,-0.66,0.03,-0.57,-0.14,0.17,0.72,1.55,0.50,-0.01,-0.03,0.66,0.74,0.19,0.44,0.07,0.59,0.69,0.35,1.34,0.53,-0.91,0.49,-0.31,0.58,0.33,0.48,1.03,0.84,0.11,0.38,1.10,-0.21,0.85,0.60,-0.15,0.65,0.03,0.30,-0.18,0.70,0.58,-0.33,-0.48,0.10,0.85,-0.49
2023-07-18 14:04:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint best.pt.tar
2023-07-18 14:04:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.999e-04) - Epoch 10: eval = 0.1907(3.18m/122)
2023-07-18 14:04:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-18 14:04:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 14:07:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 1.00e+02 / 5.02e+02 batches (snr_loss = -5.08)...
2023-07-18 14:07:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 1.00e+02 / 5.02e+02 batches (ce_loss = +3.32)...
2023-07-18 14:07:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 1.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 14:07:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 1.00e+02 / 5.02e+02 batches (loss = -3.39)...
2023-07-18 14:07:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 1.00e+02 / 5.02e+02 batches (norm = +11.83)...
2023-07-18 14:11:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 2.00e+02 / 5.02e+02 batches (snr_loss = -5.01)...
2023-07-18 14:11:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 2.00e+02 / 5.02e+02 batches (ce_loss = +3.30)...
2023-07-18 14:11:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 2.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 14:11:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 2.00e+02 / 5.02e+02 batches (loss = -3.34)...
2023-07-18 14:11:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 2.00e+02 / 5.02e+02 batches (norm = +17.27)...
2023-07-18 14:17:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 3.00e+02 / 5.02e+02 batches (snr_loss = -5.09)...
2023-07-18 14:17:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 3.00e+02 / 5.02e+02 batches (ce_loss = +3.29)...
2023-07-18 14:17:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 3.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 14:17:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 3.00e+02 / 5.02e+02 batches (loss = -3.42)...
2023-07-18 14:17:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 3.00e+02 / 5.02e+02 batches (norm = +13.60)...
2023-07-18 14:21:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 4.00e+02 / 5.02e+02 batches (snr_loss = -4.96)...
2023-07-18 14:21:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 4.00e+02 / 5.02e+02 batches (ce_loss = +3.29)...
2023-07-18 14:21:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 4.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 14:21:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 4.00e+02 / 5.02e+02 batches (loss = -3.29)...
2023-07-18 14:21:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 4.00e+02 / 5.02e+02 batches (norm = +9.53)...
2023-07-18 14:25:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 5.00e+02 / 5.02e+02 batches (snr_loss = -5.01)...
2023-07-18 14:25:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 5.00e+02 / 5.02e+02 batches (ce_loss = +3.28)...
2023-07-18 14:25:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 5.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 14:25:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 5.00e+02 / 5.02e+02 batches (loss = -3.34)...
2023-07-18 14:25:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 5.00e+02 / 5.02e+02 batches (norm = +16.95)...
2023-07-18 14:25:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=1.000e-03) - Epoch 11: train = -3.3567(21.45m/502)
2023-07-18 14:25:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 14:28:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 1.00e+02 / 1.22e+02 batches (snr_loss = -5.14)...
2023-07-18 14:28:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 1.00e+02 / 1.22e+02 batches (ce_loss = +10.62)...
2023-07-18 14:28:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 1.00e+02 / 1.22e+02 batches (mae_loss = +0.03)...
2023-07-18 14:28:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:11 processed 1.00e+02 / 1.22e+02 batches (loss = +0.19)...
2023-07-18 14:28:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 122 batches: 0.73,0.26,0.02,-0.19,0.54,0.09,0.84,0.94,0.18,1.52,-0.45,0.22,-0.08,-0.06,0.22,-0.09,1.46,-0.41,0.77,-0.93,0.74,0.37,0.39,0.33,-0.11,-0.55,-0.51,0.14,0.04,-0.75,0.02,0.87,-1.66,0.91,-0.03,0.34,0.60,1.05,-0.19,0.45,1.06,0.64,-0.29,-0.55,-0.03,0.63,-0.19,0.45,0.04,-0.41,-0.01,-0.59,-0.03,0.45,0.01,0.06,0.51,0.41,0.03,1.09,1.07,-0.17,-0.11,0.36,0.85,0.19,0.99,1.21,1.07,0.87,-0.49,-0.00,0.19,-0.71,-0.10,0.58,-0.46,0.81,-0.20,0.98,-0.33,0.78,0.09,1.32,-0.01,-1.25,0.57,-0.18,0.36,-0.89,1.24,-0.85,0.46,-0.64,-0.09,-0.43,0.11,0.71,-0.26,0.21,-0.66,0.60,-0.27,0.19,0.19,-0.15,-0.47,1.06,0.68,0.21,0.51,0.22,0.31,-0.30,0.41,0.36,0.28,0.79,0.14,-0.02,-0.34,0.04
2023-07-18 14:28:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint best.pt.tar
2023-07-18 14:28:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=1.000e-03) - Epoch 11: eval = 0.1880(3.19m/122)
2023-07-18 14:28:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-18 14:28:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 14:32:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 1.00e+02 / 5.02e+02 batches (snr_loss = -5.15)...
2023-07-18 14:32:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 1.00e+02 / 5.02e+02 batches (ce_loss = +3.27)...
2023-07-18 14:32:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 1.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 14:32:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 1.00e+02 / 5.02e+02 batches (loss = -3.49)...
2023-07-18 14:32:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 1.00e+02 / 5.02e+02 batches (norm = +14.62)...
2023-07-18 14:38:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 2.00e+02 / 5.02e+02 batches (snr_loss = -5.17)...
2023-07-18 14:38:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 2.00e+02 / 5.02e+02 batches (ce_loss = +3.24)...
2023-07-18 14:38:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 2.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 14:38:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 2.00e+02 / 5.02e+02 batches (loss = -3.52)...
2023-07-18 14:38:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 2.00e+02 / 5.02e+02 batches (norm = +9.09)...
2023-07-18 14:44:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 3.00e+02 / 5.02e+02 batches (snr_loss = -5.26)...
2023-07-18 14:44:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 3.00e+02 / 5.02e+02 batches (ce_loss = +3.23)...
2023-07-18 14:44:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 3.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 14:44:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 3.00e+02 / 5.02e+02 batches (loss = -3.62)...
2023-07-18 14:44:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 3.00e+02 / 5.02e+02 batches (norm = +21.64)...
2023-07-18 14:53:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 4.00e+02 / 5.02e+02 batches (snr_loss = -5.18)...
2023-07-18 14:53:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 4.00e+02 / 5.02e+02 batches (ce_loss = +3.24)...
2023-07-18 14:53:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 4.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 14:53:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 4.00e+02 / 5.02e+02 batches (loss = -3.53)...
2023-07-18 14:53:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 4.00e+02 / 5.02e+02 batches (norm = +15.87)...
2023-07-18 15:01:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 5.00e+02 / 5.02e+02 batches (snr_loss = -5.12)...
2023-07-18 15:01:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 5.00e+02 / 5.02e+02 batches (ce_loss = +3.22)...
2023-07-18 15:01:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 5.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 15:01:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 5.00e+02 / 5.02e+02 batches (loss = -3.49)...
2023-07-18 15:01:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 5.00e+02 / 5.02e+02 batches (norm = +13.32)...
2023-07-18 15:01:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=1.000e-03) - Epoch 12: train = -3.5297(32.73m/502)
2023-07-18 15:01:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 15:04:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 1.00e+02 / 1.22e+02 batches (snr_loss = -5.05)...
2023-07-18 15:04:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 1.00e+02 / 1.22e+02 batches (ce_loss = +10.75)...
2023-07-18 15:04:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 1.00e+02 / 1.22e+02 batches (mae_loss = +0.03)...
2023-07-18 15:04:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:12 processed 1.00e+02 / 1.22e+02 batches (loss = +0.36)...
2023-07-18 15:04:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 122 batches: 0.78,0.74,0.15,-0.31,-0.51,0.65,-0.08,1.33,-0.19,0.31,0.48,-1.03,1.31,-0.40,0.15,1.12,-0.05,-0.33,-0.09,-0.11,0.64,1.51,1.13,-0.99,-0.02,0.49,0.46,1.65,0.37,0.85,0.15,0.96,0.30,-0.64,0.05,0.56,0.43,0.56,0.70,0.77,1.23,0.49,0.25,-0.29,-0.48,0.04,-0.63,-0.07,0.15,0.44,1.26,0.01,0.14,-0.16,0.60,-0.26,1.58,-0.12,-0.27,0.06,0.91,0.55,0.74,0.20,1.02,0.25,0.69,1.09,0.71,0.88,0.96,1.37,0.30,-0.50,-0.02,1.15,-0.48,-0.06,-0.34,0.95,0.86,1.21,0.10,1.20,1.26,0.01,-0.32,0.65,0.38,0.43,0.71,-0.21,-0.58,-0.17,0.95,1.21,-0.46,0.17,0.08,-0.13,1.01,0.37,0.63,0.31,0.38,0.08,0.98,0.40,0.58,1.17,0.09,0.67,0.76,1.24,0.58,0.68,1.01,0.73,-0.08,0.47,-0.10,1.26
2023-07-18 15:04:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=1.000e-03) - Epoch 12: eval = 0.3999(2.91m/122)| no impr, best = 0.8950
2023-07-18 15:04:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-18 15:04:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 15:08:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 1.00e+02 / 5.02e+02 batches (snr_loss = -5.04)...
2023-07-18 15:08:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 1.00e+02 / 5.02e+02 batches (ce_loss = +3.21)...
2023-07-18 15:08:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 1.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 15:08:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 1.00e+02 / 5.02e+02 batches (loss = -3.41)...
2023-07-18 15:08:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 1.00e+02 / 5.02e+02 batches (norm = +17.34)...
2023-07-18 15:14:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 2.00e+02 / 5.02e+02 batches (snr_loss = -5.25)...
2023-07-18 15:14:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 2.00e+02 / 5.02e+02 batches (ce_loss = +3.19)...
2023-07-18 15:14:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 2.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 15:14:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 2.00e+02 / 5.02e+02 batches (loss = -3.63)...
2023-07-18 15:14:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 2.00e+02 / 5.02e+02 batches (norm = +12.63)...
2023-07-18 15:22:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 3.00e+02 / 5.02e+02 batches (snr_loss = -5.15)...
2023-07-18 15:22:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 3.00e+02 / 5.02e+02 batches (ce_loss = +3.18)...
2023-07-18 15:22:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 3.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 15:22:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 3.00e+02 / 5.02e+02 batches (loss = -3.53)...
2023-07-18 15:22:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 3.00e+02 / 5.02e+02 batches (norm = +14.61)...
2023-07-18 15:31:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 4.00e+02 / 5.02e+02 batches (snr_loss = -5.21)...
2023-07-18 15:31:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 4.00e+02 / 5.02e+02 batches (ce_loss = +3.17)...
2023-07-18 15:31:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 4.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 15:31:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 4.00e+02 / 5.02e+02 batches (loss = -3.60)...
2023-07-18 15:31:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 4.00e+02 / 5.02e+02 batches (norm = +9.93)...
2023-07-18 15:41:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 5.00e+02 / 5.02e+02 batches (snr_loss = -5.30)...
2023-07-18 15:41:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 5.00e+02 / 5.02e+02 batches (ce_loss = +3.16)...
2023-07-18 15:41:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 5.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 15:41:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 5.00e+02 / 5.02e+02 batches (loss = -3.69)...
2023-07-18 15:41:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 5.00e+02 / 5.02e+02 batches (norm = +13.56)...
2023-07-18 15:41:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.998e-04) - Epoch 13: train = -3.5721(36.63m/502)
2023-07-18 15:41:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 15:44:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 1.00e+02 / 1.22e+02 batches (snr_loss = -5.27)...
2023-07-18 15:44:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 1.00e+02 / 1.22e+02 batches (ce_loss = +10.73)...
2023-07-18 15:44:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 1.00e+02 / 1.22e+02 batches (mae_loss = +0.03)...
2023-07-18 15:44:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:13 processed 1.00e+02 / 1.22e+02 batches (loss = +0.12)...
2023-07-18 15:44:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 122 batches: 0.60,0.16,0.23,0.40,-0.36,0.62,0.31,-0.76,0.91,0.05,-0.64,0.92,-0.13,-0.84,0.23,-0.07,0.54,0.07,0.66,-0.11,0.17,-0.15,0.64,0.42,-0.04,0.61,1.09,0.16,1.54,0.33,-0.09,1.42,-1.06,-0.79,1.43,0.96,1.38,-0.91,1.21,-0.21,0.44,0.36,-0.34,-0.41,-0.14,0.16,0.12,-0.34,-0.29,-0.23,0.16,0.86,-0.09,0.76,-0.23,1.51,-0.49,0.08,-0.46,-0.63,0.32,-1.22,0.16,1.12,-0.46,-0.72,-0.92,0.40,0.34,1.54,0.38,0.05,-0.91,0.12,0.91,-0.45,0.34,-0.53,0.70,0.24,0.51,0.68,-0.45,0.44,-0.19,1.24,-0.12,0.39,0.91,-1.09,0.79,-0.26,-0.50,-0.11,-0.80,0.14,-0.29,-1.33,-0.39,-0.42,0.46,0.91,0.35,0.65,-0.18,-1.19,0.50,0.67,0.67,0.15,-0.39,0.53,0.50,-0.47,-0.78,0.18,0.71,-0.04,0.57,0.52,0.47,-0.21
2023-07-18 15:44:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint best.pt.tar
2023-07-18 15:44:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.998e-04) - Epoch 13: eval = 0.1375(3.53m/122)
2023-07-18 15:44:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-18 15:44:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 15:52:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 1.00e+02 / 5.02e+02 batches (snr_loss = -5.18)...
2023-07-18 15:52:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 1.00e+02 / 5.02e+02 batches (ce_loss = +3.14)...
2023-07-18 15:52:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 1.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 15:52:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 1.00e+02 / 5.02e+02 batches (loss = -3.58)...
2023-07-18 15:52:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 1.00e+02 / 5.02e+02 batches (norm = +21.86)...
2023-07-18 16:00:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 2.00e+02 / 5.02e+02 batches (snr_loss = -5.29)...
2023-07-18 16:00:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 2.00e+02 / 5.02e+02 batches (ce_loss = +3.15)...
2023-07-18 16:00:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 2.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 16:00:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 2.00e+02 / 5.02e+02 batches (loss = -3.69)...
2023-07-18 16:00:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 2.00e+02 / 5.02e+02 batches (norm = +10.40)...
2023-07-18 16:11:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 3.00e+02 / 5.02e+02 batches (snr_loss = -5.25)...
2023-07-18 16:11:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 3.00e+02 / 5.02e+02 batches (ce_loss = +3.12)...
2023-07-18 16:11:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 3.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 16:11:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 3.00e+02 / 5.02e+02 batches (loss = -3.67)...
2023-07-18 16:11:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 3.00e+02 / 5.02e+02 batches (norm = +11.94)...
2023-07-18 16:22:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 4.00e+02 / 5.02e+02 batches (snr_loss = -5.29)...
2023-07-18 16:22:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 4.00e+02 / 5.02e+02 batches (ce_loss = +3.12)...
2023-07-18 16:22:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 4.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 16:22:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 4.00e+02 / 5.02e+02 batches (loss = -3.71)...
2023-07-18 16:22:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 4.00e+02 / 5.02e+02 batches (norm = +13.09)...
2023-07-18 16:32:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 5.00e+02 / 5.02e+02 batches (snr_loss = -5.40)...
2023-07-18 16:32:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 5.00e+02 / 5.02e+02 batches (ce_loss = +3.11)...
2023-07-18 16:32:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 5.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 16:32:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 5.00e+02 / 5.02e+02 batches (loss = -3.82)...
2023-07-18 16:32:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 5.00e+02 / 5.02e+02 batches (norm = +8.68)...
2023-07-18 16:32:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=1.000e-03) - Epoch 14: train = -3.6934(47.30m/502)
2023-07-18 16:32:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 16:35:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 1.00e+02 / 1.22e+02 batches (snr_loss = -5.22)...
2023-07-18 16:35:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 1.00e+02 / 1.22e+02 batches (ce_loss = +10.89)...
2023-07-18 16:35:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 1.00e+02 / 1.22e+02 batches (mae_loss = +0.03)...
2023-07-18 16:35:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:14 processed 1.00e+02 / 1.22e+02 batches (loss = +0.25)...
2023-07-18 16:35:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 122 batches: 0.65,0.71,-0.83,0.17,-0.33,0.34,-0.65,0.35,0.58,0.32,0.34,-0.04,0.84,-0.41,-0.24,1.21,0.78,0.74,-0.18,1.04,-0.65,0.66,0.39,-0.67,0.28,-0.87,-0.82,-0.65,0.22,0.60,0.45,-0.48,-0.26,0.23,0.24,1.11,1.19,0.08,0.73,0.63,0.09,0.27,0.67,0.65,0.01,-0.68,0.19,0.77,-0.00,0.46,-0.00,1.10,1.04,0.09,0.28,0.74,-1.13,-0.02,1.17,-0.06,0.34,0.75,0.68,-0.26,0.02,2.02,-0.03,1.36,-0.90,0.90,0.11,0.31,-1.04,0.46,0.97,-0.15,-0.13,-0.28,0.11,0.32,0.77,0.02,0.40,1.02,-0.09,0.24,0.91,0.74,0.42,0.38,0.01,0.33,1.02,-0.06,0.11,-0.13,0.12,0.22,0.10,-0.12,-0.28,-0.34,0.93,-0.85,0.46,0.69,-0.25,-0.35,-1.23,0.85,-0.33,0.74,0.54,0.09,-0.47,-0.22,0.42,-0.20,-0.11,-1.11,-0.00,0.42
2023-07-18 16:35:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=1.000e-03) - Epoch 14: eval = 0.2032(3.63m/122)| no impr, best = 0.8950
2023-07-18 16:35:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-18 16:35:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 16:43:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 1.00e+02 / 5.02e+02 batches (snr_loss = -5.34)...
2023-07-18 16:43:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 1.00e+02 / 5.02e+02 batches (ce_loss = +3.10)...
2023-07-18 16:43:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 1.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 16:43:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 1.00e+02 / 5.02e+02 batches (loss = -3.76)...
2023-07-18 16:43:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 1.00e+02 / 5.02e+02 batches (norm = +19.35)...
2023-07-18 16:52:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 2.00e+02 / 5.02e+02 batches (snr_loss = -5.16)...
2023-07-18 16:52:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 2.00e+02 / 5.02e+02 batches (ce_loss = +3.10)...
2023-07-18 16:52:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 2.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 16:52:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 2.00e+02 / 5.02e+02 batches (loss = -3.59)...
2023-07-18 16:52:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 2.00e+02 / 5.02e+02 batches (norm = +21.61)...
2023-07-18 17:03:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 3.00e+02 / 5.02e+02 batches (snr_loss = -5.28)...
2023-07-18 17:03:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 3.00e+02 / 5.02e+02 batches (ce_loss = +3.09)...
2023-07-18 17:03:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 3.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 17:03:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 3.00e+02 / 5.02e+02 batches (loss = -3.71)...
2023-07-18 17:03:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 3.00e+02 / 5.02e+02 batches (norm = +12.92)...
2023-07-18 17:16:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 4.00e+02 / 5.02e+02 batches (snr_loss = -5.31)...
2023-07-18 17:16:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 4.00e+02 / 5.02e+02 batches (ce_loss = +3.08)...
2023-07-18 17:16:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 4.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 17:16:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 4.00e+02 / 5.02e+02 batches (loss = -3.74)...
2023-07-18 17:16:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 4.00e+02 / 5.02e+02 batches (norm = +10.72)...
2023-07-18 17:26:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 5.00e+02 / 5.02e+02 batches (snr_loss = -5.29)...
2023-07-18 17:26:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 5.00e+02 / 5.02e+02 batches (ce_loss = +3.07)...
2023-07-18 17:26:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 5.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 17:26:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 5.00e+02 / 5.02e+02 batches (loss = -3.73)...
2023-07-18 17:26:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 5.00e+02 / 5.02e+02 batches (norm = +14.03)...
2023-07-18 17:26:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=1.000e-03) - Epoch 15: train = -3.7037(51.13m/502)
2023-07-18 17:26:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 17:30:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 1.00e+02 / 1.22e+02 batches (snr_loss = -5.16)...
2023-07-18 17:30:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 1.00e+02 / 1.22e+02 batches (ce_loss = +10.81)...
2023-07-18 17:30:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 1.00e+02 / 1.22e+02 batches (mae_loss = +0.03)...
2023-07-18 17:30:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:15 processed 1.00e+02 / 1.22e+02 batches (loss = +0.27)...
2023-07-18 17:30:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 122 batches: -0.19,0.65,-0.18,0.14,0.26,0.46,1.37,0.02,-0.08,0.86,0.42,0.07,0.21,0.07,1.21,0.25,1.32,-0.38,-0.03,0.50,0.10,-0.91,0.85,0.50,-0.22,-0.71,-0.93,0.35,0.13,-1.10,0.02,0.50,-0.84,-0.17,0.48,-0.05,1.59,1.39,-0.24,-0.99,0.02,0.85,0.33,-0.09,-1.09,0.54,0.23,1.14,0.49,-0.19,0.00,0.07,0.34,-0.05,-0.73,0.23,-0.03,-0.06,0.45,-0.97,1.69,0.04,1.00,0.38,0.40,-0.20,0.81,1.44,1.53,1.16,0.52,0.05,0.72,0.60,1.10,0.16,0.04,0.53,0.28,0.91,0.86,-0.50,0.40,0.04,0.58,0.65,-0.01,-1.10,0.30,0.70,0.15,0.06,0.43,1.04,-0.12,-0.14,0.63,0.26,0.90,0.48,0.32,0.16,0.85,0.72,-0.40,0.11,-0.44,-0.64,0.06,0.21,0.92,0.18,0.13,-0.69,-0.18,-0.15,0.08,-0.44,1.23,0.83,0.28,-0.35
2023-07-18 17:30:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=1.000e-03) - Epoch 15: eval = 0.2438(3.74m/122)| no impr, best = 0.8950
2023-07-18 17:30:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-18 17:30:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 17:38:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 1.00e+02 / 5.02e+02 batches (snr_loss = -5.36)...
2023-07-18 17:38:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 1.00e+02 / 5.02e+02 batches (ce_loss = +3.06)...
2023-07-18 17:38:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 1.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 17:38:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 1.00e+02 / 5.02e+02 batches (loss = -3.80)...
2023-07-18 17:38:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 1.00e+02 / 5.02e+02 batches (norm = +18.98)...
2023-07-18 17:51:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 2.00e+02 / 5.02e+02 batches (snr_loss = -5.35)...
2023-07-18 17:51:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 2.00e+02 / 5.02e+02 batches (ce_loss = +3.06)...
2023-07-18 17:51:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 2.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 17:51:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 2.00e+02 / 5.02e+02 batches (loss = -3.79)...
2023-07-18 17:51:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 2.00e+02 / 5.02e+02 batches (norm = +26.19)...
2023-07-18 18:05:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 3.00e+02 / 5.02e+02 batches (snr_loss = -5.40)...
2023-07-18 18:05:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 3.00e+02 / 5.02e+02 batches (ce_loss = +3.06)...
2023-07-18 18:05:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 3.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 18:05:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 3.00e+02 / 5.02e+02 batches (loss = -3.84)...
2023-07-18 18:05:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 3.00e+02 / 5.02e+02 batches (norm = +15.67)...
2023-07-18 18:19:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 4.00e+02 / 5.02e+02 batches (snr_loss = -5.29)...
2023-07-18 18:19:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 4.00e+02 / 5.02e+02 batches (ce_loss = +3.06)...
2023-07-18 18:19:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 4.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 18:19:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 4.00e+02 / 5.02e+02 batches (loss = -3.73)...
2023-07-18 18:19:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 4.00e+02 / 5.02e+02 batches (norm = +15.99)...
2023-07-18 18:33:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 5.00e+02 / 5.02e+02 batches (snr_loss = -5.29)...
2023-07-18 18:33:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 5.00e+02 / 5.02e+02 batches (ce_loss = +3.02)...
2023-07-18 18:33:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 5.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 18:33:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 5.00e+02 / 5.02e+02 batches (loss = -3.75)...
2023-07-18 18:33:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 5.00e+02 / 5.02e+02 batches (norm = +8.14)...
2023-07-18 18:33:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.999e-04) - Epoch 16: train = -3.7849(63.21m/502)
2023-07-18 18:33:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 18:37:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 1.00e+02 / 1.22e+02 batches (snr_loss = -5.29)...
2023-07-18 18:37:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 1.00e+02 / 1.22e+02 batches (ce_loss = +10.98)...
2023-07-18 18:37:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 1.00e+02 / 1.22e+02 batches (mae_loss = +0.03)...
2023-07-18 18:37:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:16 processed 1.00e+02 / 1.22e+02 batches (loss = +0.23)...
2023-07-18 18:38:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 122 batches: -0.58,0.52,1.39,0.17,-0.84,-0.04,0.80,1.15,-0.43,0.53,0.06,0.21,0.14,-0.28,0.89,-0.52,0.65,-0.32,1.24,-0.12,0.04,0.14,1.16,0.45,0.11,-0.40,-0.30,0.23,-0.93,0.19,-0.31,0.50,-0.23,-0.55,0.65,-0.64,-0.83,1.03,0.32,-0.13,1.34,0.14,1.15,-0.51,0.83,0.28,-0.15,0.60,1.58,1.41,0.91,-0.46,0.98,0.10,0.32,-0.33,-0.23,-0.35,1.08,-0.58,0.83,0.73,-0.02,-0.59,-0.01,-0.05,0.60,0.58,-0.27,0.59,0.03,-0.37,-0.04,0.91,0.92,1.49,1.98,0.23,0.75,-0.62,-0.17,-0.18,-0.72,-0.44,0.08,0.98,0.52,0.33,-0.24,0.30,0.01,-0.28,0.15,1.21,0.82,-0.70,0.82,0.01,-0.02,-0.28,0.06,-0.19,1.35,0.76,0.62,0.17,-0.28,0.71,1.43,0.04,0.49,0.56,1.78,-0.73,0.19,1.02,-0.52,-0.33,1.48,-0.14,1.19,-0.74
2023-07-18 18:38:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.999e-04) - Epoch 16: eval = 0.2623(4.14m/122)| no impr, best = 0.8950
2023-07-18 18:38:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-18 18:38:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 18:49:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 1.00e+02 / 5.02e+02 batches (snr_loss = -5.36)...
2023-07-18 18:49:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 1.00e+02 / 5.02e+02 batches (ce_loss = +3.03)...
2023-07-18 18:49:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 1.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 18:49:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 1.00e+02 / 5.02e+02 batches (loss = -3.82)...
2023-07-18 18:49:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 1.00e+02 / 5.02e+02 batches (norm = +22.30)...
2023-07-18 19:02:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 2.00e+02 / 5.02e+02 batches (snr_loss = -5.29)...
2023-07-18 19:02:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 2.00e+02 / 5.02e+02 batches (ce_loss = +3.03)...
2023-07-18 19:02:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 2.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 19:02:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 2.00e+02 / 5.02e+02 batches (loss = -3.75)...
2023-07-18 19:02:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 2.00e+02 / 5.02e+02 batches (norm = +20.76)...
2023-07-18 19:16:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 3.00e+02 / 5.02e+02 batches (snr_loss = -5.50)...
2023-07-18 19:16:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 3.00e+02 / 5.02e+02 batches (ce_loss = +3.02)...
2023-07-18 19:16:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 3.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 19:16:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 3.00e+02 / 5.02e+02 batches (loss = -3.96)...
2023-07-18 19:16:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 3.00e+02 / 5.02e+02 batches (norm = +12.58)...
2023-07-18 19:30:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 4.00e+02 / 5.02e+02 batches (snr_loss = -5.36)...
2023-07-18 19:30:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 4.00e+02 / 5.02e+02 batches (ce_loss = +3.02)...
2023-07-18 19:30:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 4.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 19:30:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 4.00e+02 / 5.02e+02 batches (loss = -3.82)...
2023-07-18 19:30:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 4.00e+02 / 5.02e+02 batches (norm = +16.70)...
2023-07-18 19:45:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 5.00e+02 / 5.02e+02 batches (snr_loss = -5.45)...
2023-07-18 19:45:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 5.00e+02 / 5.02e+02 batches (ce_loss = +3.00)...
2023-07-18 19:45:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 5.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 19:45:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 5.00e+02 / 5.02e+02 batches (loss = -3.92)...
2023-07-18 19:45:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 5.00e+02 / 5.02e+02 batches (norm = +22.14)...
2023-07-18 19:45:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.999e-04) - Epoch 17: train = -3.8572(66.93m/502)
2023-07-18 19:45:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 19:49:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 1.00e+02 / 1.22e+02 batches (snr_loss = -5.52)...
2023-07-18 19:49:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 1.00e+02 / 1.22e+02 batches (ce_loss = +10.94)...
2023-07-18 19:49:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 1.00e+02 / 1.22e+02 batches (mae_loss = +0.03)...
2023-07-18 19:49:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:17 processed 1.00e+02 / 1.22e+02 batches (loss = -0.02)...
2023-07-18 19:49:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 122 batches: -0.25,-0.20,0.10,1.34,0.82,-0.61,-0.22,0.60,0.69,-0.13,0.44,-0.50,0.62,-1.30,-0.18,0.11,-0.25,0.72,-0.13,-1.30,0.10,0.72,0.40,-0.19,0.78,-0.77,-0.80,-0.77,-0.62,-0.04,-0.17,0.19,0.37,0.13,-0.98,-0.15,-0.69,1.15,0.06,0.46,0.51,-1.09,-0.60,-0.18,-0.15,-0.26,-0.94,-0.47,0.87,-0.16,-0.86,-0.65,0.52,0.28,0.01,-0.83,0.30,0.93,0.38,-0.58,-0.84,1.01,0.16,-0.22,0.26,0.51,0.13,-0.62,-0.37,-0.33,0.38,0.17,-0.55,-0.34,-0.08,0.22,-0.52,1.38,-0.29,-0.94,0.70,0.33,-0.22,0.45,0.60,-0.04,0.57,-0.18,0.00,1.84,0.09,0.11,-0.51,0.85,0.02,-0.34,-0.56,0.19,-1.16,-0.29,-0.60,-0.54,-0.51,-0.20,-1.15,0.65,1.18,0.04,0.07,-1.44,-0.53,-0.00,-0.34,-0.38,-0.18,0.18,-1.26,0.40,0.92,-0.46,0.38,0.81
2023-07-18 19:49:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint best.pt.tar
2023-07-18 19:49:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.999e-04) - Epoch 17: eval = -0.0396(4.70m/122)
2023-07-18 19:49:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-18 19:49:52 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 20:01:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 1.00e+02 / 5.02e+02 batches (snr_loss = -5.30)...
2023-07-18 20:01:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 1.00e+02 / 5.02e+02 batches (ce_loss = +3.00)...
2023-07-18 20:01:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 1.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 20:01:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 1.00e+02 / 5.02e+02 batches (loss = -3.77)...
2023-07-18 20:01:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 1.00e+02 / 5.02e+02 batches (norm = +15.76)...
2023-07-18 20:14:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 2.00e+02 / 5.02e+02 batches (snr_loss = -5.43)...
2023-07-18 20:14:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 2.00e+02 / 5.02e+02 batches (ce_loss = +2.98)...
2023-07-18 20:14:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 2.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 20:14:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 2.00e+02 / 5.02e+02 batches (loss = -3.91)...
2023-07-18 20:14:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 2.00e+02 / 5.02e+02 batches (norm = +27.41)...
2023-07-18 20:29:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 3.00e+02 / 5.02e+02 batches (snr_loss = -5.32)...
2023-07-18 20:29:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 3.00e+02 / 5.02e+02 batches (ce_loss = +2.96)...
2023-07-18 20:29:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 3.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 20:29:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 3.00e+02 / 5.02e+02 batches (loss = -3.81)...
2023-07-18 20:29:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 3.00e+02 / 5.02e+02 batches (norm = +11.57)...
2023-07-18 20:43:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 4.00e+02 / 5.02e+02 batches (snr_loss = -5.39)...
2023-07-18 20:43:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 4.00e+02 / 5.02e+02 batches (ce_loss = +2.98)...
2023-07-18 20:43:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 4.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 20:43:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 4.00e+02 / 5.02e+02 batches (loss = -3.88)...
2023-07-18 20:43:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 4.00e+02 / 5.02e+02 batches (norm = +19.30)...
2023-07-18 20:58:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 5.00e+02 / 5.02e+02 batches (snr_loss = -5.52)...
2023-07-18 20:58:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 5.00e+02 / 5.02e+02 batches (ce_loss = +2.97)...
2023-07-18 20:58:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 5.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 20:58:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 5.00e+02 / 5.02e+02 batches (loss = -4.01)...
2023-07-18 20:58:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 5.00e+02 / 5.02e+02 batches (norm = +16.91)...
2023-07-18 20:58:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=1.000e-03) - Epoch 18: train = -3.8752(68.46m/502)
2023-07-18 20:58:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 21:02:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 1.00e+02 / 1.22e+02 batches (snr_loss = -5.45)...
2023-07-18 21:02:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 1.00e+02 / 1.22e+02 batches (ce_loss = +10.91)...
2023-07-18 21:02:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 1.00e+02 / 1.22e+02 batches (mae_loss = +0.03)...
2023-07-18 21:02:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:18 processed 1.00e+02 / 1.22e+02 batches (loss = +0.03)...
2023-07-18 21:02:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 122 batches: -0.05,0.46,-0.01,-0.38,0.43,-0.55,-1.07,-0.61,-0.16,0.64,0.84,-0.48,-0.12,0.44,0.58,1.73,-0.12,0.03,-0.67,-0.05,-0.96,1.02,0.18,-1.33,-0.36,-1.17,1.02,0.90,1.20,-0.59,-0.06,-0.77,-0.23,0.47,-0.08,0.12,0.05,-0.40,0.08,-0.18,-0.10,-0.04,0.43,0.61,0.47,-0.10,0.22,0.38,0.51,0.65,0.90,-0.38,-0.07,0.35,-0.79,0.43,-0.49,-0.23,0.31,0.11,-0.99,0.22,-0.73,-0.25,-1.21,-0.68,0.01,-0.42,0.47,-0.39,0.15,1.38,0.84,0.51,-0.49,0.63,0.56,-0.60,-0.37,0.61,-0.59,0.25,0.14,0.46,-0.06,-0.71,0.02,-0.56,0.80,-0.39,0.60,-0.07,0.49,0.83,0.06,-0.20,0.04,0.06,0.35,-0.56,-1.55,0.08,0.10,-0.13,-0.44,-0.46,-0.56,0.79,0.82,0.09,-1.38,0.42,0.48,1.02,0.78,-0.97,1.15,-0.49,0.57,0.11,0.36,-0.71
2023-07-18 21:02:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=1.000e-03) - Epoch 18: eval = 0.0265(4.42m/122)| no impr, best = 0.8950
2023-07-18 21:02:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-18 21:02:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 21:12:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 1.00e+02 / 5.02e+02 batches (snr_loss = -5.50)...
2023-07-18 21:12:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 1.00e+02 / 5.02e+02 batches (ce_loss = +2.96)...
2023-07-18 21:12:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 1.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 21:12:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 1.00e+02 / 5.02e+02 batches (loss = -4.00)...
2023-07-18 21:12:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 1.00e+02 / 5.02e+02 batches (norm = +53.02)...
2023-07-18 21:24:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 2.00e+02 / 5.02e+02 batches (snr_loss = -5.46)...
2023-07-18 21:24:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 2.00e+02 / 5.02e+02 batches (ce_loss = +2.95)...
2023-07-18 21:24:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 2.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 21:24:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 2.00e+02 / 5.02e+02 batches (loss = -3.96)...
2023-07-18 21:24:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 2.00e+02 / 5.02e+02 batches (norm = +10.06)...
2023-07-18 21:35:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 3.00e+02 / 5.02e+02 batches (snr_loss = -5.43)...
2023-07-18 21:35:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 3.00e+02 / 5.02e+02 batches (ce_loss = +2.95)...
2023-07-18 21:35:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 3.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 21:35:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 3.00e+02 / 5.02e+02 batches (loss = -3.93)...
2023-07-18 21:35:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 3.00e+02 / 5.02e+02 batches (norm = +23.02)...
2023-07-18 21:48:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 4.00e+02 / 5.02e+02 batches (snr_loss = -5.54)...
2023-07-18 21:48:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 4.00e+02 / 5.02e+02 batches (ce_loss = +2.95)...
2023-07-18 21:48:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 4.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 21:48:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 4.00e+02 / 5.02e+02 batches (loss = -4.04)...
2023-07-18 21:48:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 4.00e+02 / 5.02e+02 batches (norm = +44.82)...
2023-07-18 21:59:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 5.00e+02 / 5.02e+02 batches (snr_loss = -5.49)...
2023-07-18 21:59:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 5.00e+02 / 5.02e+02 batches (ce_loss = +2.94)...
2023-07-18 21:59:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 5.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 21:59:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 5.00e+02 / 5.02e+02 batches (loss = -3.99)...
2023-07-18 21:59:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 5.00e+02 / 5.02e+02 batches (norm = +38.79)...
2023-07-18 21:59:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=1.000e-03) - Epoch 19: train = -3.9872(56.97m/502)
2023-07-18 21:59:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 22:03:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 1.00e+02 / 1.22e+02 batches (snr_loss = -5.53)...
2023-07-18 22:03:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 1.00e+02 / 1.22e+02 batches (ce_loss = +10.99)...
2023-07-18 22:03:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 1.00e+02 / 1.22e+02 batches (mae_loss = +0.03)...
2023-07-18 22:03:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:19 processed 1.00e+02 / 1.22e+02 batches (loss = -0.00)...
2023-07-18 22:04:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 122 batches: 0.64,0.30,0.06,0.65,-1.03,1.42,0.41,-0.77,0.08,1.16,0.10,-0.37,-0.38,0.09,0.78,-0.93,-0.20,-0.92,-0.10,-1.30,-0.46,0.28,-0.40,1.10,0.93,-0.00,-0.24,0.09,0.81,0.67,0.94,-0.22,-0.39,-0.83,0.56,0.26,0.11,-0.12,-0.55,-0.27,-0.21,-1.00,0.39,0.78,-0.19,-1.00,0.31,-0.21,-0.52,0.60,-0.43,-1.34,-0.41,-0.10,0.97,0.42,-0.20,-0.08,-0.12,0.48,-0.87,0.33,-0.42,0.10,-0.07,0.41,0.38,0.04,0.08,-0.15,-0.63,-0.37,-0.70,-0.50,-0.92,0.10,-0.22,0.36,0.23,0.15,-0.16,0.73,0.10,-0.76,0.06,0.78,-0.58,-0.14,-1.17,-0.00,0.91,-0.06,0.82,-0.18,0.06,0.27,-0.55,-0.01,0.69,1.52,-0.93,-0.24,-0.52,0.15,0.36,0.29,-1.14,0.43,0.36,-0.35,-0.34,-0.88,1.01,0.18,0.33,-0.69,0.93,0.78,-0.70,-0.47,0.39,0.08
2023-07-18 22:04:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=1.000e-03) - Epoch 19: eval = -0.0102(4.31m/122)| no impr, best = 0.8950
2023-07-18 22:04:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-18 22:04:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 22:15:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 1.00e+02 / 5.02e+02 batches (snr_loss = -5.58)...
2023-07-18 22:15:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 1.00e+02 / 5.02e+02 batches (ce_loss = +2.93)...
2023-07-18 22:15:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 1.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 22:15:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 1.00e+02 / 5.02e+02 batches (loss = -4.10)...
2023-07-18 22:15:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 1.00e+02 / 5.02e+02 batches (norm = +28.47)...
2023-07-18 22:26:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 2.00e+02 / 5.02e+02 batches (snr_loss = -5.44)...
2023-07-18 22:26:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 2.00e+02 / 5.02e+02 batches (ce_loss = +2.94)...
2023-07-18 22:26:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 2.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 22:26:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 2.00e+02 / 5.02e+02 batches (loss = -3.94)...
2023-07-18 22:26:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 2.00e+02 / 5.02e+02 batches (norm = +11.26)...
2023-07-18 22:37:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 3.00e+02 / 5.02e+02 batches (snr_loss = -5.56)...
2023-07-18 22:37:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 3.00e+02 / 5.02e+02 batches (ce_loss = +2.92)...
2023-07-18 22:37:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 3.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 22:37:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 3.00e+02 / 5.02e+02 batches (loss = -4.08)...
2023-07-18 22:37:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 3.00e+02 / 5.02e+02 batches (norm = +14.14)...
2023-07-18 22:49:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 4.00e+02 / 5.02e+02 batches (snr_loss = -5.55)...
2023-07-18 22:49:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 4.00e+02 / 5.02e+02 batches (ce_loss = +2.92)...
2023-07-18 22:49:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 4.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 22:49:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 4.00e+02 / 5.02e+02 batches (loss = -4.06)...
2023-07-18 22:49:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 4.00e+02 / 5.02e+02 batches (norm = +21.47)...
2023-07-18 23:03:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 5.00e+02 / 5.02e+02 batches (snr_loss = -5.32)...
2023-07-18 23:03:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 5.00e+02 / 5.02e+02 batches (ce_loss = +2.91)...
2023-07-18 23:03:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 5.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 23:03:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 5.00e+02 / 5.02e+02 batches (loss = -3.84)...
2023-07-18 23:03:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 5.00e+02 / 5.02e+02 batches (norm = +19.80)...
2023-07-18 23:03:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=1.000e-03) - Epoch 20: train = -4.0023(59.52m/502)
2023-07-18 23:03:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-18 23:07:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 1.00e+02 / 1.22e+02 batches (snr_loss = -5.32)...
2023-07-18 23:07:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 1.00e+02 / 1.22e+02 batches (ce_loss = +11.04)...
2023-07-18 23:07:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 1.00e+02 / 1.22e+02 batches (mae_loss = +0.03)...
2023-07-18 23:07:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:20 processed 1.00e+02 / 1.22e+02 batches (loss = +0.22)...
2023-07-18 23:08:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 122 batches: -0.04,0.03,1.52,0.44,-0.22,0.44,-0.62,0.31,-0.52,0.58,0.54,-0.66,0.00,0.03,0.82,-0.38,-1.06,0.38,0.50,-0.32,-0.15,0.93,-0.45,-0.31,0.87,1.18,0.95,-0.30,0.04,-1.21,0.51,0.18,0.88,-0.18,0.46,0.51,0.26,-0.71,0.15,0.79,-0.75,0.29,0.18,0.47,0.33,-0.29,0.44,0.28,0.44,0.04,0.90,-0.51,0.12,-0.60,0.43,0.40,0.97,0.35,1.05,-0.19,1.55,0.44,-0.01,0.86,0.91,0.70,-0.33,0.79,-0.09,0.70,0.88,-0.60,-0.09,0.03,0.06,-0.70,1.24,1.57,1.00,-0.02,0.83,0.21,-0.49,0.10,0.54,-0.40,0.68,-1.40,-0.23,1.39,1.15,0.02,0.14,0.14,-0.92,0.39,-0.88,0.36,0.21,1.00,0.10,1.37,-0.57,0.13,1.68,-0.93,-0.94,2.07,0.17,0.46,0.60,0.52,0.11,0.44,-0.87,0.38,-0.33,0.24,0.46,0.16,-0.12,1.24
2023-07-18 23:08:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=1.000e-03) - Epoch 20: eval = 0.2342(4.69m/122)| no impr, best = 0.8950
2023-07-18 23:08:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-18 23:08:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-18 23:20:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 1.00e+02 / 5.02e+02 batches (snr_loss = -5.41)...
2023-07-18 23:20:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 1.00e+02 / 5.02e+02 batches (ce_loss = +2.92)...
2023-07-18 23:20:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 1.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 23:20:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 1.00e+02 / 5.02e+02 batches (loss = -3.92)...
2023-07-18 23:20:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 1.00e+02 / 5.02e+02 batches (norm = +38.13)...
2023-07-18 23:34:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 2.00e+02 / 5.02e+02 batches (snr_loss = -5.50)...
2023-07-18 23:34:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 2.00e+02 / 5.02e+02 batches (ce_loss = +2.90)...
2023-07-18 23:34:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 2.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 23:34:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 2.00e+02 / 5.02e+02 batches (loss = -4.02)...
2023-07-18 23:34:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 2.00e+02 / 5.02e+02 batches (norm = +30.18)...
2023-07-18 23:49:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 3.00e+02 / 5.02e+02 batches (snr_loss = -5.54)...
2023-07-18 23:49:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 3.00e+02 / 5.02e+02 batches (ce_loss = +2.90)...
2023-07-18 23:49:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 3.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-18 23:49:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 3.00e+02 / 5.02e+02 batches (loss = -4.07)...
2023-07-18 23:49:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 3.00e+02 / 5.02e+02 batches (norm = +13.03)...
2023-07-19 00:04:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 4.00e+02 / 5.02e+02 batches (snr_loss = -5.59)...
2023-07-19 00:04:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 4.00e+02 / 5.02e+02 batches (ce_loss = +2.91)...
2023-07-19 00:04:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 4.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-19 00:04:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 4.00e+02 / 5.02e+02 batches (loss = -4.11)...
2023-07-19 00:04:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 4.00e+02 / 5.02e+02 batches (norm = +15.48)...
2023-07-19 00:12:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 5.00e+02 / 5.02e+02 batches (snr_loss = -5.58)...
2023-07-19 00:12:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 5.00e+02 / 5.02e+02 batches (ce_loss = +2.89)...
2023-07-19 00:12:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 5.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-19 00:12:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 5.00e+02 / 5.02e+02 batches (loss = -4.11)...
2023-07-19 00:12:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 5.00e+02 / 5.02e+02 batches (norm = +14.52)...
2023-07-19 00:12:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.999e-04) - Epoch 21: train = -4.0451(64.06m/502)
2023-07-19 00:12:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-19 00:17:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 1.00e+02 / 1.22e+02 batches (snr_loss = -5.59)...
2023-07-19 00:17:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 1.00e+02 / 1.22e+02 batches (ce_loss = +11.06)...
2023-07-19 00:17:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 1.00e+02 / 1.22e+02 batches (mae_loss = +0.03)...
2023-07-19 00:17:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:21 processed 1.00e+02 / 1.22e+02 batches (loss = -0.03)...
2023-07-19 00:17:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 122 batches: -0.25,-0.37,-0.09,-0.21,-0.07,-0.51,0.24,-0.93,0.21,-0.57,-0.73,0.05,-0.44,0.96,0.12,-0.39,0.58,1.27,0.22,-0.41,-1.32,0.29,0.83,0.28,0.20,-0.16,0.15,0.79,0.11,0.59,0.22,0.05,0.18,0.60,0.40,-0.50,1.16,0.04,-0.03,-0.74,-1.10,-0.12,0.18,-0.01,-0.96,0.50,-0.04,-0.10,0.18,0.47,1.06,-0.41,-0.53,-0.15,-0.38,0.66,0.32,-1.02,-0.63,-0.18,-0.37,-0.40,-0.02,0.11,1.05,0.10,-0.65,0.60,-0.28,0.13,0.31,0.92,-0.45,0.27,0.29,-1.67,-0.68,0.56,-0.27,-0.25,-0.77,0.48,0.56,0.03,0.17,-0.66,0.15,-0.22,0.68,-0.02,-0.32,-1.06,0.04,-0.37,-0.14,-1.34,0.92,0.30,-0.52,-0.02,0.27,0.60,0.17,-0.01,-0.49,-0.11,-0.42,0.13,0.95,0.11,-0.43,-0.72,-0.08,-0.29,0.10,-0.25,0.19,-0.32,0.06,0.72,-0.90,1.45
2023-07-19 00:17:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.999e-04) - Epoch 21: eval = -0.0208(4.97m/122)| no impr, best = 0.8950
2023-07-19 00:17:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-19 00:17:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-19 00:22:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 1.00e+02 / 5.02e+02 batches (snr_loss = -5.51)...
2023-07-19 00:22:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 1.00e+02 / 5.02e+02 batches (ce_loss = +2.89)...
2023-07-19 00:22:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 1.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-19 00:22:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 1.00e+02 / 5.02e+02 batches (loss = -4.04)...
2023-07-19 00:22:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 1.00e+02 / 5.02e+02 batches (norm = +17.19)...
2023-07-19 00:27:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 2.00e+02 / 5.02e+02 batches (snr_loss = -5.78)...
2023-07-19 00:27:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 2.00e+02 / 5.02e+02 batches (ce_loss = +2.88)...
2023-07-19 00:27:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 2.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-19 00:27:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 2.00e+02 / 5.02e+02 batches (loss = -4.31)...
2023-07-19 00:27:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 2.00e+02 / 5.02e+02 batches (norm = +40.86)...
2023-07-19 00:31:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 3.00e+02 / 5.02e+02 batches (snr_loss = -5.74)...
2023-07-19 00:31:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 3.00e+02 / 5.02e+02 batches (ce_loss = +2.87)...
2023-07-19 00:31:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 3.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-19 00:31:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 3.00e+02 / 5.02e+02 batches (loss = -4.27)...
2023-07-19 00:31:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 3.00e+02 / 5.02e+02 batches (norm = +13.42)...
2023-07-19 00:35:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 4.00e+02 / 5.02e+02 batches (snr_loss = -5.54)...
2023-07-19 00:35:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 4.00e+02 / 5.02e+02 batches (ce_loss = +2.86)...
2023-07-19 00:35:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 4.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-19 00:35:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 4.00e+02 / 5.02e+02 batches (loss = -4.08)...
2023-07-19 00:35:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 4.00e+02 / 5.02e+02 batches (norm = +14.53)...
2023-07-19 00:39:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 5.00e+02 / 5.02e+02 batches (snr_loss = -5.65)...
2023-07-19 00:39:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 5.00e+02 / 5.02e+02 batches (ce_loss = +2.88)...
2023-07-19 00:39:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 5.00e+02 / 5.02e+02 batches (mae_loss = +0.03)...
2023-07-19 00:39:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 5.00e+02 / 5.02e+02 batches (loss = -4.18)...
2023-07-19 00:39:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:22 processed 5.00e+02 / 5.02e+02 batches (norm = +28.59)...
2023-07-19 00:39:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=1.000e-03) - Epoch 22: train = -4.1775(22.07m/502)
2023-07-19 00:39:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-26 18:28:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-26 18:28:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-26 18:28:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 21
2023-07-26 18:29:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-26 18:29:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-26 18:29:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 21
2023-07-26 18:34:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-26 18:34:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-26 18:34:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 21
2023-07-26 18:38:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-26 18:38:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-26 18:38:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 21
2023-07-26 18:48:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-26 18:48:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-26 18:48:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 21
2023-07-26 19:00:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-26 19:00:28 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-26 19:00:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 21
2023-07-26 20:03:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-26 20:03:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-26 20:03:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 21
2023-07-26 20:10:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-26 20:10:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-26 20:11:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 21
2023-07-26 21:21:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-26 21:21:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-26 21:21:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 21
2023-07-26 21:30:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-26 21:30:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-26 21:30:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 21
2023-07-26 21:51:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-26 21:51:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-26 21:51:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 21
2023-07-26 21:53:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-26 21:53:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-26 21:53:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 21
2023-07-26 21:54:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-26 21:54:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-26 21:54:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 21
2023-07-26 21:57:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-26 21:57:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-26 21:57:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 21
2023-07-26 21:58:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-26 21:58:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-26 21:58:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume spk model from checkpoint /home/work_nfs4_ssd/hzhao/aslp-spknet-fork/exp/ecapa_augment_vox2/results/ecapa_augments_vox2/final.pth.tar
2023-07-26 22:06:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-26 22:06:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-26 22:06:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume spk model from checkpoint /home/work_nfs4_ssd/hzhao/aslp-spknet-fork/exp/ecapa_augment_vox2/results/ecapa_augments_vox2/final.pth.tar
2023-07-26 22:10:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-26 22:10:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-26 22:10:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume spk model from checkpoint /home/work_nfs4_ssd/hzhao/aslp-spknet-fork/exp/ecapa_augment_vox2/results/ecapa_augments_vox2/final.pth.tar
2023-07-26 22:25:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-26 22:25:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-26 22:25:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume spk model from checkpoint /home/work_nfs4_ssd/hzhao/aslp-spknet-fork/exp/ecapa_augment_vox2/results/ecapa_augments_vox2/final.pth.tar
2023-07-26 22:25:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: gradient clipping by 5.0, default L2
2023-07-26 22:25:55 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-26 22:27:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.00e+02 / 1.14e+03 batches (snr_loss = +45.03)...
2023-07-26 22:27:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.00e+02 / 1.14e+03 batches (ce_loss = +7.57)...
2023-07-26 22:27:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.00e+02 / 1.14e+03 batches (mae_loss = +0.07)...
2023-07-26 22:27:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.00e+02 / 1.14e+03 batches (loss = +48.88)...
2023-07-26 22:28:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.00e+02 / 1.14e+03 batches (snr_loss = +45.14)...
2023-07-26 22:28:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.00e+02 / 1.14e+03 batches (ce_loss = +7.57)...
2023-07-26 22:28:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.00e+02 / 1.14e+03 batches (mae_loss = +0.07)...
2023-07-26 22:28:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.00e+02 / 1.14e+03 batches (loss = +48.99)...
2023-07-26 22:29:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-26 22:29:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-26 22:29:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume spk model from checkpoint /home/work_nfs4_ssd/hzhao/aslp-spknet-fork/exp/ecapa_augment_vox2/results/ecapa_augments_vox2/final.pth.tar
2023-07-26 22:30:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-26 22:30:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-26 22:30:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume spk model from checkpoint /home/work_nfs4_ssd/hzhao/aslp-spknet-fork/exp/ecapa_augment_vox2/results/ecapa_augments_vox2/final.pth.tar
2023-07-26 22:30:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: gradient clipping by 5.0, default L2
2023-07-26 22:30:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-26 22:35:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.00e+02 / 2.86e+02 batches (snr_loss = +46.55)...
2023-07-26 22:35:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.00e+02 / 2.86e+02 batches (ce_loss = +7.59)...
2023-07-26 22:35:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.00e+02 / 2.86e+02 batches (mae_loss = +0.07)...
2023-07-26 22:35:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.00e+02 / 2.86e+02 batches (loss = +50.42)...
2023-07-26 22:42:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.00e+02 / 2.86e+02 batches (snr_loss = +46.49)...
2023-07-26 22:42:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.00e+02 / 2.86e+02 batches (ce_loss = +7.59)...
2023-07-26 22:42:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.00e+02 / 2.86e+02 batches (mae_loss = +0.07)...
2023-07-26 22:42:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.00e+02 / 2.86e+02 batches (loss = +50.35)...
2023-07-26 22:47:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 286 batches: 51.37,52.03,52.10,50.48,49.95,50.38,52.18,49.59,52.15,50.58,50.82,49.12,49.15,49.48,48.80,50.86,51.91,50.43,52.60,50.23,49.82,49.25,51.30,49.53,51.39,50.87,49.40,50.75,50.57,52.68,49.49,49.40,51.94,51.77,50.09,49.29,50.03,51.06,48.08,51.67,51.26,50.03,48.60,50.44,49.32,49.82,50.15,50.90,50.27,50.42,49.39,49.48,50.07,50.28,50.76,49.60,51.85,52.77,49.39,49.63,50.01,48.94,52.87,49.06,51.62,49.56,49.76,50.12,49.41,51.77,50.00,48.39,51.05,50.35,50.62,49.49,48.70,49.69,51.76,51.13,49.76,53.76,50.08,49.47,50.35,50.94,49.18,50.55,50.62,52.10,50.84,49.66,49.78,50.06,49.10,51.15,50.52,51.93,49.43,51.33,50.50,51.01,49.06,51.41,49.03,50.96,50.92,49.82,51.62,50.08,51.68,50.59,51.05,50.59,51.12,47.46,51.38,50.39,50.53,53.87,51.43,48.70,51.23,50.71,50.70,49.81,49.84,51.50,49.62,51.29,49.57,48.60,52.68,51.68,48.20,51.49,50.04,49.37,50.08,50.86,50.30,51.59,50.41,48.73,48.71,49.85,51.61,50.58,49.75,49.98,49.88,51.29,49.64,50.10,50.50,48.56,50.30,50.56,51.31,51.59,49.36,49.78,48.34,51.27,50.25,52.83,51.80,50.72,51.75,50.15,50.68,49.37,49.68,49.26,50.51,50.81,48.14,52.18,49.82,48.97,51.59,52.07,49.29,51.21,51.67,50.59,49.46,49.10,50.33,51.96,49.62,50.91,49.66,49.08,50.66,48.88,48.67,50.65,50.05,48.52,50.13,50.39,51.23,48.45,48.81,51.41,48.09,49.36,50.96,51.77,52.29,49.93,50.75,50.78,52.92,51.40,50.43,49.30,50.59,51.38,50.02,50.60,50.96,51.43,52.44,52.20,50.99,50.35,49.27,48.48,48.60,49.59,49.85,51.05,51.98,48.98,50.26,49.51,50.01,49.22,50.17,50.31,51.69,50.37,53.54,50.55,50.78,49.79,50.92,50.42,48.21,51.55,49.23,50.35,51.79,52.05,51.37,50.47,50.84,49.71,51.29,52.44,48.36,50.83,48.55,49.68,51.18,52.66,49.07,52.96,49.96,50.61,51.12,50.40,52.52,51.70,49.23,49.81,49.73,51.10,50.04,48.77,52.98,50.48,48.48,51.06
2023-07-26 22:47:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: start from epoch 0, loss = 50.4286
2023-07-26 22:47:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-26 22:55:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 1.18e+03 batches (snr_loss = -1.83)...
2023-07-26 22:55:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 1.18e+03 batches (ce_loss = +6.69)...
2023-07-26 22:55:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 1.18e+03 batches (mae_loss = +0.15)...
2023-07-26 22:55:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 1.18e+03 batches (loss = +1.66)...
2023-07-26 22:55:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 1.18e+03 batches (norm = +11.22)...
2023-07-26 23:03:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 1.18e+03 batches (snr_loss = -3.44)...
2023-07-26 23:03:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 1.18e+03 batches (ce_loss = +5.52)...
2023-07-26 23:03:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 1.18e+03 batches (mae_loss = +0.11)...
2023-07-26 23:03:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 1.18e+03 batches (loss = -0.57)...
2023-07-26 23:03:09 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 1.18e+03 batches (norm = +11.47)...
2023-07-26 23:11:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 1.18e+03 batches (snr_loss = -3.65)...
2023-07-26 23:11:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 1.18e+03 batches (ce_loss = +5.00)...
2023-07-26 23:11:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 1.18e+03 batches (mae_loss = +0.11)...
2023-07-26 23:11:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 1.18e+03 batches (loss = -1.04)...
2023-07-26 23:11:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 1.18e+03 batches (norm = +5.16)...
2023-07-26 23:20:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 1.18e+03 batches (snr_loss = -3.59)...
2023-07-26 23:20:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 1.18e+03 batches (ce_loss = +4.82)...
2023-07-26 23:20:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 1.18e+03 batches (mae_loss = +0.08)...
2023-07-26 23:20:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 1.18e+03 batches (loss = -1.10)...
2023-07-26 23:20:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 1.18e+03 batches (norm = +18.10)...
2023-07-26 23:30:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 1.18e+03 batches (snr_loss = -3.69)...
2023-07-26 23:30:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 1.18e+03 batches (ce_loss = +4.73)...
2023-07-26 23:30:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 1.18e+03 batches (mae_loss = +0.07)...
2023-07-26 23:30:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 1.18e+03 batches (loss = -1.25)...
2023-07-26 23:30:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 1.18e+03 batches (norm = +36.45)...
2023-07-26 23:39:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 1.18e+03 batches (snr_loss = -3.68)...
2023-07-26 23:39:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 1.18e+03 batches (ce_loss = +4.68)...
2023-07-26 23:39:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 1.18e+03 batches (mae_loss = +0.07)...
2023-07-26 23:39:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 1.18e+03 batches (loss = -1.28)...
2023-07-26 23:39:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 1.18e+03 batches (norm = +34.36)...
2023-07-26 23:47:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 1.18e+03 batches (snr_loss = -3.70)...
2023-07-26 23:47:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 1.18e+03 batches (ce_loss = +4.67)...
2023-07-26 23:47:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-26 23:47:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 1.18e+03 batches (loss = -1.30)...
2023-07-26 23:47:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 1.18e+03 batches (norm = +30.91)...
2023-07-26 23:56:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 1.18e+03 batches (snr_loss = -3.78)...
2023-07-26 23:56:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 1.18e+03 batches (ce_loss = +4.65)...
2023-07-26 23:56:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-26 23:56:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 1.18e+03 batches (loss = -1.40)...
2023-07-26 23:56:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 1.18e+03 batches (norm = +20.48)...
2023-07-27 00:09:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 1.18e+03 batches (snr_loss = -3.69)...
2023-07-27 00:09:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 1.18e+03 batches (ce_loss = +4.63)...
2023-07-27 00:09:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 00:09:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 1.18e+03 batches (loss = -1.31)...
2023-07-27 00:09:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 1.18e+03 batches (norm = +31.54)...
2023-07-27 00:17:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 1.18e+03 batches (snr_loss = -3.81)...
2023-07-27 00:17:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 1.18e+03 batches (ce_loss = +4.61)...
2023-07-27 00:17:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 00:17:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 1.18e+03 batches (loss = -1.45)...
2023-07-27 00:17:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 1.18e+03 batches (norm = +34.50)...
2023-07-27 00:25:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 1.18e+03 batches (snr_loss = -3.66)...
2023-07-27 00:25:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 1.18e+03 batches (ce_loss = +4.60)...
2023-07-27 00:25:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 00:25:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 1.18e+03 batches (loss = -1.30)...
2023-07-27 00:25:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 1.18e+03 batches (norm = +35.74)...
2023-07-27 00:31:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=1.000e-03) - Epoch  1: train = -0.9691(103.84m/1178)
2023-07-27 00:31:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-27 00:36:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 2.86e+02 batches (snr_loss = -3.67)...
2023-07-27 00:36:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 2.86e+02 batches (ce_loss = +9.18)...
2023-07-27 00:36:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 2.86e+02 batches (mae_loss = +0.06)...
2023-07-27 00:36:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 2.86e+02 batches (loss = +0.98)...
2023-07-27 00:42:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 2.86e+02 batches (snr_loss = -3.80)...
2023-07-27 00:42:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 2.86e+02 batches (ce_loss = +9.17)...
2023-07-27 00:42:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 2.86e+02 batches (mae_loss = +0.06)...
2023-07-27 00:42:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 2.86e+02 batches (loss = +0.84)...
2023-07-27 00:47:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 286 batches: -0.68,1.75,1.95,1.05,0.26,1.30,0.94,0.98,0.57,1.65,-0.83,0.13,0.75,1.54,1.72,2.56,-0.11,-0.23,1.86,0.30,1.63,1.82,1.61,0.81,1.99,1.06,0.44,0.78,1.67,-0.64,1.88,0.74,0.48,1.12,-0.54,2.56,0.90,1.02,0.44,0.29,0.98,1.41,1.34,2.73,1.47,1.17,0.52,0.37,0.09,0.77,0.10,0.33,0.75,0.40,1.70,1.23,0.19,2.07,-0.89,0.58,2.52,0.53,1.83,0.73,0.20,1.15,0.50,2.50,-0.59,1.58,1.80,0.58,0.10,1.60,-0.73,0.89,0.48,1.57,2.71,1.65,1.18,0.39,1.58,0.96,2.48,1.43,1.90,1.14,0.99,-0.32,1.83,-0.66,1.53,0.74,1.43,1.22,-0.39,0.33,0.70,3.03,0.27,1.34,1.22,0.92,0.34,1.36,2.07,0.45,0.83,1.28,1.26,0.38,1.18,2.07,-0.02,0.84,0.21,-0.24,1.50,1.77,0.65,-1.58,0.14,0.54,-0.03,0.35,0.32,0.25,2.26,0.47,1.20,0.74,-0.18,1.51,2.03,0.82,-0.09,-0.07,-1.18,0.12,0.79,1.15,1.68,0.59,1.22,1.01,1.13,-0.65,1.17,-0.30,0.46,0.45,0.39,1.05,0.25,-0.63,1.40,2.90,0.87,1.81,1.44,0.48,0.42,0.01,-0.03,2.18,1.37,0.54,0.24,1.43,0.42,0.20,1.88,1.04,1.24,2.28,0.64,0.22,-0.74,1.01,0.88,2.13,2.09,2.12,2.38,1.04,0.32,2.16,-0.10,2.29,1.25,0.84,1.44,1.01,1.07,0.09,0.35,1.24,0.61,0.50,0.81,0.65,1.36,0.05,0.39,0.83,0.79,0.74,2.41,2.84,0.59,2.69,1.65,2.16,0.13,-2.01,0.98,0.54,-0.24,0.63,-0.22,0.80,0.51,1.34,2.26,0.54,0.41,1.82,0.08,1.15,2.01,0.27,-1.70,0.99,1.89,1.46,0.68,0.77,0.68,0.27,2.29,0.36,0.60,-0.08,1.55,0.58,-0.32,1.37,0.63,1.20,0.49,1.43,0.50,1.73,1.85,1.03,1.67,2.39,0.76,-0.14,0.66,2.03,1.35,2.03,1.69,0.24,0.59,2.28,0.30,1.75,0.66,0.01,1.58,1.45,1.00,0.12,0.62,0.50,0.83,0.79,0.54,-1.40,0.96,-0.19,-0.42,-0.36
2023-07-27 00:47:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint best.pt.tar
2023-07-27 00:47:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=1.000e-03) - Epoch  1: eval = 0.8931(16.29m/286)
2023-07-27 00:47:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-27 00:47:47 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-27 00:58:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 1.18e+03 batches (snr_loss = -3.71)...
2023-07-27 00:58:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 1.18e+03 batches (ce_loss = +4.60)...
2023-07-27 00:58:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 00:58:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 1.18e+03 batches (loss = -1.36)...
2023-07-27 00:58:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 1.18e+03 batches (norm = +40.02)...
2023-07-27 01:07:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 1.18e+03 batches (snr_loss = -3.64)...
2023-07-27 01:07:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 1.18e+03 batches (ce_loss = +4.56)...
2023-07-27 01:07:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 01:07:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 1.18e+03 batches (loss = -1.30)...
2023-07-27 01:07:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 1.18e+03 batches (norm = +30.23)...
2023-07-27 01:17:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 1.18e+03 batches (snr_loss = -3.63)...
2023-07-27 01:17:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 1.18e+03 batches (ce_loss = +4.55)...
2023-07-27 01:17:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 01:17:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 1.18e+03 batches (loss = -1.30)...
2023-07-27 01:17:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 1.18e+03 batches (norm = +57.45)...
2023-07-27 01:26:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 1.18e+03 batches (snr_loss = -3.48)...
2023-07-27 01:26:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 1.18e+03 batches (ce_loss = +4.53)...
2023-07-27 01:26:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 01:26:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 1.18e+03 batches (loss = -1.16)...
2023-07-27 01:26:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 1.18e+03 batches (norm = +38.12)...
2023-07-27 01:37:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 1.18e+03 batches (snr_loss = -3.56)...
2023-07-27 01:37:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 1.18e+03 batches (ce_loss = +4.51)...
2023-07-27 01:37:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 01:37:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 1.18e+03 batches (loss = -1.25)...
2023-07-27 01:37:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 1.18e+03 batches (norm = +127.10)...
2023-07-27 01:51:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 1.18e+03 batches (snr_loss = -3.82)...
2023-07-27 01:51:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 1.18e+03 batches (ce_loss = +4.47)...
2023-07-27 01:51:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 01:51:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 1.18e+03 batches (loss = -1.53)...
2023-07-27 01:51:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 1.18e+03 batches (norm = +178.07)...
2023-07-27 02:03:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 1.18e+03 batches (snr_loss = -3.60)...
2023-07-27 02:03:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 1.18e+03 batches (ce_loss = +4.47)...
2023-07-27 02:03:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 02:03:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 1.18e+03 batches (loss = -1.31)...
2023-07-27 02:03:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 1.18e+03 batches (norm = +45.72)...
2023-07-27 02:17:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 1.18e+03 batches (snr_loss = -3.73)...
2023-07-27 02:17:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 1.18e+03 batches (ce_loss = +4.42)...
2023-07-27 02:17:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 02:17:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 1.18e+03 batches (loss = -1.46)...
2023-07-27 02:17:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 1.18e+03 batches (norm = +29.56)...
2023-07-27 02:32:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 1.18e+03 batches (snr_loss = -3.53)...
2023-07-27 02:32:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 1.18e+03 batches (ce_loss = +4.41)...
2023-07-27 02:32:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 02:32:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 1.18e+03 batches (loss = -1.27)...
2023-07-27 02:32:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 1.18e+03 batches (norm = +26.84)...
2023-07-27 02:45:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 1.18e+03 batches (snr_loss = -3.63)...
2023-07-27 02:45:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 1.18e+03 batches (ce_loss = +4.39)...
2023-07-27 02:45:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 02:45:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 1.18e+03 batches (loss = -1.38)...
2023-07-27 02:45:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 1.18e+03 batches (norm = +30.76)...
2023-07-27 02:57:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 1.18e+03 batches (snr_loss = -3.74)...
2023-07-27 02:57:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 1.18e+03 batches (ce_loss = +4.37)...
2023-07-27 02:57:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 02:57:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 1.18e+03 batches (loss = -1.49)...
2023-07-27 02:57:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 1.18e+03 batches (norm = +45.23)...
2023-07-27 03:06:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.992e-04) - Epoch  2: train = -1.3454(138.20m/1178)
2023-07-27 03:06:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-27 03:16:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 2.86e+02 batches (snr_loss = -3.58)...
2023-07-27 03:16:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 2.86e+02 batches (ce_loss = +9.66)...
2023-07-27 03:16:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 2.86e+02 batches (mae_loss = +0.06)...
2023-07-27 03:16:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 2.86e+02 batches (loss = +1.30)...
2023-07-27 03:25:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 2.86e+02 batches (snr_loss = -3.45)...
2023-07-27 03:25:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 2.86e+02 batches (ce_loss = +9.65)...
2023-07-27 03:25:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 2.86e+02 batches (mae_loss = +0.06)...
2023-07-27 03:25:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 2.86e+02 batches (loss = +1.43)...
2023-07-27 03:32:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 286 batches: 0.50,2.52,1.41,1.73,1.32,1.43,1.36,1.07,1.89,2.55,0.15,2.20,1.53,3.04,1.17,0.19,3.12,1.35,1.00,1.63,0.44,0.75,1.57,-0.35,1.39,1.84,1.11,1.71,0.68,0.67,0.92,0.07,-0.90,0.84,1.13,1.22,0.09,1.78,1.13,1.05,1.07,0.98,0.81,0.14,0.64,1.90,2.17,-0.48,1.81,1.12,2.31,0.77,2.33,1.06,1.74,1.84,2.08,1.79,0.81,3.59,2.01,-0.39,0.79,2.52,3.09,2.15,0.63,1.79,1.22,1.80,2.92,1.81,-1.07,0.98,0.28,0.27,1.66,0.68,2.39,1.41,2.15,0.71,-0.20,1.76,1.70,0.23,2.67,1.46,2.02,3.04,1.64,2.81,1.18,1.40,0.43,0.10,0.44,0.93,1.07,0.96,0.73,3.18,2.56,0.84,-0.13,1.81,1.10,1.64,1.30,1.51,-0.50,3.06,3.08,1.46,1.13,1.79,1.92,1.61,1.33,2.16,2.30,0.42,0.62,1.25,1.62,-0.24,3.53,1.39,1.53,2.42,0.96,1.01,1.27,2.06,1.37,0.56,0.37,2.99,2.04,1.76,1.96,0.05,2.98,1.57,1.32,0.84,2.11,1.75,-0.26,0.96,1.08,2.40,2.20,1.29,1.86,1.57,-0.03,1.13,2.35,1.66,1.26,-0.43,0.84,1.69,-0.82,1.22,1.98,0.93,2.42,1.35,1.35,1.83,2.45,1.56,2.04,1.84,1.81,1.55,1.49,1.21,0.79,1.24,0.96,2.51,-0.10,0.25,0.31,0.66,1.98,0.79,2.17,1.22,1.39,3.01,0.30,2.95,0.44,2.28,1.32,1.74,0.13,0.27,0.76,2.57,0.52,0.50,0.94,0.76,1.52,1.40,1.00,0.83,1.25,0.71,2.65,1.02,1.41,1.55,1.92,1.60,-0.06,1.61,0.34,1.74,0.72,1.41,1.20,0.07,2.30,2.25,1.85,0.65,2.62,2.09,-0.54,1.82,-0.12,0.47,0.77,1.94,1.04,0.62,2.25,1.88,0.69,0.03,1.30,1.71,-0.08,1.56,2.31,0.89,0.73,1.10,0.90,0.13,1.06,0.18,1.71,0.86,1.32,0.50,1.61,0.76,1.43,0.82,0.20,0.88,0.81,2.04,2.26,1.23,0.70,1.22,1.70,1.65,2.40,2.23,1.05,1.80,1.68,2.38,1.42,0.31,0.75,1.49
2023-07-27 03:32:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.992e-04) - Epoch  2: eval = 1.3130(26.39m/286)| no impr, best = 50.4286
2023-07-27 03:32:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-27 03:32:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-27 03:44:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+02 / 1.18e+03 batches (snr_loss = -3.67)...
2023-07-27 03:44:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+02 / 1.18e+03 batches (ce_loss = +4.33)...
2023-07-27 03:44:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 03:44:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+02 / 1.18e+03 batches (loss = -1.45)...
2023-07-27 03:44:48 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+02 / 1.18e+03 batches (norm = +65.56)...
2023-07-27 03:57:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 2.00e+02 / 1.18e+03 batches (snr_loss = -3.69)...
2023-07-27 03:57:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 2.00e+02 / 1.18e+03 batches (ce_loss = +4.30)...
2023-07-27 03:57:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 2.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 03:57:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 2.00e+02 / 1.18e+03 batches (loss = -1.49)...
2023-07-27 03:57:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 2.00e+02 / 1.18e+03 batches (norm = +38.17)...
2023-07-27 04:08:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 3.00e+02 / 1.18e+03 batches (snr_loss = -3.60)...
2023-07-27 04:08:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 3.00e+02 / 1.18e+03 batches (ce_loss = +4.28)...
2023-07-27 04:08:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 3.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 04:08:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 3.00e+02 / 1.18e+03 batches (loss = -1.40)...
2023-07-27 04:08:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 3.00e+02 / 1.18e+03 batches (norm = +78.11)...
2023-07-27 04:19:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 4.00e+02 / 1.18e+03 batches (snr_loss = -3.69)...
2023-07-27 04:19:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 4.00e+02 / 1.18e+03 batches (ce_loss = +4.27)...
2023-07-27 04:19:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 4.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 04:19:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 4.00e+02 / 1.18e+03 batches (loss = -1.49)...
2023-07-27 04:19:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 4.00e+02 / 1.18e+03 batches (norm = +45.47)...
2023-07-27 04:31:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 5.00e+02 / 1.18e+03 batches (snr_loss = -3.73)...
2023-07-27 04:31:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 5.00e+02 / 1.18e+03 batches (ce_loss = +4.26)...
2023-07-27 04:31:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 5.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 04:31:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 5.00e+02 / 1.18e+03 batches (loss = -1.55)...
2023-07-27 04:31:35 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 5.00e+02 / 1.18e+03 batches (norm = +33.12)...
2023-07-27 04:41:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 6.00e+02 / 1.18e+03 batches (snr_loss = -3.82)...
2023-07-27 04:41:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 6.00e+02 / 1.18e+03 batches (ce_loss = +4.26)...
2023-07-27 04:41:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 6.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 04:41:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 6.00e+02 / 1.18e+03 batches (loss = -1.64)...
2023-07-27 04:41:56 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 6.00e+02 / 1.18e+03 batches (norm = +35.92)...
2023-07-27 04:52:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 7.00e+02 / 1.18e+03 batches (snr_loss = -3.82)...
2023-07-27 04:52:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 7.00e+02 / 1.18e+03 batches (ce_loss = +4.24)...
2023-07-27 04:52:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 7.00e+02 / 1.18e+03 batches (mae_loss = +0.05)...
2023-07-27 04:52:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 7.00e+02 / 1.18e+03 batches (loss = -1.65)...
2023-07-27 04:52:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 7.00e+02 / 1.18e+03 batches (norm = +51.82)...
2023-07-27 05:03:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 8.00e+02 / 1.18e+03 batches (snr_loss = -3.68)...
2023-07-27 05:03:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 8.00e+02 / 1.18e+03 batches (ce_loss = +4.23)...
2023-07-27 05:03:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 8.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 05:03:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 8.00e+02 / 1.18e+03 batches (loss = -1.50)...
2023-07-27 05:03:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 8.00e+02 / 1.18e+03 batches (norm = +61.57)...
2023-07-27 05:16:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 9.00e+02 / 1.18e+03 batches (snr_loss = -3.84)...
2023-07-27 05:16:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 9.00e+02 / 1.18e+03 batches (ce_loss = +4.23)...
2023-07-27 05:16:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 9.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 05:16:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 9.00e+02 / 1.18e+03 batches (loss = -1.67)...
2023-07-27 05:16:08 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 9.00e+02 / 1.18e+03 batches (norm = +55.82)...
2023-07-27 05:26:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+03 / 1.18e+03 batches (snr_loss = -3.77)...
2023-07-27 05:26:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+03 / 1.18e+03 batches (ce_loss = +4.21)...
2023-07-27 05:26:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+03 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 05:26:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+03 / 1.18e+03 batches (loss = -1.61)...
2023-07-27 05:26:23 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+03 / 1.18e+03 batches (norm = +40.10)...
2023-07-27 05:42:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.10e+03 / 1.18e+03 batches (snr_loss = -3.66)...
2023-07-27 05:42:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.10e+03 / 1.18e+03 batches (ce_loss = +4.19)...
2023-07-27 05:42:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.10e+03 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 05:42:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.10e+03 / 1.18e+03 batches (loss = -1.51)...
2023-07-27 05:42:24 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.10e+03 / 1.18e+03 batches (norm = +35.69)...
2023-07-27 05:53:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.983e-04) - Epoch  3: train = -1.5401(140.67m/1178)
2023-07-27 05:53:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-27 06:04:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+02 / 2.86e+02 batches (snr_loss = -3.64)...
2023-07-27 06:04:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+02 / 2.86e+02 batches (ce_loss = +9.77)...
2023-07-27 06:04:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+02 / 2.86e+02 batches (mae_loss = +0.05)...
2023-07-27 06:04:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+02 / 2.86e+02 batches (loss = +1.29)...
2023-07-27 06:14:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 2.00e+02 / 2.86e+02 batches (snr_loss = -3.64)...
2023-07-27 06:14:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 2.00e+02 / 2.86e+02 batches (ce_loss = +9.77)...
2023-07-27 06:14:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 2.00e+02 / 2.86e+02 batches (mae_loss = +0.05)...
2023-07-27 06:14:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 2.00e+02 / 2.86e+02 batches (loss = +1.30)...
2023-07-27 06:21:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 286 batches: 0.23,-0.49,2.22,1.36,0.71,0.40,1.31,1.59,2.35,1.74,1.98,-0.38,0.43,1.58,1.73,0.59,1.78,2.58,0.39,1.25,1.65,1.27,2.34,0.20,0.94,0.37,1.16,1.24,2.37,0.06,2.33,1.90,1.25,1.14,-1.21,0.13,1.97,1.02,1.40,0.70,1.76,1.67,0.52,0.59,0.24,1.79,1.81,1.10,1.53,0.16,0.41,3.10,1.64,2.47,2.85,0.60,0.07,1.34,1.47,0.71,0.73,1.00,0.95,1.03,1.62,0.01,1.47,1.73,1.96,1.02,1.75,1.41,0.98,0.38,2.41,2.64,1.29,-0.08,2.81,1.54,1.98,3.95,1.23,0.36,2.46,1.43,3.22,1.37,0.01,1.36,1.77,0.13,1.47,0.82,1.79,1.31,0.94,1.21,2.38,2.06,-0.25,1.37,0.98,1.35,2.40,0.60,1.88,1.56,1.21,1.25,2.06,0.75,0.98,0.27,2.13,0.70,1.42,0.47,1.61,1.16,1.18,3.35,0.64,1.16,-0.10,1.60,2.05,0.11,0.64,1.27,0.67,2.71,4.20,2.24,3.16,1.55,1.45,2.20,0.50,1.44,2.06,-0.68,1.80,2.52,1.98,0.38,2.37,1.02,0.15,2.18,1.19,0.96,0.44,1.68,0.21,1.89,1.76,0.36,-0.46,0.83,2.42,1.12,1.55,1.75,0.82,-0.99,0.83,2.92,1.05,2.70,1.24,1.30,0.18,2.24,0.97,2.04,2.02,2.13,2.81,1.37,0.77,1.07,1.86,1.35,1.26,2.23,-0.01,1.81,0.99,2.40,0.42,0.32,0.06,0.48,2.58,0.13,1.71,0.81,-0.48,0.79,2.44,1.28,0.60,1.35,1.11,2.73,-0.40,1.76,0.71,1.94,2.06,2.37,0.58,0.48,1.49,1.86,1.03,0.99,2.22,-0.22,1.86,2.17,-0.19,1.58,3.44,1.13,1.05,0.56,3.76,1.45,-0.51,-0.38,0.81,0.63,0.42,1.71,1.90,1.54,1.78,2.17,0.75,1.86,1.36,1.85,1.65,1.24,2.04,0.57,2.46,0.34,2.92,2.08,0.88,0.25,1.57,1.85,0.85,-0.65,1.18,1.88,1.55,0.29,2.79,1.42,2.28,2.05,0.82,0.11,0.67,1.37,0.37,1.45,1.42,1.24,0.69,1.46,2.08,1.19,1.71,0.19,-0.59,0.67,0.01,0.67,1.06,2.00
2023-07-27 06:21:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.983e-04) - Epoch  3: eval = 1.2871(28.78m/286)| no impr, best = 50.4286
2023-07-27 06:22:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-27 06:22:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-27 06:34:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 1.18e+03 batches (snr_loss = -3.76)...
2023-07-27 06:34:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 1.18e+03 batches (ce_loss = +4.15)...
2023-07-27 06:34:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 06:34:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 1.18e+03 batches (loss = -1.63)...
2023-07-27 06:34:32 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 1.18e+03 batches (norm = +32.20)...
2023-07-27 06:46:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 2.00e+02 / 1.18e+03 batches (snr_loss = -3.61)...
2023-07-27 06:46:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 2.00e+02 / 1.18e+03 batches (ce_loss = +4.13)...
2023-07-27 06:46:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 2.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 06:46:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 2.00e+02 / 1.18e+03 batches (loss = -1.49)...
2023-07-27 06:46:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 2.00e+02 / 1.18e+03 batches (norm = +33.40)...
2023-07-27 06:58:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 3.00e+02 / 1.18e+03 batches (snr_loss = -3.71)...
2023-07-27 06:58:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 3.00e+02 / 1.18e+03 batches (ce_loss = +4.11)...
2023-07-27 06:58:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 3.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 06:58:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 3.00e+02 / 1.18e+03 batches (loss = -1.60)...
2023-07-27 06:58:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 3.00e+02 / 1.18e+03 batches (norm = +54.10)...
2023-07-27 07:09:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 4.00e+02 / 1.18e+03 batches (snr_loss = -3.76)...
2023-07-27 07:09:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 4.00e+02 / 1.18e+03 batches (ce_loss = +4.11)...
2023-07-27 07:09:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 4.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 07:09:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 4.00e+02 / 1.18e+03 batches (loss = -1.65)...
2023-07-27 07:09:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 4.00e+02 / 1.18e+03 batches (norm = +30.78)...
2023-07-27 07:22:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 5.00e+02 / 1.18e+03 batches (snr_loss = -3.85)...
2023-07-27 07:22:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 5.00e+02 / 1.18e+03 batches (ce_loss = +4.09)...
2023-07-27 07:22:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 5.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 07:22:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 5.00e+02 / 1.18e+03 batches (loss = -1.75)...
2023-07-27 07:22:58 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 5.00e+02 / 1.18e+03 batches (norm = +67.95)...
2023-07-27 07:35:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 6.00e+02 / 1.18e+03 batches (snr_loss = -3.72)...
2023-07-27 07:35:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 6.00e+02 / 1.18e+03 batches (ce_loss = +4.07)...
2023-07-27 07:35:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 6.00e+02 / 1.18e+03 batches (mae_loss = +0.05)...
2023-07-27 07:35:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 6.00e+02 / 1.18e+03 batches (loss = -1.63)...
2023-07-27 07:35:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 6.00e+02 / 1.18e+03 batches (norm = +44.89)...
2023-07-27 07:45:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 7.00e+02 / 1.18e+03 batches (snr_loss = -3.79)...
2023-07-27 07:45:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 7.00e+02 / 1.18e+03 batches (ce_loss = +4.07)...
2023-07-27 07:45:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 7.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 07:45:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 7.00e+02 / 1.18e+03 batches (loss = -1.70)...
2023-07-27 07:45:34 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 7.00e+02 / 1.18e+03 batches (norm = +42.15)...
2023-07-27 07:56:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 8.00e+02 / 1.18e+03 batches (snr_loss = -3.86)...
2023-07-27 07:56:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 8.00e+02 / 1.18e+03 batches (ce_loss = +4.08)...
2023-07-27 07:56:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 8.00e+02 / 1.18e+03 batches (mae_loss = +0.05)...
2023-07-27 07:56:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 8.00e+02 / 1.18e+03 batches (loss = -1.77)...
2023-07-27 07:56:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 8.00e+02 / 1.18e+03 batches (norm = +51.26)...
2023-07-27 08:09:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 9.00e+02 / 1.18e+03 batches (snr_loss = -3.83)...
2023-07-27 08:09:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 9.00e+02 / 1.18e+03 batches (ce_loss = +4.06)...
2023-07-27 08:09:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 9.00e+02 / 1.18e+03 batches (mae_loss = +0.05)...
2023-07-27 08:09:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 9.00e+02 / 1.18e+03 batches (loss = -1.75)...
2023-07-27 08:09:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 9.00e+02 / 1.18e+03 batches (norm = +59.44)...
2023-07-27 08:21:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+03 / 1.18e+03 batches (snr_loss = -3.68)...
2023-07-27 08:21:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+03 / 1.18e+03 batches (ce_loss = +4.03)...
2023-07-27 08:21:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+03 / 1.18e+03 batches (mae_loss = +0.05)...
2023-07-27 08:21:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+03 / 1.18e+03 batches (loss = -1.61)...
2023-07-27 08:21:00 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+03 / 1.18e+03 batches (norm = +52.68)...
2023-07-27 08:32:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.10e+03 / 1.18e+03 batches (snr_loss = -3.94)...
2023-07-27 08:32:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.10e+03 / 1.18e+03 batches (ce_loss = +4.05)...
2023-07-27 08:32:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.10e+03 / 1.18e+03 batches (mae_loss = +0.05)...
2023-07-27 08:32:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.10e+03 / 1.18e+03 batches (loss = -1.86)...
2023-07-27 08:32:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.10e+03 / 1.18e+03 batches (norm = +78.24)...
2023-07-27 08:40:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.984e-04) - Epoch  4: train = -1.6846(138.30m/1178)
2023-07-27 08:40:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-27 08:50:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 2.86e+02 batches (snr_loss = -3.69)...
2023-07-27 08:50:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 2.86e+02 batches (ce_loss = +9.97)...
2023-07-27 08:50:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 2.86e+02 batches (mae_loss = +0.05)...
2023-07-27 08:50:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 2.86e+02 batches (loss = +1.35)...
2023-07-27 09:00:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 2.00e+02 / 2.86e+02 batches (snr_loss = -3.60)...
2023-07-27 09:00:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 2.00e+02 / 2.86e+02 batches (ce_loss = +9.97)...
2023-07-27 09:00:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 2.00e+02 / 2.86e+02 batches (mae_loss = +0.05)...
2023-07-27 09:00:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 2.00e+02 / 2.86e+02 batches (loss = +1.43)...
2023-07-27 09:07:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 286 batches: 1.60,2.33,2.17,2.87,2.59,0.49,2.32,1.78,1.96,1.12,1.29,1.26,1.43,2.89,0.57,2.76,2.19,1.41,2.24,1.80,1.58,0.84,1.97,1.06,-0.00,1.84,0.88,2.24,0.43,1.17,1.31,3.00,0.41,0.63,1.13,0.30,2.07,2.03,0.21,0.27,0.39,1.93,2.01,1.32,2.41,2.83,1.63,0.78,1.65,0.07,1.33,1.98,1.49,1.33,1.74,0.68,1.46,0.42,2.71,1.52,0.47,-0.62,0.18,0.15,0.52,2.39,1.07,0.70,0.87,2.14,0.18,2.93,1.18,1.07,1.82,-0.23,0.07,1.15,0.05,2.22,0.96,1.76,1.86,0.89,2.10,0.56,0.72,0.35,0.24,0.28,1.35,2.30,1.83,2.44,2.01,1.15,0.52,2.22,1.29,1.82,2.25,1.64,1.22,1.72,1.76,0.83,0.42,1.06,2.28,2.34,0.69,1.72,1.99,2.48,2.87,1.36,2.42,1.16,2.11,1.41,2.19,2.13,0.77,1.14,1.69,-0.27,0.84,1.74,0.68,0.62,0.43,2.25,-0.71,1.44,0.63,1.95,0.87,0.34,1.89,1.78,1.58,1.05,1.80,1.58,0.01,1.83,0.06,0.51,1.07,1.58,0.75,2.08,1.79,0.75,0.27,2.04,1.84,1.91,2.02,1.05,2.21,1.85,2.32,1.82,1.01,1.96,2.41,2.74,2.95,1.20,-1.11,3.12,0.52,2.29,1.85,1.20,-1.71,1.25,2.69,-0.50,1.87,2.05,2.22,-0.72,1.43,2.11,1.39,1.85,1.00,0.89,1.15,0.34,3.00,2.48,0.63,1.04,2.01,2.67,2.53,1.53,0.99,1.94,1.55,1.27,1.15,2.20,0.68,1.91,0.74,0.52,1.15,0.59,1.81,2.40,1.63,0.51,1.53,1.65,1.25,-0.20,3.38,1.90,2.10,1.44,1.86,2.18,0.38,2.80,1.76,1.24,2.17,2.79,3.63,0.54,0.56,0.40,1.78,1.27,2.10,1.38,2.68,1.01,1.17,0.35,2.02,2.42,2.13,2.20,2.01,0.73,3.39,2.06,0.04,1.02,2.28,2.74,2.63,0.93,1.29,2.45,1.81,1.88,1.57,1.64,1.19,2.51,1.46,0.26,1.39,1.72,2.13,1.93,2.09,1.90,1.66,0.75,1.69,2.72,0.95,2.28,2.34,2.04,1.10,1.24,0.34,1.96
2023-07-27 09:07:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.984e-04) - Epoch  4: eval = 1.4592(26.97m/286)| no impr, best = 50.4286
2023-07-27 09:07:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-27 09:07:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-27 09:20:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+02 / 1.18e+03 batches (snr_loss = -3.67)...
2023-07-27 09:20:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+02 / 1.18e+03 batches (ce_loss = +4.03)...
2023-07-27 09:20:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+02 / 1.18e+03 batches (mae_loss = +0.05)...
2023-07-27 09:20:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+02 / 1.18e+03 batches (loss = -1.60)...
2023-07-27 09:20:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+02 / 1.18e+03 batches (norm = +64.08)...
2023-07-27 09:33:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 2.00e+02 / 1.18e+03 batches (snr_loss = -3.50)...
2023-07-27 09:33:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 2.00e+02 / 1.18e+03 batches (ce_loss = +4.00)...
2023-07-27 09:33:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 2.00e+02 / 1.18e+03 batches (mae_loss = +0.06)...
2023-07-27 09:33:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 2.00e+02 / 1.18e+03 batches (loss = -1.44)...
2023-07-27 09:33:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 2.00e+02 / 1.18e+03 batches (norm = +52.55)...
2023-07-27 09:45:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 3.00e+02 / 1.18e+03 batches (snr_loss = -3.66)...
2023-07-27 09:45:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 3.00e+02 / 1.18e+03 batches (ce_loss = +3.98)...
2023-07-27 09:45:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 3.00e+02 / 1.18e+03 batches (mae_loss = +0.05)...
2023-07-27 09:45:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 3.00e+02 / 1.18e+03 batches (loss = -1.61)...
2023-07-27 09:45:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 3.00e+02 / 1.18e+03 batches (norm = +34.64)...
2023-07-27 09:56:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-27 09:56:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-27 09:56:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 4
2023-07-27 09:56:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: gradient clipping by 5.0, default L2
2023-07-27 09:56:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-27 10:02:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 5.72e+02 batches (snr_loss = -3.84)...
2023-07-27 10:02:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 5.72e+02 batches (ce_loss = +9.97)...
2023-07-27 10:02:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 5.72e+02 batches (mae_loss = +0.05)...
2023-07-27 10:02:22 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 5.72e+02 batches (loss = +1.20)...
2023-07-27 10:06:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 2.00e+02 / 5.72e+02 batches (snr_loss = -3.67)...
2023-07-27 10:06:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 2.00e+02 / 5.72e+02 batches (ce_loss = +9.97)...
2023-07-27 10:06:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 2.00e+02 / 5.72e+02 batches (mae_loss = +0.05)...
2023-07-27 10:06:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 2.00e+02 / 5.72e+02 batches (loss = +1.37)...
2023-07-27 10:11:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 3076, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((3076,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=3332, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=3076, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(3076, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-27 10:11:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 18.08M
2023-07-27 10:11:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 4
2023-07-27 10:14:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-27 10:14:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-27 10:14:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 4
2023-07-27 10:14:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: gradient clipping by 5.0, default L2
2023-07-27 10:14:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-27 10:22:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 2.86e+02 batches (snr_loss = -3.67)...
2023-07-27 10:22:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 2.86e+02 batches (ce_loss = +9.97)...
2023-07-27 10:22:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 2.86e+02 batches (mae_loss = +0.05)...
2023-07-27 10:22:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 1.00e+02 / 2.86e+02 batches (loss = +1.37)...
2023-07-27 10:26:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 2.00e+02 / 2.86e+02 batches (snr_loss = -3.60)...
2023-07-27 10:26:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 2.00e+02 / 2.86e+02 batches (ce_loss = +9.97)...
2023-07-27 10:26:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 2.00e+02 / 2.86e+02 batches (mae_loss = +0.05)...
2023-07-27 10:26:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:4 processed 2.00e+02 / 2.86e+02 batches (loss = +1.43)...
2023-07-27 10:32:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 286 batches: -0.26,1.62,1.34,0.95,1.96,2.83,1.07,2.10,3.07,0.53,2.98,1.34,2.28,0.93,0.87,2.82,2.51,2.10,1.11,2.55,3.34,0.21,1.56,0.39,0.92,1.56,0.36,2.46,0.74,1.01,0.87,0.28,0.30,2.19,0.78,1.16,0.96,1.14,3.92,1.87,2.22,2.50,3.10,1.33,1.46,1.80,-0.02,2.43,1.76,0.06,1.76,1.13,-0.12,1.85,2.12,1.45,1.04,1.55,0.78,0.47,1.89,0.65,2.09,1.06,1.38,1.31,0.65,1.14,2.62,0.43,0.66,0.60,1.11,1.07,2.85,1.67,2.51,1.95,0.18,1.63,-0.27,2.06,0.34,0.94,1.34,1.25,0.84,1.27,0.99,1.43,1.13,1.03,1.50,0.88,-0.41,1.09,0.93,0.97,1.10,1.60,0.89,1.20,2.20,2.33,1.69,1.61,1.04,1.72,0.28,1.40,-0.56,1.03,2.29,2.26,1.56,1.14,1.56,1.13,1.20,0.80,1.71,1.21,1.01,1.61,1.27,0.28,1.16,0.94,2.06,1.50,1.61,2.27,0.81,2.06,0.57,2.97,0.17,2.02,2.15,1.22,0.32,1.11,1.84,1.71,2.76,1.30,0.73,0.77,1.32,0.16,0.80,2.12,1.86,1.74,-0.06,3.54,1.39,0.92,0.80,1.08,1.88,1.03,2.35,1.88,1.63,1.55,0.92,2.40,1.46,1.13,2.12,0.26,2.09,0.24,2.64,1.65,0.64,2.24,0.35,1.60,3.29,2.31,1.28,1.77,2.14,0.88,1.42,2.00,2.25,2.81,0.95,1.68,1.52,1.13,2.40,0.98,-0.02,1.06,-0.12,2.06,1.50,1.64,1.99,2.60,2.13,1.39,1.82,3.09,2.33,1.10,1.33,0.94,2.16,1.05,1.94,3.01,1.07,0.96,0.76,-0.13,0.62,2.25,3.00,-0.12,0.83,0.72,1.73,3.24,1.19,0.89,1.24,0.29,1.07,1.91,1.04,2.64,1.20,2.57,2.43,1.31,2.35,1.39,1.85,1.80,1.82,1.67,1.22,2.08,1.18,2.16,2.24,0.90,0.02,0.39,1.98,3.02,0.55,1.78,2.49,1.44,0.82,1.12,1.92,2.22,1.25,0.97,0.48,1.86,2.12,2.17,3.17,0.17,1.02,2.00,2.43,0.54,1.48,1.92,0.69,0.26,2.21,1.82,-0.53,2.36,1.58,-0.53
2023-07-27 10:32:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: start from epoch 4, loss = 1.4366
2023-07-27 10:32:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-27 10:43:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+02 / 1.18e+03 batches (snr_loss = -3.57)...
2023-07-27 10:43:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+02 / 1.18e+03 batches (ce_loss = +4.02)...
2023-07-27 10:43:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+02 / 1.18e+03 batches (mae_loss = +0.05)...
2023-07-27 10:43:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+02 / 1.18e+03 batches (loss = -1.50)...
2023-07-27 10:43:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+02 / 1.18e+03 batches (norm = +50.10)...
2023-07-27 10:53:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 2.00e+02 / 1.18e+03 batches (snr_loss = -3.66)...
2023-07-27 10:53:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 2.00e+02 / 1.18e+03 batches (ce_loss = +3.99)...
2023-07-27 10:53:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 2.00e+02 / 1.18e+03 batches (mae_loss = +0.05)...
2023-07-27 10:53:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 2.00e+02 / 1.18e+03 batches (loss = -1.61)...
2023-07-27 10:53:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 2.00e+02 / 1.18e+03 batches (norm = +35.32)...
2023-07-27 11:04:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 3.00e+02 / 1.18e+03 batches (snr_loss = -3.86)...
2023-07-27 11:04:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 3.00e+02 / 1.18e+03 batches (ce_loss = +4.01)...
2023-07-27 11:04:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 3.00e+02 / 1.18e+03 batches (mae_loss = +0.05)...
2023-07-27 11:04:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 3.00e+02 / 1.18e+03 batches (loss = -1.80)...
2023-07-27 11:04:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 3.00e+02 / 1.18e+03 batches (norm = +52.24)...
2023-07-27 11:16:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 4.00e+02 / 1.18e+03 batches (snr_loss = -3.60)...
2023-07-27 11:16:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 4.00e+02 / 1.18e+03 batches (ce_loss = +4.00)...
2023-07-27 11:16:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 4.00e+02 / 1.18e+03 batches (mae_loss = +0.05)...
2023-07-27 11:16:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 4.00e+02 / 1.18e+03 batches (loss = -1.55)...
2023-07-27 11:16:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 4.00e+02 / 1.18e+03 batches (norm = +36.94)...
2023-07-27 11:29:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 5.00e+02 / 1.18e+03 batches (snr_loss = -3.80)...
2023-07-27 11:29:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 5.00e+02 / 1.18e+03 batches (ce_loss = +3.99)...
2023-07-27 11:29:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 5.00e+02 / 1.18e+03 batches (mae_loss = +0.05)...
2023-07-27 11:29:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 5.00e+02 / 1.18e+03 batches (loss = -1.75)...
2023-07-27 11:29:29 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 5.00e+02 / 1.18e+03 batches (norm = +51.62)...
2023-07-27 11:42:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 6.00e+02 / 1.18e+03 batches (snr_loss = -3.85)...
2023-07-27 11:42:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 6.00e+02 / 1.18e+03 batches (ce_loss = +4.00)...
2023-07-27 11:42:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 6.00e+02 / 1.18e+03 batches (mae_loss = +0.05)...
2023-07-27 11:42:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 6.00e+02 / 1.18e+03 batches (loss = -1.80)...
2023-07-27 11:42:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 6.00e+02 / 1.18e+03 batches (norm = +57.60)...
2023-07-27 11:58:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 7.00e+02 / 1.18e+03 batches (snr_loss = -3.59)...
2023-07-27 11:58:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 7.00e+02 / 1.18e+03 batches (ce_loss = +3.97)...
2023-07-27 11:58:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 7.00e+02 / 1.18e+03 batches (mae_loss = +0.05)...
2023-07-27 11:58:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 7.00e+02 / 1.18e+03 batches (loss = -1.56)...
2023-07-27 11:58:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 7.00e+02 / 1.18e+03 batches (norm = +39.64)...
2023-07-27 12:14:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 8.00e+02 / 1.18e+03 batches (snr_loss = -3.74)...
2023-07-27 12:14:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 8.00e+02 / 1.18e+03 batches (ce_loss = +3.94)...
2023-07-27 12:14:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 8.00e+02 / 1.18e+03 batches (mae_loss = +0.05)...
2023-07-27 12:14:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 8.00e+02 / 1.18e+03 batches (loss = -1.72)...
2023-07-27 12:14:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 8.00e+02 / 1.18e+03 batches (norm = +53.86)...
2023-07-27 12:31:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 9.00e+02 / 1.18e+03 batches (snr_loss = -3.77)...
2023-07-27 12:31:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 9.00e+02 / 1.18e+03 batches (ce_loss = +3.96)...
2023-07-27 12:31:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 9.00e+02 / 1.18e+03 batches (mae_loss = +0.05)...
2023-07-27 12:31:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 9.00e+02 / 1.18e+03 batches (loss = -1.73)...
2023-07-27 12:31:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 9.00e+02 / 1.18e+03 batches (norm = +82.50)...
2023-07-27 12:45:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+03 / 1.18e+03 batches (snr_loss = -3.82)...
2023-07-27 12:45:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+03 / 1.18e+03 batches (ce_loss = +3.95)...
2023-07-27 12:45:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+03 / 1.18e+03 batches (mae_loss = +0.05)...
2023-07-27 12:45:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+03 / 1.18e+03 batches (loss = -1.79)...
2023-07-27 12:45:02 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.00e+03 / 1.18e+03 batches (norm = +129.87)...
2023-07-27 13:01:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.10e+03 / 1.18e+03 batches (snr_loss = -3.80)...
2023-07-27 13:01:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.10e+03 / 1.18e+03 batches (ce_loss = +3.93)...
2023-07-27 13:01:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.10e+03 / 1.18e+03 batches (mae_loss = +0.05)...
2023-07-27 13:01:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.10e+03 / 1.18e+03 batches (loss = -1.78)...
2023-07-27 13:01:04 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:5 processed 1.10e+03 / 1.18e+03 batches (norm = +82.44)...
2023-07-27 13:17:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.979e-04) - Epoch  5: train = -1.6779(164.62m/1178)
2023-07-27 13:17:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-28 21:00:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-28 21:00:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-28 21:00:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume spk model from checkpoint /home/work_nfs4_ssd/hzhao/aslp-spknet-fork/exp/ecapa_augment_vox2/results/ecapa_augments_vox2/final.pth.tar
2023-07-28 21:00:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: gradient clipping by 5.0, default L2
2023-07-28 21:00:11 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-28 21:21:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-28 21:21:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-28 21:21:07 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume from checkpoint /home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/exp/exp_cos_2loss_TAPloss/last.pt.tar: epoch 4
2023-07-28 21:21:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: gradient clipping by 5.0, default L2
2023-07-28 21:21:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-28 22:34:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-28 22:34:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-28 22:34:39 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume spk model from checkpoint /home/work_nfs4_ssd/hzhao/aslp-spknet-fork/exp/ecapa_augment_vox2/results/ecapa_augments_vox2/final.pth.tar
2023-07-28 22:34:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: gradient clipping by 5.0, default L2
2023-07-28 22:34:50 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-28 22:35:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-28 22:35:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-28 22:35:12 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume spk model from checkpoint /home/work_nfs4_ssd/hzhao/aslp-spknet-fork/exp/ecapa_augment_vox2/results/ecapa_augments_vox2/final.pth.tar
2023-07-28 22:37:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-28 22:37:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-28 22:37:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume spk model from checkpoint /home/work_nfs4_ssd/hzhao/aslp-spknet-fork/exp/ecapa_augment_vox2/results/ecapa_augments_vox2/final.pth.tar
2023-07-28 22:38:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-28 22:38:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-28 22:38:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume spk model from checkpoint /home/work_nfs4_ssd/hzhao/aslp-spknet-fork/exp/ecapa_augment_vox2/results/ecapa_augments_vox2/final.pth.tar
2023-07-28 22:39:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: model summary:
E3Net(
  (spk_model): ModelWrapper(
    (feature_extractor): FeatureWrapper(
      (feature_module): Fbank(
        (stft): STFT()
        (filterbank): Filterbank()
      )
      (feature_normalization): SentenceFeatureNormalization()
    )
    (embedding_model): EcapaTdnnSpeakerVerification(
      (conv_block): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (se_res2block_list): ModuleList(
        (0): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (1): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
        (2): SERes2Block(
          (block1): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (dilated_conv): Res2DilatedConv1d(
            (conv_list): ModuleList(
              (0): Identity()
              (1): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (4): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (5): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (6): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (7): TdnnConvLayer(
                (activation): ReLU()
                (kernel): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))
                (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (block2): TdnnConvLayer(
            (activation): ReLU()
            (kernel): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (se_block): SEBlock1d(
            (avg_pool): AdaptiveAvgPool1d(output_size=1)
            (fc): Sequential(
              (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
              (1): ReLU(inplace=True)
              (2): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
              (3): Sigmoid()
            )
          )
        )
      )
      (mfa): TdnnConvLayer(
        (activation): ReLU()
        (kernel): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,))
        (norm): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (attentive_statistic_pooling): AttentiveStatisticsPooling(
        (tdnn): TdnnConvLayer(
          (activation): ReLU()
          (kernel): Conv1d(4608, 128, kernel_size=(1,), stride=(1,))
          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (tanh): Tanh()
        (conv): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))
      )
      (asp_bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (fc): Conv1d(3072, 256, kernel_size=(1,), stride=(1,))
    )
  )
  (encoder): Conv1d(1, 2048, kernel_size=(320,), stride=(160,))
  (encoder_norm): Sequential(
    (0): PReLU(num_parameters=1)
    (1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
  )
  (fullyconnection): Sequential(
    (0): Linear(in_features=2304, out_features=1024, bias=True)
    (1): PReLU(num_parameters=1)
    (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_1): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=1024, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_2): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_3): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (lstmblock_4): LSTMBlock(
    (fullyconnection_block): Sequential(
      (0): Linear(in_features=256, out_features=1024, bias=True)
      (1): PReLU(num_parameters=1)
      (2): Linear(in_features=1024, out_features=256, bias=True)
      (3): PReLU(num_parameters=1)
      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (lstm): LSTM(256, 256, batch_first=True)
    (layernorm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (layernorm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (mask): Sequential(
    (0): Linear(in_features=256, out_features=2048, bias=True)
    (1): Sigmoid()
  )
  (decoder): ConvTranspose1d(2048, 1, kernel_size=(320,), stride=(160,))
  (fc): Linear(in_features=256, out_features=1955, bias=True)
)
2023-07-28 22:39:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: #param: 16.10M
2023-07-28 22:39:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: resume spk model from checkpoint /home/work_nfs4_ssd/hzhao/aslp-spknet-fork/exp/ecapa_augment_vox2/results/ecapa_augments_vox2/final.pth.tar
2023-07-28 22:39:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: gradient clipping by 5.0, default L2
2023-07-28 22:39:30 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-28 23:02:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.00e+02 / 2.86e+02 batches (snr_loss = +47.30)...
2023-07-28 23:02:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.00e+02 / 2.86e+02 batches (ce_loss = +7.58)...
2023-07-28 23:02:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.00e+02 / 2.86e+02 batches (mae_loss = +0.08)...
2023-07-28 23:02:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 1.00e+02 / 2.86e+02 batches (loss = +51.17)...
2023-07-28 23:23:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.00e+02 / 2.86e+02 batches (snr_loss = +47.37)...
2023-07-28 23:23:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.00e+02 / 2.86e+02 batches (ce_loss = +7.58)...
2023-07-28 23:23:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.00e+02 / 2.86e+02 batches (mae_loss = +0.08)...
2023-07-28 23:23:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:0 processed 2.00e+02 / 2.86e+02 batches (loss = +51.24)...
2023-07-28 23:40:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 286 batches: 50.56,48.20,50.24,50.31,52.84,52.52,51.37,51.84,49.62,51.30,52.90,50.35,52.67,49.82,50.38,54.05,49.13,51.03,51.28,50.33,49.10,51.32,50.68,51.37,50.68,50.09,50.64,51.24,50.07,51.26,53.45,50.18,50.18,49.38,51.47,49.86,51.67,49.31,52.24,51.37,51.57,51.61,52.57,49.60,50.70,50.87,51.32,51.23,51.98,50.78,50.11,52.21,51.68,50.10,52.88,51.21,52.17,51.74,50.70,50.92,51.78,53.00,49.36,51.80,52.87,51.47,51.52,51.90,53.03,50.43,52.02,51.65,51.02,51.25,50.37,49.95,51.68,51.21,50.33,52.88,51.98,50.34,50.32,51.34,50.48,50.25,51.33,49.16,52.68,49.31,51.40,50.16,51.70,51.74,52.66,49.59,52.15,53.81,52.72,52.17,49.51,51.74,53.33,51.69,50.60,49.42,51.71,50.58,51.96,49.36,51.15,50.19,49.70,49.07,51.57,49.38,50.47,49.94,50.93,53.32,50.22,50.43,54.52,51.95,52.42,50.77,52.59,51.10,50.56,51.77,51.37,49.45,52.91,52.56,50.98,50.38,50.80,49.93,52.25,52.51,51.24,51.01,53.14,50.88,50.47,52.39,48.83,50.29,51.88,50.28,49.64,49.43,50.99,50.48,51.96,53.27,51.88,51.83,52.25,50.08,52.76,50.14,50.86,53.00,50.39,52.11,51.62,51.13,51.58,51.49,51.63,51.83,50.30,50.05,52.26,51.60,51.37,50.74,52.27,51.99,54.19,49.71,50.10,51.16,50.99,50.60,50.31,52.94,51.78,50.26,52.63,51.70,51.46,53.58,50.19,52.30,50.68,50.82,50.21,51.77,51.22,52.72,51.64,52.28,51.22,51.27,50.98,50.86,52.12,51.20,49.52,48.82,51.24,51.72,51.67,51.23,52.72,50.82,50.91,51.76,52.15,49.99,51.56,51.68,50.98,50.17,50.71,51.08,50.43,49.33,49.59,54.24,51.30,51.77,54.02,53.20,52.69,49.62,51.42,52.88,49.85,51.06,50.46,50.62,49.84,52.34,49.95,53.80,49.89,51.02,52.02,50.28,50.69,51.30,52.79,50.41,51.98,51.03,49.18,50.47,52.35,50.24,50.75,51.12,50.04,52.46,51.25,51.77,49.23,51.37,50.63,50.74,49.09,49.19,52.13,51.07,48.66,49.73,51.03,50.63,49.77,50.57,49.84,51.26,52.64,54.51
2023-07-28 23:40:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: start from epoch 0, loss = 51.1770
2023-07-28 23:40:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-29 00:09:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 1.18e+03 batches (snr_loss = -1.53)...
2023-07-29 00:09:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 1.18e+03 batches (ce_loss = +6.68)...
2023-07-29 00:09:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 1.18e+03 batches (mae_loss = +0.09)...
2023-07-29 00:09:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 1.18e+03 batches (loss = +1.91)...
2023-07-29 00:09:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 1.18e+03 batches (norm = +9.90)...
2023-07-29 00:33:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 1.18e+03 batches (snr_loss = -3.75)...
2023-07-29 00:33:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 1.18e+03 batches (ce_loss = +5.49)...
2023-07-29 00:33:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 1.18e+03 batches (mae_loss = +0.04)...
2023-07-29 00:33:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 1.18e+03 batches (loss = -0.96)...
2023-07-29 00:33:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 1.18e+03 batches (norm = +7.34)...
2023-07-29 00:57:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 1.18e+03 batches (snr_loss = -3.83)...
2023-07-29 00:57:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 1.18e+03 batches (ce_loss = +5.00)...
2023-07-29 00:57:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 00:57:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 1.18e+03 batches (loss = -1.30)...
2023-07-29 00:57:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 3.00e+02 / 1.18e+03 batches (norm = +9.80)...
2023-07-29 01:21:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 1.18e+03 batches (snr_loss = -3.88)...
2023-07-29 01:21:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 1.18e+03 batches (ce_loss = +4.81)...
2023-07-29 01:21:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 01:21:14 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 1.18e+03 batches (loss = -1.45)...
2023-07-29 01:21:15 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 4.00e+02 / 1.18e+03 batches (norm = +10.83)...
2023-07-29 01:46:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 1.18e+03 batches (snr_loss = -3.92)...
2023-07-29 01:46:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 1.18e+03 batches (ce_loss = +4.72)...
2023-07-29 01:46:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 01:46:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 1.18e+03 batches (loss = -1.54)...
2023-07-29 01:46:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 5.00e+02 / 1.18e+03 batches (norm = +11.72)...
2023-07-29 02:10:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 1.18e+03 batches (snr_loss = -3.85)...
2023-07-29 02:10:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 1.18e+03 batches (ce_loss = +4.64)...
2023-07-29 02:10:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 02:10:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 1.18e+03 batches (loss = -1.50)...
2023-07-29 02:10:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 6.00e+02 / 1.18e+03 batches (norm = +7.11)...
2023-07-29 02:29:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 1.18e+03 batches (snr_loss = -3.69)...
2023-07-29 02:29:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 1.18e+03 batches (ce_loss = +4.58)...
2023-07-29 02:29:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 02:29:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 1.18e+03 batches (loss = -1.37)...
2023-07-29 02:29:20 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 7.00e+02 / 1.18e+03 batches (norm = +9.67)...
2023-07-29 02:47:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 1.18e+03 batches (snr_loss = -3.80)...
2023-07-29 02:47:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 1.18e+03 batches (ce_loss = +4.56)...
2023-07-29 02:47:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 02:47:18 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 1.18e+03 batches (loss = -1.49)...
2023-07-29 02:47:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 8.00e+02 / 1.18e+03 batches (norm = +11.63)...
2023-07-29 03:05:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 1.18e+03 batches (snr_loss = -3.73)...
2023-07-29 03:05:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 1.18e+03 batches (ce_loss = +4.53)...
2023-07-29 03:05:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 03:05:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 1.18e+03 batches (loss = -1.43)...
2023-07-29 03:05:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 9.00e+02 / 1.18e+03 batches (norm = +8.71)...
2023-07-29 03:26:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 1.18e+03 batches (snr_loss = -3.84)...
2023-07-29 03:26:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 1.18e+03 batches (ce_loss = +4.48)...
2023-07-29 03:26:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 03:26:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 1.18e+03 batches (loss = -1.56)...
2023-07-29 03:26:44 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+03 / 1.18e+03 batches (norm = +6.09)...
2023-07-29 03:44:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 1.18e+03 batches (snr_loss = -3.78)...
2023-07-29 03:44:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 1.18e+03 batches (ce_loss = +4.45)...
2023-07-29 03:44:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 03:44:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 1.18e+03 batches (loss = -1.52)...
2023-07-29 03:44:40 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.10e+03 / 1.18e+03 batches (norm = +9.40)...
2023-07-29 03:56:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=1.000e-03) - Epoch  1: train = -1.1352(255.60m/1178)
2023-07-29 03:56:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-29 04:08:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 2.86e+02 batches (snr_loss = -3.92)...
2023-07-29 04:08:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 2.86e+02 batches (ce_loss = +9.77)...
2023-07-29 04:08:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 2.86e+02 batches (mae_loss = +0.03)...
2023-07-29 04:08:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 1.00e+02 / 2.86e+02 batches (loss = +0.99)...
2023-07-29 04:17:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 2.86e+02 batches (snr_loss = -3.73)...
2023-07-29 04:17:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 2.86e+02 batches (ce_loss = +9.77)...
2023-07-29 04:17:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 2.86e+02 batches (mae_loss = +0.03)...
2023-07-29 04:17:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:1 processed 2.00e+02 / 2.86e+02 batches (loss = +1.18)...
2023-07-29 04:18:19 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 286 batches: 1.75,1.10,2.07,1.66,1.92,1.06,1.78,0.07,0.59,-0.61,0.19,0.92,1.27,-0.22,-0.14,1.50,0.76,0.40,1.54,0.27,1.30,0.95,2.41,0.98,1.96,2.11,1.12,0.80,0.61,0.43,1.85,-0.00,0.79,0.67,1.52,2.61,0.92,-2.25,0.61,0.81,0.29,0.54,1.12,1.47,0.01,2.15,2.10,0.16,1.11,1.18,1.67,0.69,1.71,3.03,1.85,2.05,0.44,0.44,-1.97,0.82,0.97,0.27,0.59,0.65,1.28,0.55,2.02,1.43,-0.29,0.34,0.49,0.86,0.49,1.47,0.94,1.79,0.22,0.46,2.13,0.56,0.15,3.53,1.03,1.34,0.51,0.81,2.14,1.13,0.85,2.00,1.18,1.87,-0.73,2.11,-0.10,-0.50,2.00,0.42,2.58,0.83,1.30,0.84,1.38,0.16,0.78,1.38,0.63,1.52,1.69,1.34,0.28,1.89,1.27,1.90,0.20,1.68,1.04,2.34,-1.10,1.57,0.95,2.03,0.06,1.04,1.83,0.77,0.77,-0.87,1.75,2.00,2.61,-0.23,1.11,1.67,-0.08,0.56,1.36,1.90,1.83,0.28,1.94,0.01,3.80,2.13,0.53,0.37,2.02,0.68,1.07,1.47,0.29,0.87,1.92,1.31,2.05,1.92,-0.32,0.45,0.66,0.37,1.46,1.73,1.34,1.73,0.91,1.38,1.68,1.72,2.91,1.91,1.66,1.53,0.23,1.38,0.16,0.73,0.38,0.79,2.36,1.04,1.26,1.17,1.97,2.09,-0.15,0.63,0.24,1.83,-0.46,0.91,2.42,0.77,1.23,1.04,0.20,1.80,1.62,1.70,1.32,2.57,0.80,0.18,0.39,1.27,0.60,1.40,0.36,1.24,0.03,2.05,1.96,1.66,1.58,1.09,2.30,1.63,-1.26,0.36,-0.31,2.08,1.12,1.24,0.05,0.43,1.82,0.39,-0.34,1.23,0.87,0.92,1.75,1.10,-0.54,3.13,0.96,0.93,3.55,1.10,-0.18,0.37,1.13,1.05,1.08,1.53,1.95,1.98,-0.13,0.30,0.66,1.30,1.46,2.93,1.18,1.71,0.34,1.22,1.41,0.56,1.64,2.37,0.96,-0.03,2.96,1.34,1.51,0.67,0.07,1.45,1.62,1.40,1.13,1.53,0.43,1.88,2.73,1.38,0.63,0.91,1.83,1.42,0.49,0.28,0.38,1.64,-0.29,0.92
2023-07-29 04:18:27 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint best.pt.tar
2023-07-29 04:18:31 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=1.000e-03) - Epoch  1: eval = 1.0898(22.29m/286)
2023-07-29 04:18:36 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-29 04:18:37 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-29 04:32:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 1.18e+03 batches (snr_loss = -3.78)...
2023-07-29 04:32:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 1.18e+03 batches (ce_loss = +4.39)...
2023-07-29 04:32:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 04:32:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 1.18e+03 batches (loss = -1.56)...
2023-07-29 04:32:13 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 1.18e+03 batches (norm = +8.98)...
2023-07-29 04:48:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 1.18e+03 batches (snr_loss = -3.81)...
2023-07-29 04:48:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 1.18e+03 batches (ce_loss = +4.36)...
2023-07-29 04:48:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 04:48:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 1.18e+03 batches (loss = -1.60)...
2023-07-29 04:48:33 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 1.18e+03 batches (norm = +7.86)...
2023-07-29 05:03:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 1.18e+03 batches (snr_loss = -3.89)...
2023-07-29 05:03:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 1.18e+03 batches (ce_loss = +4.34)...
2023-07-29 05:03:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 05:03:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 1.18e+03 batches (loss = -1.69)...
2023-07-29 05:03:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 3.00e+02 / 1.18e+03 batches (norm = +7.61)...
2023-07-29 05:19:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 1.18e+03 batches (snr_loss = -3.84)...
2023-07-29 05:19:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 1.18e+03 batches (ce_loss = +4.30)...
2023-07-29 05:19:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 05:19:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 1.18e+03 batches (loss = -1.66)...
2023-07-29 05:19:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 4.00e+02 / 1.18e+03 batches (norm = +7.39)...
2023-07-29 05:44:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 1.18e+03 batches (snr_loss = -3.80)...
2023-07-29 05:44:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 1.18e+03 batches (ce_loss = +4.27)...
2023-07-29 05:44:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 05:44:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 1.18e+03 batches (loss = -1.64)...
2023-07-29 05:44:41 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 5.00e+02 / 1.18e+03 batches (norm = +12.07)...
2023-07-29 06:09:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 1.18e+03 batches (snr_loss = -3.71)...
2023-07-29 06:09:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 1.18e+03 batches (ce_loss = +4.25)...
2023-07-29 06:09:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 06:09:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 1.18e+03 batches (loss = -1.55)...
2023-07-29 06:09:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 6.00e+02 / 1.18e+03 batches (norm = +10.73)...
2023-07-29 06:29:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 1.18e+03 batches (snr_loss = -3.76)...
2023-07-29 06:29:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 1.18e+03 batches (ce_loss = +4.23)...
2023-07-29 06:29:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 06:29:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 1.18e+03 batches (loss = -1.62)...
2023-07-29 06:29:57 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 7.00e+02 / 1.18e+03 batches (norm = +5.83)...
2023-07-29 06:48:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 1.18e+03 batches (snr_loss = -3.95)...
2023-07-29 06:48:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 1.18e+03 batches (ce_loss = +4.20)...
2023-07-29 06:48:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 06:48:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 1.18e+03 batches (loss = -1.82)...
2023-07-29 06:48:03 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 8.00e+02 / 1.18e+03 batches (norm = +11.05)...
2023-07-29 07:06:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 1.18e+03 batches (snr_loss = -3.76)...
2023-07-29 07:06:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 1.18e+03 batches (ce_loss = +4.18)...
2023-07-29 07:06:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 07:06:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 1.18e+03 batches (loss = -1.64)...
2023-07-29 07:06:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 9.00e+02 / 1.18e+03 batches (norm = +7.57)...
2023-07-29 07:26:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 1.18e+03 batches (snr_loss = -3.98)...
2023-07-29 07:26:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 1.18e+03 batches (ce_loss = +4.14)...
2023-07-29 07:26:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 07:26:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 1.18e+03 batches (loss = -1.88)...
2023-07-29 07:26:01 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+03 / 1.18e+03 batches (norm = +5.87)...
2023-07-29 07:42:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 1.18e+03 batches (snr_loss = -4.23)...
2023-07-29 07:42:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 1.18e+03 batches (ce_loss = +4.11)...
2023-07-29 07:42:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 07:42:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 1.18e+03 batches (loss = -2.14)...
2023-07-29 07:42:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.10e+03 / 1.18e+03 batches (norm = +6.13)...
2023-07-29 07:53:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.988e-04) - Epoch  2: train = -1.7357(215.10m/1178)
2023-07-29 07:53:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set eval mode...
2023-07-29 07:59:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 2.86e+02 batches (snr_loss = -4.10)...
2023-07-29 07:59:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 2.86e+02 batches (ce_loss = +10.11)...
2023-07-29 07:59:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 2.86e+02 batches (mae_loss = +0.03)...
2023-07-29 07:59:17 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 1.00e+02 / 2.86e+02 batches (loss = +0.98)...
2023-07-29 08:00:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 2.86e+02 batches (snr_loss = -4.22)...
2023-07-29 08:00:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 2.86e+02 batches (ce_loss = +10.12)...
2023-07-29 08:00:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 2.86e+02 batches (mae_loss = +0.03)...
2023-07-29 08:00:21 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:2 processed 2.00e+02 / 2.86e+02 batches (loss = +0.87)...
2023-07-29 08:00:59 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: loss on 286 batches: 0.83,1.67,0.40,-0.17,0.73,-0.01,0.48,1.77,1.13,1.40,0.78,2.72,0.94,0.81,-0.20,1.34,0.20,2.00,1.32,1.88,2.40,0.90,2.58,-1.09,0.39,-0.12,0.60,-0.48,0.68,1.23,1.15,1.44,1.25,0.60,0.33,-0.23,1.77,0.38,1.63,1.21,2.06,-0.74,0.55,0.64,2.30,-0.40,1.10,2.41,0.11,-0.08,0.87,0.95,1.21,1.19,-1.32,2.13,0.53,0.13,1.59,0.96,3.02,2.26,0.26,4.06,2.67,-0.84,0.28,0.49,0.69,2.47,0.67,3.02,1.26,2.35,-0.23,1.30,0.57,0.17,2.09,1.79,0.60,1.42,0.38,0.03,1.27,1.54,1.18,1.32,-0.07,-0.55,1.32,1.60,0.20,-0.09,1.27,1.82,1.07,1.07,0.55,1.10,-0.78,0.26,1.08,2.78,-1.60,0.53,1.43,0.75,0.49,1.29,0.16,0.08,1.65,3.02,2.15,1.14,1.01,0.67,2.47,2.12,0.14,1.00,-0.97,0.92,1.91,-0.11,0.40,0.06,1.07,1.00,1.35,3.04,-0.03,0.19,1.70,0.90,0.57,0.67,0.94,1.39,0.92,1.47,0.13,0.27,0.29,0.07,1.11,0.50,1.42,-0.01,1.21,-0.01,0.45,2.97,1.43,0.43,2.38,0.76,-0.77,0.06,0.66,0.25,1.63,0.94,1.41,1.38,0.40,2.70,2.12,1.85,-0.30,0.01,-0.19,1.15,-0.19,0.28,0.54,1.59,0.77,-0.47,1.57,0.67,0.40,-0.23,-0.01,0.75,0.54,1.66,0.77,1.67,0.79,0.86,1.46,1.38,2.15,1.34,-1.38,1.04,1.14,1.96,0.20,1.27,-0.41,-0.71,-0.24,1.53,2.04,1.40,2.70,2.77,-0.23,0.67,1.49,1.06,-0.01,0.42,1.82,3.14,1.58,1.68,0.32,1.84,2.06,2.19,-0.25,1.16,1.12,-0.09,0.02,3.40,1.79,0.38,0.42,0.46,4.48,1.81,1.00,1.33,-0.01,0.93,2.51,1.49,0.25,1.13,1.40,-0.11,-0.43,1.53,2.80,1.06,-0.94,-0.40,0.99,1.09,0.31,-1.13,0.04,0.79,0.27,0.24,0.93,0.51,-0.06,1.77,0.15,0.81,1.58,0.60,0.09,1.21,0.89,1.12,-0.71,2.32,2.31,1.12,1.70,1.16,1.34,1.33,0.27,1.36,1.27,2.21,-0.05,0.42
2023-07-29 08:01:10 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint best.pt.tar
2023-07-29 08:01:16 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Loss(time/N, lr=9.988e-04) - Epoch  2: eval = 0.9452(7.27m/286)
2023-07-29 08:01:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: save checkpoint last.pt.tar
2023-07-29 08:01:38 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: set train mode...
2023-07-29 08:14:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+02 / 1.18e+03 batches (snr_loss = -4.25)...
2023-07-29 08:14:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+02 / 1.18e+03 batches (ce_loss = +4.09)...
2023-07-29 08:14:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 08:14:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+02 / 1.18e+03 batches (loss = -2.18)...
2023-07-29 08:14:25 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+02 / 1.18e+03 batches (norm = +7.16)...
2023-07-29 08:29:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 2.00e+02 / 1.18e+03 batches (snr_loss = -4.18)...
2023-07-29 08:29:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 2.00e+02 / 1.18e+03 batches (ce_loss = +4.06)...
2023-07-29 08:29:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 2.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 08:29:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 2.00e+02 / 1.18e+03 batches (loss = -2.12)...
2023-07-29 08:29:43 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 2.00e+02 / 1.18e+03 batches (norm = +8.12)...
2023-07-29 08:44:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 3.00e+02 / 1.18e+03 batches (snr_loss = -4.19)...
2023-07-29 08:44:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 3.00e+02 / 1.18e+03 batches (ce_loss = +4.04)...
2023-07-29 08:44:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 3.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 08:44:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 3.00e+02 / 1.18e+03 batches (loss = -2.14)...
2023-07-29 08:44:06 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 3.00e+02 / 1.18e+03 batches (norm = +15.58)...
2023-07-29 09:00:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 4.00e+02 / 1.18e+03 batches (snr_loss = -4.39)...
2023-07-29 09:00:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 4.00e+02 / 1.18e+03 batches (ce_loss = +4.03)...
2023-07-29 09:00:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 4.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 09:00:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 4.00e+02 / 1.18e+03 batches (loss = -2.35)...
2023-07-29 09:00:26 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 4.00e+02 / 1.18e+03 batches (norm = +10.92)...
2023-07-29 09:18:45 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 5.00e+02 / 1.18e+03 batches (snr_loss = -4.28)...
2023-07-29 09:18:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 5.00e+02 / 1.18e+03 batches (ce_loss = +4.01)...
2023-07-29 09:18:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 5.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 09:18:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 5.00e+02 / 1.18e+03 batches (loss = -2.25)...
2023-07-29 09:18:46 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 5.00e+02 / 1.18e+03 batches (norm = +9.65)...
2023-07-29 09:35:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 6.00e+02 / 1.18e+03 batches (snr_loss = -4.29)...
2023-07-29 09:35:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 6.00e+02 / 1.18e+03 batches (ce_loss = +3.99)...
2023-07-29 09:35:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 6.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 09:35:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 6.00e+02 / 1.18e+03 batches (loss = -2.26)...
2023-07-29 09:35:49 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 6.00e+02 / 1.18e+03 batches (norm = +7.83)...
2023-07-29 09:51:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 7.00e+02 / 1.18e+03 batches (snr_loss = -4.42)...
2023-07-29 09:51:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 7.00e+02 / 1.18e+03 batches (ce_loss = +3.97)...
2023-07-29 09:51:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 7.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 09:51:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 7.00e+02 / 1.18e+03 batches (loss = -2.41)...
2023-07-29 09:51:42 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 7.00e+02 / 1.18e+03 batches (norm = +14.71)...
2023-07-29 10:08:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 8.00e+02 / 1.18e+03 batches (snr_loss = -4.35)...
2023-07-29 10:08:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 8.00e+02 / 1.18e+03 batches (ce_loss = +3.95)...
2023-07-29 10:08:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 8.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 10:08:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 8.00e+02 / 1.18e+03 batches (loss = -2.35)...
2023-07-29 10:08:51 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 8.00e+02 / 1.18e+03 batches (norm = +11.59)...
2023-07-29 10:25:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 9.00e+02 / 1.18e+03 batches (snr_loss = -4.42)...
2023-07-29 10:25:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 9.00e+02 / 1.18e+03 batches (ce_loss = +3.93)...
2023-07-29 10:25:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 9.00e+02 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 10:25:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 9.00e+02 / 1.18e+03 batches (loss = -2.43)...
2023-07-29 10:25:54 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 9.00e+02 / 1.18e+03 batches (norm = +13.10)...
2023-07-29 10:46:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+03 / 1.18e+03 batches (snr_loss = -4.32)...
2023-07-29 10:46:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+03 / 1.18e+03 batches (ce_loss = +3.89)...
2023-07-29 10:46:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+03 / 1.18e+03 batches (mae_loss = +0.03)...
2023-07-29 10:46:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+03 / 1.18e+03 batches (loss = -2.35)...
2023-07-29 10:46:05 [/home/work_nfs7/zqwang/summer_intern_dir/team03/summer_intern/trainer/trainer.py:66 - INFO ] Trainer: Epoch:3 processed 1.00e+03 / 1.18e+03 batches (norm = +8.87)...
